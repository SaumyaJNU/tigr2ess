<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN" "JATS-archivearticle1.dtd"> 
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName JATS-journalpublishing1.dtd?><?SourceDTD.Version 1.1?><?ConverterInfo.XSLTName jp2nlmx2.xsl?><?ConverterInfo.Version 1?><front><journal-meta><journal-id journal-id-type="nlm-ta">Sensors (Basel)</journal-id><journal-id journal-id-type="iso-abbrev">Sensors (Basel)</journal-id><journal-id journal-id-type="publisher-id">sensors</journal-id><journal-title-group><journal-title>Sensors (Basel, Switzerland)</journal-title></journal-title-group><issn pub-type="epub">1424-8220</issn><publisher><publisher-name>MDPI</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">6069430</article-id><article-id pub-id-type="doi">10.3390/s18072089</article-id><article-id pub-id-type="publisher-id">sensors-18-02089</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>A Novel Approach for Mapping Wheat Areas Using High Resolution Sentinel-2 Images</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Nasrallah</surname><given-names>Ali</given-names></name><xref ref-type="aff" rid="af1-sensors-18-02089">1</xref><xref ref-type="aff" rid="af2-sensors-18-02089">2</xref><xref ref-type="aff" rid="af3-sensors-18-02089">3</xref><xref rid="c1-sensors-18-02089" ref-type="corresp">*</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-9461-4120</contrib-id><name><surname>Baghdadi</surname><given-names>Nicolas</given-names></name><xref ref-type="aff" rid="af1-sensors-18-02089">1</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-2741-8653</contrib-id><name><surname>Mhawej</surname><given-names>Mario</given-names></name><xref ref-type="aff" rid="af2-sensors-18-02089">2</xref></contrib><contrib contrib-type="author"><name><surname>Faour</surname><given-names>Ghaleb</given-names></name><xref ref-type="aff" rid="af2-sensors-18-02089">2</xref></contrib><contrib contrib-type="author"><name><surname>Darwish</surname><given-names>Talal</given-names></name><xref ref-type="aff" rid="af2-sensors-18-02089">2</xref></contrib><contrib contrib-type="author"><name><surname>Belhouchette</surname><given-names>Hatem</given-names></name><xref ref-type="aff" rid="af3-sensors-18-02089">3</xref></contrib><contrib contrib-type="author"><name><surname>Darwich</surname><given-names>Salem</given-names></name><xref ref-type="aff" rid="af4-sensors-18-02089">4</xref></contrib></contrib-group><aff id="af1-sensors-18-02089"><label>1</label>IRSTEA, University of Montpellier, TETIS, 34090 Montpellier, France; <email>nicolas.baghdadi@teledetection.fr</email></aff><aff id="af2-sensors-18-02089"><label>2</label>National Center for Remote Sensing, National Council for Scientific Research (CNRS), Riad al Soloh, Beirut 1107 2260, Lebanon; <email>mario.mhawej@gmail.com</email> (M.M.); <email>gfaour@cnrs.edu.lb</email> (G.F.); <email>tdarwich@cnrs.edu.lb</email> (T.D.)</aff><aff id="af3-sensors-18-02089"><label>3</label>CIHEAM-IAMM, UMR-System, 34090 Montpellier, France; <email>belhouchette@iamm.fr</email></aff><aff id="af4-sensors-18-02089"><label>4</label>Faculty of Agriculture, Lebanese University, Beirut 99, Lebanon; <email>salem.darwich@ul.edu.lb</email></aff><author-notes><corresp id="c1-sensors-18-02089"><label>*</label>Correspondence: <email>ali.nasrallah@agroparistech.fr</email>; Tel.: +33-4-675-487-38</corresp></author-notes><pub-date pub-type="epub"><day>29</day><month>6</month><year>2018</year></pub-date><pub-date pub-type="collection"><month>7</month><year>2018</year></pub-date><volume>18</volume><issue>7</issue><elocation-id>2089</elocation-id><history><date date-type="received"><day>03</day><month>5</month><year>2018</year></date><date date-type="accepted"><day>26</day><month>6</month><year>2018</year></date></history><permissions><copyright-statement>&#x000a9; 2018 by the authors.</copyright-statement><copyright-year>2018</copyright-year><license license-type="open-access"><license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p></license></permissions><abstract><p>Global wheat production reached 754.8 million tons in 2017, according to the FAO database. While wheat is considered as a staple food for many populations across the globe, mapping wheat could be an effective tool to achieve the SDG2 sustainable development goal&#x02014;End Hunger and Secure Food Security. In Lebanon, this crop is supported financially, and sometimes technically, by the Lebanese government. However, there is a lack of statistical databases, at both national and regional scales, as well as critical information much needed in the subsidy and compensation system. In this context, this study proposes an innovative approach, named Simple and Effective Wheat Mapping Approach (<italic>SEWMA</italic>), to map the winter wheat areas grown in the Bekaa plain, the primary wheat production area in Lebanon, in the years of 2016 and 2017. The proposed methodology is a tree-like approach relying on the Normalized Difference Vegetation Index (NDVI) values of four-month period that coincides with several phenological stages of wheat (i.e., tillering, stem extension, heading, flowering and ripening). The usage of the freely available Sentinel-2 imageries, with a high spatial (10 m) and temporal (5 days) resolutions, was necessary, particularly due to the small sized and overlapped plots encountered in the study area. Concerning the wheat areas, results show that there was a decrease from 11,063 &#x000b1; 1309 ha in 2016 to 7605 &#x000b1; 1184 in 2017. When <italic>SEWMA</italic> was applied using 2016 ground truth data, the overall accuracy reached 87.0% on 2017 data, whereas, when implemented using 2017 ground truth data, the overall accuracy was 82.6% on 2016 data. The novelty resides in executing early classification output (up to six weeks before harvest) as well as distinguishing wheat from other winter cereal crops with similar NDVI yearly profiles (i.e., barley and triticale). <italic>SEWMA</italic> offers a simple, yet effective and budget-saving approach providing early-season classification information, very crucial to decision support systems and the Lebanese government concerning, but not limited to, food production, trade, management and agricultural financial support.</p></abstract><kwd-group><kwd>wheat</kwd><kwd>crop classification</kwd><kwd>Sentinel-2</kwd><kwd>NDVI</kwd><kwd>tree-like approach</kwd><kwd>Lebanon</kwd></kwd-group></article-meta></front><body><sec id="sec1-sensors-18-02089"><title>1. Introduction</title><p>With the steady increase of population and food demands in Lebanon [<xref rid="B1-sensors-18-02089" ref-type="bibr">1</xref>], particularly following the massive influx of Syrian refugees since 2011, land degradation and mismanagement threaten food security. The latter is jeopardized as well by the partial and intermittent agricultural census, held once every 5&#x02013;8 years depending on field questionnaires and farmers&#x02019; estimations. Even the national land cover/land use map, which is updated approximately every five years, contains no crop-specific classification. However, according to assumptions in 2010, the winter wheat cereal, supported by the Lebanese government as a strategic crop for food security in the country, occupied around 44% of the total field crop-cultivated land [<xref rid="B2-sensors-18-02089" ref-type="bibr">2</xref>]. </p><p>A regularly updated agricultural map, beginning with the identification of wheat parcels through remote sensing imageries, is then highly crucial for the Lebanese state and national statistics. These crop maps can assist decision-makers and end-users in identifying the cropped areas, estimating biomass production, water productivity, irrigation needs and scheduling, as well as defining management strategies. But more importantly, deriving statistics for annual cash crops to support sustainable national food security policies is vital [<xref rid="B3-sensors-18-02089" ref-type="bibr">3</xref>,<xref rid="B4-sensors-18-02089" ref-type="bibr">4</xref>,<xref rid="B5-sensors-18-02089" ref-type="bibr">5</xref>,<xref rid="B6-sensors-18-02089" ref-type="bibr">6</xref>].</p><p>In this context, previous studies have focused on generating the annual reference temporal profile using diverse Vegetation Indices (VI), such as the commonly known Normalized Difference Vegetation Index (NDVI) [<xref rid="B3-sensors-18-02089" ref-type="bibr">3</xref>,<xref rid="B7-sensors-18-02089" ref-type="bibr">7</xref>,<xref rid="B8-sensors-18-02089" ref-type="bibr">8</xref>,<xref rid="B9-sensors-18-02089" ref-type="bibr">9</xref>]. Low-resolution sensors such as the Advanced Very High Resolution Radiometer (AVHRR), with a spatial resolution of 1 km, and the Moderate Resolution Imaging Spectroradiometer (MODIS), with a spatial resolution of 250 m, were largely used to classify several crops such as corn and soybeans [<xref rid="B10-sensors-18-02089" ref-type="bibr">10</xref>,<xref rid="B11-sensors-18-02089" ref-type="bibr">11</xref>]. Results showed high accuracy (~80%) in terms of differentiation between major crops&#x02019; type (e.g., rice, corn, millet and cotton) [<xref rid="B10-sensors-18-02089" ref-type="bibr">10</xref>,<xref rid="B12-sensors-18-02089" ref-type="bibr">12</xref>]. However, and due to the low spatial resolution sensors, many heterogeneous pixels were mixed&#x02014;crop/non crop, irrigated/non-irrigated, and even between different crops&#x02019; type [<xref rid="B7-sensors-18-02089" ref-type="bibr">7</xref>,<xref rid="B13-sensors-18-02089" ref-type="bibr">13</xref>,<xref rid="B14-sensors-18-02089" ref-type="bibr">14</xref>].</p><p>The usage of sensors with higher spatial and temporal resolutions was then needed. Both [<xref rid="B15-sensors-18-02089" ref-type="bibr">15</xref>,<xref rid="B16-sensors-18-02089" ref-type="bibr">16</xref>] applied a decision tree algorithm to Landsat-8 imageries, with a spatial resolution of 30 m. Their approaches yielded high accuracy in mapping the available main crops (i.e., wheat, alfalfa, barley rice, trees, vegetables and potato). Another study [<xref rid="B17-sensors-18-02089" ref-type="bibr">17</xref>] has showed that the inclusion of Gaussian kernel soft classifier, with Euclidean Norm in Possibilistic c-Means (KPCM), has been more robust in identification of the wheat crop when using Landsat 8 imageries. As for the temporal data, imageries corresponding to tillering, stem extension, heading and ripening stages of wheat crop would be the best combination to reach a highly accurate classification [<xref rid="B17-sensors-18-02089" ref-type="bibr">17</xref>].</p><p>Another study [<xref rid="B18-sensors-18-02089" ref-type="bibr">18</xref>] has considered the usage of both optical (i.e., Landsat-8) and radar (i.e., Sentinel-1 SAR) satellite imageries to improve early crop type (i.e., sunflower, wheat/barley, corn, soybean, grassland, alfalfa, bare soil, rapeseed and no-crop) classification. The obvious reason of merging the two imageries&#x02019; types is to create a &#x0201c;weather-independent&#x0201d; methodology. The proposed approach showed that the Kappa value increased to 73%, from 66% and 69%, when using Sentinel-1 and Landsat-8 solely, respectively. In the same context, McNairn et al. [<xref rid="B19-sensors-18-02089" ref-type="bibr">19</xref>] integrated both optical and Synthetic Aperture Radar (SAR) imageries. Results showed that SAR images alone were not enough to accurately map crops. When only one or two optical images are available, the addition of two SAR images will improve overall accuracies and will boost individual crop classification matching to reach at least 85%.</p><p>Through the first experience with Sentinel-2 data for crop and tree species classification in central Europe, Immitzer et al. [<xref rid="B20-sensors-18-02089" ref-type="bibr">20</xref>] employed a supervised random forest classifier (RF). They successfully mapped six summer crop species (i.e., carrots, maize, soya, onions, sugar beet and sunflower), in addition to winter crops and bare soil in lower Austria, as well as seven different deciduous and coniferous trees in Germany. Cross-validated overall accuracies ranged between 65% (tree species) and 76% (crop types). However, the study has also revealed the great potential of the red-edge and shortwave infrared bands for mapping vegetation. </p><p>As saving resources has been having great attention recently, some studies have focused on the cross-year validation. For instance, in the central United States, soybean and corn were mapped using Landsat imagery with cross year validation [<xref rid="B21-sensors-18-02089" ref-type="bibr">21</xref>]. Results have showed an average overall accuracy of 82%. The proposed approach required several sets of input variables (i.e., traditional spectral features at imaging dates, phenological metrics derived from EVI time series, spectral features and vegetation indices interpolated at phenological transition dates, and accumulated temperature during phenological stages). Thus, with high complexity of data sources, the implementation of such approach could be challenging.</p><p>Early crop mapping has been the focus of recent work, especially when coupled with remotely-sensed data. In 2015, a study was conducted in France to assess the contribution of very high spatial resolution (VHSR) Pl&#x000e9;iades images to early season crop identification. The validation of the approach showed a drop in overall accuracy from 79%, when considering winter cereals as a composite class, to 69% when discriminating among winter wheat and winter barley [<xref rid="B22-sensors-18-02089" ref-type="bibr">22</xref>]. In a recent study [<xref rid="B23-sensors-18-02089" ref-type="bibr">23</xref>], MODIS NDVI time-series data, crop mask and growing degree days were used to map winter crops in an automated way up to two months prior to harvesting period. Their results have showed accuracy exceeding 90%. While it is highly important to execute early season mapping, further crop-specific classification, with a high overall accuracy, is much needed at regional and national scale.</p><p>In the abovementioned studies several shortcomings were observed: (1) wheat classification could not be carried out before the end of the cropping season (i.e., during maturation stage); (2) results have not been validated on different cropping seasons; and (3) they did not distinguish among similar VI-annual profile cereal crops (e.g., barley and triticale). In this context, this paper will be examining the ability of the new high resolution optical sensor Sentinel-2 with 10 m spatial and 5 days temporal resolutions, to accurately map winter wheat in the Bekaa plain of Lebanon using a novel, yet simple classification approach, named Simple and Effective Wheat Mapping Approach or <italic>SEWMA</italic>. It is a decision tree-like algorithm, based on the NDVI values that is able to overcome the major challenges of achieving high accuracy classification before the end of the cropping cycle, could be portable to other years, and can distinguish wheat from barley and triticale. The implementation of <italic>SEWMA</italic> approach at regional/national scale shall enable an adequate planning and managements by decision makers and governments while saving on resources and monetary values for field based statistics. <xref ref-type="sec" rid="sec2-sensors-18-02089">Section 2</xref> presents the study site and the cropping calendar, followed by <xref ref-type="sec" rid="sec3-sensors-18-02089">Section 3</xref> which describes the database and materials used. <xref ref-type="sec" rid="sec4-sensors-18-02089">Section 4</xref> describes the methodology of the proposed approach. The results are shown in <xref ref-type="sec" rid="sec4-sensors-18-02089">Section 4</xref>. <xref ref-type="sec" rid="sec5-sensors-18-02089">Section 5</xref> presents a discussion of the important results, followed by a conclusion.</p></sec><sec id="sec2-sensors-18-02089"><title>2. Study Area</title><p>The selected study area, the Bekaa plain, is located between 33&#x000b0;33&#x02032; N and 33&#x000b0;60&#x02032; N latitude, 35&#x000b0;39&#x02032; E and 36&#x000b0;14&#x02032; E longitude (<xref ref-type="fig" rid="sensors-18-02089-f001">Figure 1</xref>), covering an area of 860.25 km<sup>2</sup>. The plain lies between two natural units having very steep slopes; the eastern slopes of the Mount-Lebanon Mountains (western unit) and the Western slopes of the Anti-Lebanon Mountains (eastern unit). The average elevation of the study area is around 1000 m above sea level (a.s.l.). The study area is characterized by a semi-arid (northern part) and dry-Mediterranean (southern part) climate and the average annual precipitation is around 600 mm [<xref rid="B24-sensors-18-02089" ref-type="bibr">24</xref>].</p><p>Agriculture is the main economic activity in the Bekaa plain, including several field crops (e.g., wheat, potato, barley and alfalfa) of various field areas ranging from 0.1 ha to more than 20 ha. However, the wheat parcels predominate in the areas, corresponding to more than 65% of national cereal production [<xref rid="B2-sensors-18-02089" ref-type="bibr">2</xref>]. Wheat, as well as the other local cereals (i.e., barley and triticale), have a very similar phenological cycle as they are sown in November and harvested next year in June. In addition to the cereals, other spring and summer crops (e.g., potato, corn, vegetables and alfalfa), are being cultivated in the Bekaa plain. <xref ref-type="fig" rid="sensors-18-02089-f002">Figure 2</xref> illustrates the crop calendar of the main field crops grown in the plain. </p></sec><sec id="sec3-sensors-18-02089"><title>3. Material and Methods</title><sec id="sec3dot1-sensors-18-02089"><title>3.1. Datasets and Preprocessing</title><p>Two types of datasets were essential to conduct this study: two-year field data containing ground reference plots to train and validate our approach, and corresponding Sentinel-2 imageries (each tile is of 100 &#x000d7; 100 km<sup>2</sup>). These datasets were used to extract the NDVI temporal profile, as it was the main key to eventually classify winter wheat at the Bekaa plain of Lebanon during the two years of study (i.e., 2016 and 2017). <xref ref-type="fig" rid="sensors-18-02089-f003">Figure 3</xref> represents a flowchart summarizing the preparation work, whose output will be used as input for our proposed approach.</p><sec id="sec3dot1dot1-sensors-18-02089"><title>3.1.1. Satellite Data</title><p>Sentinel-2 is the second generation Earth Observation (EO) satellite operated by the European Space Agency (ESA) [<xref rid="B26-sensors-18-02089" ref-type="bibr">26</xref>]. The launching of Sentinel-2A and Sentinel-2B was in June 2015 and March 2017 respectively, as an integral part of Europe&#x02019;s Copernicus program aiming at independent and continued global observation capacities [<xref rid="B20-sensors-18-02089" ref-type="bibr">20</xref>]. Sentinel-2 offers a fine spectral, spatial and temporal resolutions (i.e., 13 bands ranging from 10 m to 60 m with a revisit time of five days). Datasets produced by this satellite could be downloaded free of charge from Europe&#x02019;s Copernicus website [<xref rid="B27-sensors-18-02089" ref-type="bibr">27</xref>]. Eight Sentinel-2 images were used each year (i.e., 2016 and 2017) between January and May (<xref rid="sensors-18-02089-t001" ref-type="table">Table 1</xref>), as these images cover the main phenological stages. The pre-processing of L1C (Top of Atmosphere or TOA reflectance) Sentinel-2 images, which includes ortho-rectification, cloud removal (using cloud mask produced by Sen2Cor/SNAP), radiometric calibration and atmospheric correction, was produced using SNAP/Sentinel-2 toolbox. The output of the pre-processing, corresponds to L2A (Bottom of Atmosphere or BOA reflectance).</p><p>The Normalized Difference Vegetation Index (NDVI), which ranges from &#x02212;1 to 1 is successful in predicting photosynthetic activity as it is computed from the Red (<italic>&#x003c1;</italic>RED) and Near Infrared (<italic>&#x003c1;</italic>NIR) reflectance values, corresponding to Bands 4 and 8, respectively, as follows:<disp-formula id="FD1-sensors-18-02089"><label>(1)</label><mml:math id="mm1"><mml:mrow><mml:mrow><mml:mi>NDVI</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>&#x003c1;</mml:mi><mml:mi>NIR</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003c1;</mml:mi><mml:mi>RED</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003c1;</mml:mi><mml:mi>NIR</mml:mi><mml:mo>+</mml:mo><mml:mi>&#x003c1;</mml:mi><mml:mi>RED</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>There is a strong correlation between the NDVI ratio and above ground green biomass [<xref rid="B28-sensors-18-02089" ref-type="bibr">28</xref>]. In other words, as green biomass increases, NDVI reflectance tends to get closer to 1, thus, spectral measurements are strongly related to the amount of leafy biomass [<xref rid="B29-sensors-18-02089" ref-type="bibr">29</xref>,<xref rid="B30-sensors-18-02089" ref-type="bibr">30</xref>].</p><p>As in our case, during winter, the wheat canopy tends to go through a dormancy stage where development is paused until reaching a certain Growth Degree Days [<xref rid="B31-sensors-18-02089" ref-type="bibr">31</xref>]. During this period, NDVI normally does not exceed 0.3. After stem elongation and booting stage are initiated, NDVI comes closer to 1 [<xref rid="B32-sensors-18-02089" ref-type="bibr">32</xref>].</p><p>While applying the mean shift segmentation (post cloud removal) to the study area for each year, the area of interest was clustered into homogeneous units (segments) in each year (2016 and 2017). For both years, eight NDVI images (<xref rid="sensors-18-02089-t001" ref-type="table">Table 1</xref>) were stacked together and used as an input to the mean-shift algorithm, to produce unique homogeneous units&#x02019; map (segments) for each year (i.e., 2016 and 2017). The mean-shift segmentation [<xref rid="B33-sensors-18-02089" ref-type="bibr">33</xref>,<xref rid="B34-sensors-18-02089" ref-type="bibr">34</xref>] is a widely used segmentation approach [<xref rid="B35-sensors-18-02089" ref-type="bibr">35</xref>], firstly proposed by [<xref rid="B36-sensors-18-02089" ref-type="bibr">36</xref>]. It relies basically on spatial and range radii and was executed in this paper using the open source software QGIS [<xref rid="B37-sensors-18-02089" ref-type="bibr">37</xref>]. The segmentation parameters are: Spatial radius = 10 pixels and NDVI range radius = 0.1. The reason behind setting such parameters is, first, since the resolution of Sentine-2 is 10 m, then ten pixels are 1000 m<sup>2</sup>, which is the minimum cultivated area by farmers in the studied region; second, since the variability in NDVI within our reference plots over the eight dates used did not exceed 0.1 as NDVI value, a 0.1 range radius was used.</p></sec><sec id="sec3dot1dot2-sensors-18-02089"><title>3.1.2. Ground Data</title><p>Field visits were carried out between February and June of the corresponding years (i.e., 2016 and 2017), as this period covers the most critical wheat phenological stages needed for classification. Cereals plots (i.e., wheat, barley and triticale) as well as other cultivated plots (i.e., spring potato and spring vegetables, fruit trees, vineyards, and alfalfa) and bare soil areas were visited and their coordinates were recorded as reference plots (<xref rid="sensors-18-02089-t002" ref-type="table">Table 2</xref>). These plots were fragmented according to the segmentation output (produced earlier) of each year and used for training and validation processes.</p></sec><sec id="sec3dot1dot3-sensors-18-02089"><title>3.1.3. Temporal Profile Analysis</title><p>In order to produce the NDVI-temporal profiles for the main cultivations in the study area, the mean and the standard deviation of the NDVI images were calculated at segment level.</p><p>The behaviors of the reflectance of the main cereals (i.e., wheat, barley and triticale), spring potato and spring vegetables in the NIR, Red and NDVI are presented in the Results section (<xref ref-type="sec" rid="sec4dot1-sensors-18-02089">Section 4.1</xref>).</p></sec></sec><sec id="sec3dot2-sensors-18-02089"><title>3.2. SEWMA Generation</title><p>The main objective of this study is to map the spatial distribution of the wheat segments four to six weeks prior to the harvesting period for both 2016 and 2017 cropping seasons. The methodology proposed consists basically of two phases. The first phase discriminates wheat candidate segments (plots or sub-plots), which could be wheat, barley or triticale plantation, from other land-cover types. For this purpose, we extracted the NDVI temporal profile from the Sentinel-2 imageries for the three winter cereal crops (i.e., wheat, barley and triticale). Using the wheat NDVI values of each date of the eight dates, linear relationships were established between each date and the date that follows. The parameters resulted from those linear relationships were used to simulate NDVI images that allowed further to select wheat candidate segments (end of the first phase).</p><p>By referring to the NDVI temporal profile of the three winter cereal crops and following the application of several conditions, the second phase enables the selection of wheat segments from the others plantations (i.e., barley and triticale).</p><p>As we intended to train and validate <italic>SEWMA</italic> using different years, all reference wheat segments collected (<xref rid="sensors-18-02089-t002" ref-type="table">Table 2</xref>) were used for the training and validation processes. When <italic>SEWMA</italic> was trained with 2016 reference segments, the application was on 2017 Sentinel-2 (S2) images, and when trained with 2017 reference segments, the application was on 2016 Sentinel-2 (S2) images. Thus, 348 wheat segments were used to train year 2016, and 216 wheat segments were used to train year 2017. In the coming sections, we will be presenting a detailed description of each phase. A simplified flowchart of the methodology is illustrated in <xref ref-type="fig" rid="sensors-18-02089-f004">Figure 4</xref> below.</p><sec id="sec3dot2dot1-sensors-18-02089"><title>3.2.1. Identification of Wheat Candidate Segments: First Phase</title><p>Using the Sentinel-2 mean NDVI per wheat segment values, identified from the field campaigns (reference wheat segments) in 2016 and 2017, linear relationships of their NDVI values were established for each year between each two consecutive dates. In this study, we have used linear fitting because of the short-term data used. Moreover, in terms of NDVI real value, the development of wheat has proven to be predicted between two dates (<italic>t</italic> and <italic>t</italic> + 1) in a linear manner. This predictability was particularly essential because different wheat plots present different NDVI values through their development. With the usage of these relationships on different dates, segments could be eventually selected as wheat candidate segments (i.e., wheat, barley or triticale). The reference wheat NDVI linear relationship between each two consecutive dates (<italic>t</italic> and <italic>t</italic> + 1) is defined by:<disp-formula id="FD2-sensors-18-02089"><label>(2)</label><mml:math id="mm2"><mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>D</mml:mi><mml:mi>V</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="normal">a</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mi>N</mml:mi><mml:mi>D</mml:mi><mml:mi>V</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi mathvariant="normal">b</mml:mi></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>By using the linear relationships (slopes &#x0201c;a&#x0201d; and interceptions &#x0201c;b&#x0201d;), we simulate NDVI images <inline-formula><mml:math id="mm3"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>N</mml:mi><mml:mi>D</mml:mi><mml:mi>V</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> for each date of the Sentinel-2 <inline-formula><mml:math id="mm4"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>N</mml:mi><mml:mi>D</mml:mi><mml:mi>V</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> images. The slopes and interceptions deduced from the already produced linear relationships for each date used, are listed in the Results (<xref ref-type="sec" rid="sec4dot2-sensors-18-02089">Section 4.2</xref>).</p><p>To simulate NDVI images for the dates of 2016, &#x0201c;a&#x0201d; and &#x0201c;b&#x0201d; coefficients (<xref ref-type="sec" rid="sec4dot2-sensors-18-02089">Section 4.2</xref>) deduced from linear relationships (Equation (2)) of 2017 Sentinel-2 NDVI images were used, in addition to the Sentinel-2 NDVI images of 2016. Same is applied when simulating NDVI images for the dates of 2017. For each wheat reference segment, the following equation is applied:<disp-formula id="FD3-sensors-18-02089"><label>(3)</label><mml:math id="mm5"><mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>D</mml:mi><mml:mi>V</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="normal">a</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mi>N</mml:mi><mml:mi>D</mml:mi><mml:mi>V</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi mathvariant="normal">b</mml:mi></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>However, with a minimum coefficient of determination (R<sup>2</sup>) of 0.52, the application of these linear relationships could under- or over-estimate the probability of a segment being a candidate wheat plantation. In this context, the addition of a margin of error is required. After the production of the simulated NDVI images <inline-formula><mml:math id="mm6"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>N</mml:mi><mml:mi>D</mml:mi><mml:mi>V</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, we calculate the average Sentinel-2 NDVI <inline-formula><mml:math id="mm7"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>N</mml:mi><mml:mi>D</mml:mi><mml:mi>V</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> as well as the average simulated NDVI <inline-formula><mml:math id="mm8"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>N</mml:mi><mml:mi>D</mml:mi><mml:mi>V</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> for each reference segment of each date in both years of study. Then, the difference between the average simulated NDVI <inline-formula><mml:math id="mm9"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>N</mml:mi><mml:mi>D</mml:mi><mml:mi>V</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> value and the average Sentinel-2 NDVI <inline-formula><mml:math id="mm10"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>N</mml:mi><mml:mi>D</mml:mi><mml:mi>V</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> value was calculated for each reference segment in all dates of both years.</p><p>For each reference segment, the difference (Diff) is produced between simulated NDVI and S2 NDVI values, in each date of each year, as follows:<disp-formula id="FD4-sensors-18-02089"><label>(4)</label><mml:math id="mm11"><mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>N</mml:mi><mml:mi>D</mml:mi><mml:mi>V</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>N</mml:mi><mml:mi>D</mml:mi><mml:mi>V</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>D</mml:mi><mml:mi>V</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>&#x000d7;</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>After the calculation of the differences between simulated NDVI and Sentinel-2 NDVI of each reference segment in each date of each year, we calculate both the average &#x003bc;(<italic>t</italic>) and the standard deviation &#x003c3;(<italic>t</italic>) of the obtained differences, for each date. Using &#x003bc;(<italic>t</italic>) and &#x003c3;(<italic>t</italic>) of the differences among the dates, and to ensure the highest accuracy with least over- and under-estimations, three thresholds were selected as follow: (1) [&#x003bc; + <italic>1</italic>&#x003c3;]; (2) [&#x003bc; + <italic>1.5</italic>&#x003c3;]; and (3) [&#x003bc; + <italic>2</italic>&#x003c3;], for each year. These thresholds are seen as the margin of errors used. The difference of wheat reference segments when using the three thresholds for both years are illustrated in box plots in the Results (<xref ref-type="sec" rid="sec4dot2-sensors-18-02089">Section 4.2</xref>). The most adequate threshold should have the highest accuracy in determining the wheat segments. It will be defined following the implementation of <italic>SEWMA</italic> (<xref ref-type="sec" rid="sec4dot3-sensors-18-02089">Section 4.3</xref>) through the production of confusion matrices for each selected threshold. Nonetheless, for now, these three thresholds should be used.</p><p>In each year (2016 and 2017), the highest [&#x003bc;(<italic>t</italic>) + <italic>n</italic>&#x003c3;(<italic>t</italic>)] value among the dates was chosen to represent the threshold of its corresponding year, where <italic>n</italic> is either 1, 1.5 or 2 depending on the chosen threshold. For instance, when using the threshold &#x003bc;(<italic>t</italic>) + <italic>1.5</italic>&#x003c3;(<italic>t</italic>), its value on date 4 in 2016 (6th of April) was the highest (27%), thus, 27% was assigned as a threshold produced by 2016 wheat reference segments. A criterion now has to be met; at least in three out of the first six dates (DOY 47 through 137 for 2016 and DOY 41 through 131 for 2017), segmented areas should have a difference (Diff) between simulated NDVI and S2 NDVI within the chosen threshold. If so, the segment is then considered as potential wheat cultivation. The later could also pinpoint at barley or triticale segments. The other segments are eliminated and not considered in the further processing steps. As a result, the output of the first phase is the identification of wheat candidate segments.</p></sec><sec id="sec3dot2dot2-sensors-18-02089"><title>3.2.2. Identification of Wheat Segments: Second Phase</title><p>By referring to the NDVI temporal profile analysis (<xref ref-type="sec" rid="sec4dot1-sensors-18-02089">Section 4.1</xref>), it was found that barley can be distinguished from wheat on DOY 107 through 117 in 2016 and DOY 131 in 2017. While these periods generally highlight the anthesis of wheat, the NDVI average value for barley segments is generally lower than the NDVI average value for wheat cultivation. The difference between barley and wheat in terms of mean NDVI could be justified in terms of water availability/uptake since wheat is supplementary irrigated during the season, whereas, barley is generally a rain-fed cultivation [<xref rid="B38-sensors-18-02089" ref-type="bibr">38</xref>].</p><p>If a segment&#x02019;s mean NDVI is less than the total average NDVI plus the standard deviation of barley reference segments in anthesis, then it is considered as barley plantation and thus eliminated. As for triticale, and by consulting the NDVI temporal profile analysis (<xref ref-type="sec" rid="sec4dot1-sensors-18-02089">Section 4.1</xref>), on DOY 137 in 2016 and 151 in 2017, a huge drop of NDVI average value is shown. While these dates correspond to the harvesting period of triticale, thus rendering lands without vegetation cover and very low NDVI, the NDVI values for triticale plots are generally much lower than the NDVI values for wheat cultivation. Accordingly, if the difference between the date corresponding to anthesis and the date afterwards (<italic>t</italic> + 1) is lower than 70% (value set upon our observations on 645 wheat and triticale reference segments), at segment level, then this segment is classified as wheat. The others reflect triticale cultivated segments and thus eliminated. Therefore, the output of the second phase is the identification of wheat segments relying on the NDVI real values. In that event, after selecting the candidate segments (at the end of phase one) and the elimination of barley and triticale segments (at the end of phase two), wheat segments are then identified for both 2016 and 2017 years. It is important to note that the proposed approach was established by 2016 datasets and validated through 2017 datasets, and vice versa, using three thresholds (i.e., (1) &#x003bc; + <italic>1</italic>&#x003c3;; (2) &#x003bc; + <italic>1.5</italic>&#x003c3;; and (3) &#x003bc; + <italic>2</italic>&#x003c3;) as mentioned above.</p></sec><sec id="sec3dot2dot3-sensors-18-02089"><title>3.2.3. Validation</title><p>Accuracy assessments were done to evaluate the classification approach presented in this study. Since the classification approach for 2016 was done by relying on 2017 ground truth data (GTD) to calibrate it, and vice versa, we had to test the overall accuracy of 2016 classification using 2016 GTD and for 2017 using 2017 GTD. For this purpose, wheat segments collected from 2016 were used to validate year 2016, and wheat segments collected in 2017 were used to validate year 2017. As to run the confusion matrix, wheat and non-wheat segments were needed. Same number as wheat segments was chosen for non-wheat segments. For 2017 classification, we had 348 wheat segments, thus an equivalent number of non-wheat segments were randomly chosen from the whole area of study so that the total number of segments to run the confusion matrix of 2017 was 696 consisting of 50% wheat segments and 50% non-wheat segments. Same for 2016, the total number of segments used was 432, consisting of 50% wheat segments and 50% non-wheat segments.</p></sec></sec></sec><sec id="sec4-sensors-18-02089"><title>4. Results</title><p>In this section, we report the results of the proposed method. The obtained temporal profiles of the crops analyzed are presented in this section (<xref ref-type="sec" rid="sec4dot1-sensors-18-02089">Section 4.1</xref>). In addition, the preliminary results deduced from the first phase of <italic>SEWMA</italic> generation are also illustrated (<xref ref-type="sec" rid="sec4dot2-sensors-18-02089">Section 4.2</xref>). The accuracy assessment is reported for both years (<xref ref-type="sec" rid="sec4dot3-sensors-18-02089">Section 4.3</xref>) as well as the spatial distribution of wheat plots (<xref ref-type="sec" rid="sec4dot4-sensors-18-02089">Section 4.4</xref>).</p><sec id="sec4dot1-sensors-18-02089"><title>4.1. Crops&#x02019; Temporal Profiles</title><p><xref ref-type="fig" rid="sensors-18-02089-f005">Figure 5</xref> and <xref ref-type="fig" rid="sensors-18-02089-f006">Figure 6</xref> represent the mean &#x000b1; standard deviation of <italic>&#x003c1;</italic>NIR and <italic>&#x003c1;</italic>RED temporal profiles. The mean and the standard deviation values for the crops below (<xref ref-type="fig" rid="sensors-18-02089-f005">Figure 5</xref> and <xref ref-type="fig" rid="sensors-18-02089-f006">Figure 6</xref>) were extracted from the Sentinel-2 images for each date in each year (i.e., 2016 and 2017).</p><p>By analyzing the differences among years, up to the third date, corresponding to heading stage (DOY 97/2016 and 101/2017), the three cereal cultivars (i.e., wheat, barley and triticale) have higher reflectance in the NIR band in 2016 than 2017 and lower reflectance in the RED band in 2016 than 2017 (<xref ref-type="fig" rid="sensors-18-02089-f005">Figure 5</xref>). Among crops, wheat and triticale experienced a very similar behavior in terms of reflectance in both bands and years until the date when triticale was harvested (DOY 137/2016 and 151/2017). Whereas for barley, the reflectance in the NIR band was significantly lower than that of wheat and triticale for DOY 107-117/2016 and 131/2017, and the reflectance in the RED band was significantly higher than the reflectance in the RED band for wheat and triticale for DOY 131/2017.</p><p>In order to make sure there was no classification confusion between the three main cereal crops (wheat, barley and triticale) and other crops that share part of their seasons, <italic>&#x003c1;</italic>NIR and <italic>&#x003c1;</italic>RED were analyzed for spring potato and spring vegetables (<xref ref-type="fig" rid="sensors-18-02089-f006">Figure 6</xref>).</p><p>As the sowing dates of spring potato and spring vegetables do not occur before March, the reflectance values in the RED and NIR bands were close to each other (<xref ref-type="fig" rid="sensors-18-02089-f006">Figure 6</xref>). For spring potato, after the sowing date in March, the reflectance in the NIR began to increase (DOY 87/2016 and 101/2017) reaching the peak of around 0.55 in DOY 137/2016 and 0.65 in DOY 151/2017. Nevertheless, the reflectance in the RED band also started experiencing a change and decreased to reach its minimum of around 0.04 in DOY 137/2016 and 151/2017 corresponding to the potato full flowering stage.</p><p>As for spring vegetables, reflectance in the RED and NIR did not start to change before DOY 97/2016 and 101/2017 (<xref ref-type="fig" rid="sensors-18-02089-f006">Figure 6</xref>). For the reflectance in the NIR band, the maximum was reached in DOY 137/2016 (0.35) and DOY 151/2017 (0.42). As for the reflectance in the RED, the minimum was reached in the same dates of 0.07 and 0.03 in 2016 and 2017 respectively. </p><p>The time profile of the NDVI with respect to time (dates of the available images) was constructed and analyzed for the three main cereal crops (i.e., wheat, barley and triticale) in addition to spring potato and spring vegetables during the two years of study (2016 and 2017). The evolution of NDVI along both cropping seasons for the three main crops is shown in <xref ref-type="fig" rid="sensors-18-02089-f007">Figure 7</xref>, representing the mean &#x000b1; standard deviation of NDVI temporal profiles.</p><p><xref ref-type="fig" rid="sensors-18-02089-f007">Figure 7</xref> clearly shows that the NDVI behavior during 2016 and 2017 of the cereal crops is not the same throughout the cropping season. The temporal profiles of the three main cereal classes (wheat, barley and triticale) during both years (<xref ref-type="fig" rid="sensors-18-02089-f007">Figure 7</xref>a,b) show the crop evolution after emergence through maturity (wheat and barley) and harvesting (triticale). In 2016 (<xref ref-type="fig" rid="sensors-18-02089-f007">Figure 7</xref>a), the three classes finished the vegetative growth and reached anthesis in DOY 107. After that, wheat and barley started their maturation stage in DOY 137 while triticale was already harvested to be sold for fodder use. In 2017 (<xref ref-type="fig" rid="sensors-18-02089-f007">Figure 7</xref>b), the dormancy stage was relatively longer than 2016 (<xref ref-type="fig" rid="sensors-18-02089-f007">Figure 7</xref>a), which led to a different temporal profile, and anthesis was reached between DOY 111 and DOY 131. According to the NDVI images corresponding to the anthesis stage of both years, barley&#x02019;s NDVI was significantly lower than wheat&#x02019;s NDVI. As for spring potato and spring vegetables, indeed these two classes share some of their crop cycle with the three main cereal crops. As they are sowed between end of February and start of March, they start to witness an increase in their NDVI starting DOY 97 in 2016 and DOY 101 in 2017, thus, they are easily separated and do not actually interfere in our classification of winter wheat.</p></sec><sec id="sec4dot2-sensors-18-02089"><title>4.2. SEWMA First Phase Preliminary Results</title><p>Through the first phase of <italic>SEWMA</italic> generation, linear relationships of wheat reference segments&#x02019; NDVI values were established for each year between each two consecutive dates (Equation (2)). The output parameters (slopes &#x0201c;a&#x0201d; and interceptions &#x0201c;b&#x0201d;) are listed in <xref rid="sensors-18-02089-t003" ref-type="table">Table 3</xref>, which were used to simulate NDVI images (<xref ref-type="sec" rid="sec3dot2dot1-sensors-18-02089">Section 3.2.1</xref>) using Equation (3).</p><p>Through the identification of wheat candidate segments (<xref ref-type="sec" rid="sec3dot2dot1-sensors-18-02089">Section 3.2.1</xref>), and after NDVI images were simulated depending on the parameters presented in <xref rid="sensors-18-02089-t003" ref-type="table">Table 3</xref> above, the differences between Sentinel-2 and simulated NDVI values versus thresholds assigned are presented in <xref ref-type="fig" rid="sensors-18-02089-f008">Figure 8</xref>.</p><p>As (Diff) (Equation (4)) reflects the difference between simulated NDVI and Sentinel-2 NDVI, the differences of wheat reference segments (<xref ref-type="fig" rid="sensors-18-02089-f008">Figure 8</xref>) could be either positive or negative. For this reason, the threshold is expressed above positively and negatively.</p></sec><sec id="sec4dot3-sensors-18-02089"><title>4.3. SEWMA Accuracy Assesment</title><p>The approach accuracy assessment was produced for the three thresholds (i.e., &#x003bc; + <italic>1</italic>&#x003c3;, &#x003bc; + <italic>1.5</italic>&#x003c3; and &#x003bc; + <italic>2</italic>&#x003c3;) (<xref rid="sensors-18-02089-t004" ref-type="table">Table 4</xref>). It clearly shows that the implementation of the 2016 approach on 2017 generates a higher accuracy from, inversely, applying the 2017 approach on 2016. Also, according to this same table, the best accuracy was noted in the second threshold used (i.e., &#x003bc; + <italic>1.5</italic>&#x003c3;).</p><p>A confusion matrix was presented for the second threshold (i.e., &#x000b5; + <italic>1.5</italic>&#x003c3;) (<xref rid="sensors-18-02089-t005" ref-type="table">Table 5</xref> and <xref rid="sensors-18-02089-t006" ref-type="table">Table 6</xref>). By using the 2016 trained wheat approach classification on 2017, the overall accuracy reached 82.6%. When applying the 2017 trained wheat approach classification on 2016, the overall accuracy reached 87.0%.</p></sec><sec id="sec4dot4-sensors-18-02089"><title>4.4. Wheat Spatial Distribution</title><p><xref rid="sensors-18-02089-t007" ref-type="table">Table 7</xref> shows the wheat cultivated areas in the Bekaa plain estimated based on the reference sample data, with 95% confidence interval according to [<xref rid="B39-sensors-18-02089" ref-type="bibr">39</xref>], in addition to wheat areas declared by the Lebanese government. Wheat cultivated areas below present a decrease from 2016 to 2017. This area is densely distributed in the center and to the southern part of the study site (<xref ref-type="fig" rid="sensors-18-02089-f009">Figure 9</xref>). Crop rotation is also noticeable in comparison among the plots (<xref ref-type="fig" rid="sensors-18-02089-f009">Figure 9</xref>).</p><p>According to the wheat spatial distribution in <xref ref-type="fig" rid="sensors-18-02089-f009">Figure 9</xref>, cultivation of wheat was denser in the south west of the plain comparing to the northern part, as water is more available, thus more compatible to irrigation management. Rotation is also visible as most farmers follow the traditional potato-wheat rotation. However, A number of plots have witnessed wheat cultivation in the two consecutive years (2016 and 2017) occupying up to 28% of plots cultivated in monoculture each year.</p></sec></sec><sec id="sec5-sensors-18-02089"><title>5. Discussion</title><sec id="sec5dot1-sensors-18-02089"><title>5.1. Crops&#x02019; Temporal Profiles</title><p>Winter wheat, which was classified in this study, is sown in November, similar to other winter cereals (i.e., barley and triticale). The winter cereals (i.e., wheat, barley and triticale) go through successive phenological stages during the cropping season, which are reflected in the NDVI temporal profiles.</p><p>In each year (<xref ref-type="fig" rid="sensors-18-02089-f007">Figure 7</xref>), the winter cereals (i.e., wheat, barley and triticale) showed similar evolution in terms of NDVI until the vegetative growth was almost over (anthesis period), where the peak NDVI value is reached. Generally, irrigated crops have been found to have a higher peak NDVI values and maintain a higher NDVI during each crop&#x02019;s growth cycle than non-irrigated crops [<xref rid="B13-sensors-18-02089" ref-type="bibr">13</xref>]. By the end of March, one supplementary irrigation had been already applied earlier that month to wheat and triticale. Due to this, wheat and triticale&#x02019;s NDVI values rise to get closest to 1, whereas barleys&#x02019; NDVI values become significantly separable. By referring to <xref ref-type="fig" rid="sensors-18-02089-f005">Figure 5</xref>, this finding was reflected in the NIR and Red bands results. On DOY 107 through 117, barley exhibited a significant lower reflectance in the NIR band than wheat and triticale and a slightly higher reflectance in the visible (Red) band. As previously mentioned, the less leaf water content in barley than wheat and triticale could be responsible for such a drop [<xref rid="B40-sensors-18-02089" ref-type="bibr">40</xref>].</p><p>After the flowering period, when triticale reaches maximum vegetative growth, farmers rush to harvest the triticale-cultivated plots before maturation kicks in. For this reason, triticale plots witness a sharp drop in their NDVI values due to harvesting event, thus triticale becomes significantly distinguishable. On further justification to such finding in the NDVI temporal profile (<xref ref-type="fig" rid="sensors-18-02089-f007">Figure 7</xref>), referring to <xref ref-type="fig" rid="sensors-18-02089-f005">Figure 5</xref>e,f, when harvesting triticale, the gap between the reflectance of Red and NIR bands is minimized. On one hand, the reflectance in the NIR decreased as the green cover is cut, thus the leaf water content is diminished, while on the other hand, the reflectance in the visible Red band increased because the contribution of chlorophyll pigments in the absorption in the Red band is significantly reduced, due to the harvesting event [<xref rid="B29-sensors-18-02089" ref-type="bibr">29</xref>,<xref rid="B41-sensors-18-02089" ref-type="bibr">41</xref>].</p><p>As for the other analyzed crops (i.e., spring vegetables and spring potato), their sowing date is in March. Spring vegetables and spring potato start their vegetative development in spring, yet their NDVI does not reach high levels as they do not fully cover the soil. According to the NDVI temporal profiles (<xref ref-type="fig" rid="sensors-18-02089-f007">Figure 7</xref>), spring vegetables and spring potato could be significantly separable from the three winter cereals. Referring to <xref ref-type="fig" rid="sensors-18-02089-f006">Figure 6</xref> can explain such response. The increase in NDVI (<xref ref-type="fig" rid="sensors-18-02089-f007">Figure 7</xref>) during the spring is related to the increase in NIR reflectance (due to increase in leaf water content), and the decrease in the visible Red reflectance (due to the increase in leaf chlorophyll pigments) (<xref ref-type="fig" rid="sensors-18-02089-f006">Figure 6</xref>) [<xref rid="B41-sensors-18-02089" ref-type="bibr">41</xref>].</p><p>The standard deviation of the winter cereals was higher in the beginning of the season, probably due to different germination rates [<xref rid="B29-sensors-18-02089" ref-type="bibr">29</xref>] and decreased gradually through reaching the anthesis stage. When anthesis stage is reached, the canopies reach their maximum height as vegetative growth stops when flowering occurs [<xref rid="B29-sensors-18-02089" ref-type="bibr">29</xref>]. By the end of the vegetative growth, maximum leaf area is reached, which was reflected in the NDVI temporal profile [<xref rid="B29-sensors-18-02089" ref-type="bibr">29</xref>,<xref rid="B42-sensors-18-02089" ref-type="bibr">42</xref>]. This difference in germination rates could be due to sowing date [<xref rid="B43-sensors-18-02089" ref-type="bibr">43</xref>], variation in soil conditions [<xref rid="B44-sensors-18-02089" ref-type="bibr">44</xref>], wheat varieties [<xref rid="B45-sensors-18-02089" ref-type="bibr">45</xref>] and/or climate [<xref rid="B46-sensors-18-02089" ref-type="bibr">46</xref>]. For spring vegetables and spring potato, during the first three dates, the standard deviation was low as the crops were not germinated before April. After germination, the standard deviation increased as different varieties of different crops were grouped together [<xref rid="B45-sensors-18-02089" ref-type="bibr">45</xref>].</p><p>According to the Lebanese Agricultural Research Institute (LARI), both years were climatically different as winter season in 2017 was colder than 2016. This was obviously reflected in the NDVI temporal profiles. In 2017, by the end of February, the winter cereals&#x02019; NDVI had not reached 0.6, whereas by that time in 2016, winter cereals&#x02019; NDVI have had reached higher values already (<xref ref-type="fig" rid="sensors-18-02089-f007">Figure 7</xref>). Such response in the NDVI reflectance is basically related to the dormancy period [<xref rid="B47-sensors-18-02089" ref-type="bibr">47</xref>] which was relatively shorter in 2016 than in 2017.</p></sec><sec id="sec5dot2-sensors-18-02089"><title>5.2. SEWMA First Phase Preliminary Results</title><p>In the proposed approach, we did use linear fitting between each two adjacent dates (i.e., <italic>t</italic> and <italic>t</italic> + 1). The linear fitting between each two consecutive dates produced slopes and interceptions (<xref rid="sensors-18-02089-t003" ref-type="table">Table 3</xref>), which were used afterwards to simulate NDVI images. Due to variability in weather conditions and imaging dates, curve-fittings classifiers cannot be trained and applied on different years [<xref rid="B48-sensors-18-02089" ref-type="bibr">48</xref>]. As <italic>SEWMA</italic> was built using short-term data, linear fitting was used rather than harmonic analysis, as the latter is suggested, when detecting changes in land use/land cover over a period of years is necessary [<xref rid="B49-sensors-18-02089" ref-type="bibr">49</xref>].</p><p>In addition, smoothed temporal profile (e.g., moving window method) used in curve-fittings [<xref rid="B21-sensors-18-02089" ref-type="bibr">21</xref>] might produce a curve that do not represent only wheat plots, but also other cultivations. Moreover, we did find that a date (<italic>t</italic> + 1) could be predicted from date (<italic>t</italic>), which reflects that the development of the wheat could be predictable with high accuracy in different wheat parcels and in diverse climate and regions presented in our study area.</p><p>Predicting NDVI<italic><sub>t</sub></italic><sub>+1</sub> from NDVI<italic><sub>t</sub></italic> could under- or over-estimate the probability of a segment being a candidate wheat plantation. In this context, the addition of a margin of error was required, by setting thresholds (<xref ref-type="fig" rid="sensors-18-02089-f008">Figure 8</xref>), which could be avoided when using curve-fitting techniques [<xref rid="B48-sensors-18-02089" ref-type="bibr">48</xref>]. The choice of the selected threshold is discussed in the following section (<xref ref-type="sec" rid="sec5dot3-sensors-18-02089">Section 5.3</xref>).</p></sec><sec id="sec5dot3-sensors-18-02089"><title>5.3. SEWMA Accuracy Assessment</title><p><italic>SEWMA</italic> was run in parallel using the three thresholds (i.e., &#x003bc; + <italic>1</italic>&#x003c3;, &#x003bc; + <italic>1.5</italic>&#x003c3; and &#x003bc; + <italic>2</italic>&#x003c3;) and &#x003bc; + <italic>1.5</italic>&#x003c3; showed the highest final overall accuracy (<xref rid="sensors-18-02089-t004" ref-type="table">Table 4</xref>), thus &#x003bc; + <italic>1.5</italic>&#x003c3; was adopted. &#x003bc; + <italic>1.5</italic>&#x003c3; threshold allowed us to select the wheat candidate segments (after the first phase) with less under estimation than &#x003bc; + <italic>1</italic>&#x003c3; and less over estimation than &#x003bc; + <italic>2</italic>&#x003c3;. </p><p>The underestimation of wheat classification that occurred when applying 2016 linear relationships on 2017 was mainly for two reasons. First, since the threshold was produced by 2016 ground truth data, few wheat segments did not cross the first phase of the approach, as they exceeded the threshold set in more than 3 dates. The difference in climate among the two years (2016 and 2017) was reflected via the NDVI profiles, hence these few segments were not considered as candidate segments and eliminated after the first phase. Second, during the second phase of the approach, the mean NDVI of reference barley segments plus the standard deviation at the anthesis period (DOY 117 of 2016) used to designate barley segments, was around 0.84 (<xref ref-type="fig" rid="sensors-18-02089-f007">Figure 7</xref>a). Thereby, some wheat segments were removed. This elimination is mainly related to the fact that the year 2017 was a cold and wet year, and since the season of wheat was longer than that in 2016, the NDVI of some wheat segments in 2017 was lower than that in 2016 during anthesis (DOY 117/2016 and 131/2017).</p><p>As shown in <xref ref-type="fig" rid="sensors-18-02089-f008">Figure 8</xref>d (2017 by 2016), since the dormancy period was longer in 2017 than 2016, one date (date 3) was completely out of the threshold borders. In date 3/2017 wheat was still through the dormancy stage (cumulative Growth Degree Days did not exceed 300 &#x000b0;C) and the NDVI did not exceed 0.45, while in date 3 of 2016, wheat&#x02019;s NDVI has had reached 0.9 already (cumulative Growth Degree Days exceeded 450 &#x000b0;C) [<xref rid="B30-sensors-18-02089" ref-type="bibr">30</xref>]. If unlike our case, both years were climatically similar, less wheat segments will be eliminated after the first phase of the approach.</p><p>When the approach was trained by 2017 ground truth data, the overall accuracy showed 82.6% when validated on 2016 images. The decrease in the overall accuracy was basically due to selecting some barley segments as wheat. This is because the classification was trained by 2017 GTD. As we refer to <xref ref-type="fig" rid="sensors-18-02089-f007">Figure 7</xref>a, in DOY 117, some barley segments had NDVI above 0.8.</p><p>Winter wheat plantations at the Bekaa plain receive some supplementary irrigation during the spring-early summer season, hence their NDVI reaches higher level than barley during the anthesis period. However, if some growers cultivate wheat with no supplementary irrigation (due to water shortage), such wheat segments would have similar NDVI values as barley and could be eliminated through phase two of <italic>SEWMA</italic>.</p><p>Our overall accuracies were satisfactory, similar to other previous studies, aiming at mapping winter crops [<xref rid="B13-sensors-18-02089" ref-type="bibr">13</xref>,<xref rid="B50-sensors-18-02089" ref-type="bibr">50</xref>,<xref rid="B51-sensors-18-02089" ref-type="bibr">51</xref>], especially early-season classification [<xref rid="B22-sensors-18-02089" ref-type="bibr">22</xref>,<xref rid="B23-sensors-18-02089" ref-type="bibr">23</xref>]. Discriminating winter wheat from other winter cereal crops especially barley, as proposed by our approach is highly challenging, as it was shown in a previous study, where accuracy dropped to below 70% when cereals were ungrouped and winter wheat was discriminated from barley [<xref rid="B22-sensors-18-02089" ref-type="bibr">22</xref>].</p><p>The difference in accuracy among both years (i.e., 2016 and 2017) is attributable to several reasons: (1) different number of training segments (plots or sub-plots); (2) different climatic conditions among the two years and (3) slightly different shift in the dates of available Sentinel-2 images.</p></sec><sec id="sec5dot4-sensors-18-02089"><title>5.4. Wheat Spatial Distribution</title><p>As wheat growth, tillering, biomass and grain yield are highly affected by soil moisture [<xref rid="B52-sensors-18-02089" ref-type="bibr">52</xref>,<xref rid="B53-sensors-18-02089" ref-type="bibr">53</xref>], the dominance of wheat segments at the western-southern part of the plain is due to the higher availability of water in a cooler climate, thus allowing wheat&#x02019;s root system to proliferate horizontally and vertically for water extraction, benefiting from the fact that the water table is relatively shallow. Contrariwise, at the upper part of the plain, farmers generally prefer to cultivate barley or other crops that do not require any supplementary irrigation during the winter season.</p><p>To assess whether the change in areas between 2016 and 2017 was significant or error related, we followed the approach proposed by Olofsson et al. [<xref rid="B38-sensors-18-02089" ref-type="bibr">38</xref>]. The approach relies basically on accuracy assessment sample data, in addition to the area proportions of each class, to eventually estimate the area of classified classes &#x000b1; the standard error, with 95% confidence of interval. Referring to the areas of each year (<xref rid="sensors-18-02089-t007" ref-type="table">Table 7</xref>), it appears that the wheat areas have significantly decreased between 2016 and 2017.</p><p>The decrease in areas is basically related to the rotation system (i.e., simple potato-wheat rotation) applied by most farmers in the plain. Thus, we expect an increase of these areas in 2018. Nevertheless, a change in the subsidy policy could discourage farmers from cultivating wheat in the future and could also be a reason behind the decrease in wheat cultivated area from 2016 through 2017. Actually, since 2016, the government has stopped purchasing the wheat production, instead, the Ministry of Economy (MoE) subsidizes farmers only by cultivated area with relatively small monetary amounts (800 USD/hectare), which barely cover the cultivation costs. The other constraint that farmers are facing is that Syrian borders are closed due to the ongoing Syrian civil war, which prevents them from exporting their production. While on the other hand, the Lebanese government is still importing wheat grains without any pre-consideration of the market needs leading to a fully saturated local market. For this reason, the deterioration of the unsold wheat production is never encouraging farmers to grow wheat throughout the coming years.</p><p>A comparison of the wheat areas obtained by <italic>SEWMA</italic> to those estimated by the Lebanese government (<xref rid="sensors-18-02089-t007" ref-type="table">Table 7</xref>) illustrates a similarity in the obtained numbers. To be more specific, the government&#x02019;s estimations rely on wheat farmers who declare that they cultivated wheat to benefit from the subsidy program, which is followed by field inspections. It is important to note that some wheat farmers do not give notice to the government, thus are not included in the governmental statistics. The difference between the areas estimated by <italic>SEWMA</italic> and those reported by the Lebanese government could be caused by several technical and human-related errors. First, discriminating triticale from wheat lands visually is generally difficult, even for specialized personnel. Second, fake reports could be submitted by farmers claiming that they have cultivated wheat, coupled with an impossibility of the corresponding teams to access their lands for field verification. Third, the estimations have started in 2016, thus, many farmers in that year have faced complications in submitting applications regarding their cultivated areas.</p><p>Although it is never recommended to avoid rotation, there is a number of plots that witnessed wheat cultivation in two consecutive years (2016 and 2017) (<xref ref-type="fig" rid="sensors-18-02089-f009">Figure 9</xref>). Because other crops are not supported (e.g., potato, vegetables and legumes), poor farmers who rent lands in order to maintain their livelihood tend to avoid the risk of growing other crops and keep cultivating wheat in monoculture despite the risk of soil borne diseases, knowing in advance that they will be subsidized by the government. </p><p>The proposed method has allowed the mapping of winter wheat throughout 2016 and 2017. The outcome has proved that year-to-year transfer of knowledge is possible, if the evolution of a certain crop is well understood. Nevertheless, discriminating winter wheat among other winter cereal crops (i.e., barley and triticale) is doable using remotely-sensed data, in addition to ground observations.</p></sec><sec id="sec5dot5-sensors-18-02089"><title>5.5. Strengths, Limitations and Future Directions</title><p>The proposed method, Simple and Effective Wheat Mapping Approach (<italic>SEWMA</italic>), has proven to be successful in predicting wheat spatial distribution in the Bekaa plain of Lebanon for the years 2016 and 2017. </p><p><italic>SEWMA</italic> appears to have several strong points; (1) it only requires limited number of satellite imageries datasets in one single season for executing the classification, an option highly crucial in a developing country such as Lebanon; (2) it discriminates wheat from other similar winter cereals (i.e., barley and triticale) with only few field campaigns required; (3) it produces accurate (87%) early outputs in an automated way, thus saving resources and time.</p><p>In the same context, application of <italic>SEWMA</italic> is technically simple and easy to implement. However, it is site dependent and some requirements have to be met. For instance, replicating <italic>SEWMA</italic> in different regions may be affected by climate, farming conditions, agricultural practices and crop calendar. Concerning this, avoiding field visits in a new study site may result in critical drawbacks and unsatisfactory results.</p><p>Distinguishing winter wheat from barley and triticale could not be well achieved if the key phenological dates were not well known, particularly anthesis. In addition, irrigation practices were very important to deriving the conditions applied in the second phase of <italic>SEWMA</italic>. As previously mentioned (<xref ref-type="sec" rid="sec5dot3-sensors-18-02089">Section 5.3</xref>), wheat plots that are not irrigated due to shortage in water, could be susceptible to elimination, in addition to barley plots, during the second phase of <italic>SEWMA</italic>.</p><p>As reported in Sentinel-2 data quality report in 2018 [<xref rid="B54-sensors-18-02089" ref-type="bibr">54</xref>], Sentinel-2A images before 15 June 2016 stem registration errors, due to three main contributors: (a) dynamic vibrations residuals mainly related to on-board oscillations; (b) static LOS calibration residuals; and (c) correlation noise and outliers. Thus, several previous studies [<xref rid="B55-sensors-18-02089" ref-type="bibr">55</xref>,<xref rid="B56-sensors-18-02089" ref-type="bibr">56</xref>,<xref rid="B57-sensors-18-02089" ref-type="bibr">57</xref>] have shown a mis-registration between multi-temporal Sentinel-2A images from the same and different orbits for images acquired in 2016. To tackle the issue, we tried to visually investigate that matter by using the &#x0201c;chessboard&#x0201d; approach proposed by Shakun et al. [<xref rid="B56-sensors-18-02089" ref-type="bibr">56</xref>] as well as the qualitative visual registration assessment described in [<xref rid="B58-sensors-18-02089" ref-type="bibr">58</xref>]. In addition, an open source software based on Yan et al. [<xref rid="B58-sensors-18-02089" ref-type="bibr">58</xref>] was used to quantify the occurred shifting in the x and y directions. The average mis-registration on the whole Sentinel-2 tile between 2016 and 2017 was around 0.068 &#x000b1; 0.13 &#x000d7; 10 m in the x direction and 0.128 &#x000b1; 0.263 &#x000d7; 10 m in the y direction. When quantifying the mis-registration on our study site, the shifting decreased to an average of 0.028 &#x000b1; 0.1 &#x000d7; 10 m in the x direction and 0.034 &#x000b1; 0.1 &#x000d7; 10 m in the y direction. It could be related to the location of our study area at the center of the Sentinel 2A tile (<xref ref-type="fig" rid="sensors-18-02089-f001">Figure 1</xref>) and far from the swath edges [<xref rid="B55-sensors-18-02089" ref-type="bibr">55</xref>]. For future studies, an open source software [<xref rid="B58-sensors-18-02089" ref-type="bibr">58</xref>,<xref rid="B59-sensors-18-02089" ref-type="bibr">59</xref>] designed for mis-registration quantifications and corrections is recommended. These approaches are particularly needed when combining different sensors such as Landsat 8 and Sentinel-2 datasets.</p><p>As cloudy images are always a drawback when working with optical satellites, the availability of cloud-free datasets, or further pre-processing, is always recommended. Several algorithms have been proposed (e.g., Mean Attribute, Most Common Attribute value and k-nearest neighbor imputation) to fill the data lost by cloud removal [<xref rid="B60-sensors-18-02089" ref-type="bibr">60</xref>]. The decision on whether to apply those algorithms, and which to choose amongst, is highly dependent on climatic and environmental conditions, as well as the purpose of use.</p><p>Furthermore, since Sentinel-2B was not launched before March, 2017, we could not benefit from its data for our study, otherwise, temporal resolution could be maximized (5-days) and more images could have been available. As other previous studies have proven, the usage of both optical and radar images would improve the classification, especially when pilot areas are covered with clouds [<xref rid="B18-sensors-18-02089" ref-type="bibr">18</xref>,<xref rid="B19-sensors-18-02089" ref-type="bibr">19</xref>]. The performance of <italic>SEWMA</italic> was tested on the Bekaa plain of Lebanon, which is a semi-arid climatic region. Hence, for future studies, including other climatic regions and enlarging the sampling data would generate better outputs. However, with a total accuracy of 87%, our proposed approach could be implemented across the Bekaa region and in similar climatic areas.</p></sec></sec><sec id="sec6-sensors-18-02089"><title>6. Conclusions</title><p>A novel wheat classification tree-like approach was presented in this study. Combining remote sensing with field observations allowed us to classify wheat throughout 2016 and 2017 four to six weeks prior to harvest which is highly important for any country with subsidy system. Moreover, the proposed approach, surnamed <italic>SEWMA</italic>, showed high accuracy in identifying wheat segments (87% in 2016 and 82.6% in 2017) even in climatically different years and with the existence of several crops with similar NDVI yearly profiles.</p><p>Wheat area decreased from 11,063 &#x000b1; 1309 ha in 2016 to 7605 &#x000b1; 1184 in 2017 due to different reasons including; (1) agricultural practices; (2) corrupt subsidy policies; (3) the Syrian war and (4) marketing policies. As for the spatial distribution of wheat in the area of study, we found that wheat cultivations were denser in areas with more available water and shallower water table (i.e., south-west Bekaa plain) to secure supplemental irrigation. </p><p>Increasing the sustainability of water use and improved water productivity are some of the very essential goals of the Sustainable Development Goals (SDG). <italic>SEWMA</italic> in this sense plays a very effective role as its output allows forecasting the areas cultivated to allow controlling and sustainably managing wheat crops in food insecure countries. <italic>SEWMA</italic> is then an important tool that can be recommended for the monitoring of cultivated areas and assessment of expected yield by decision makers, food producers and trade managers, which could be integrated within the national and regional agricultural financial support systems.</p></sec></body><back><ack><title>Acknowledgments</title><p>The authors would like to acknowledge the European Space Agency (ESA) for providing the Sentinel-2 satellite datasets.</p></ack><notes><title>Author Contributions</title><p>Conceptualization, A.N., G.F. and T.D.; Data curation, A.N.; Formal analysis, N.B.; Methodology, A.N., M.M. and G.F.; Project administration, G.F.; Resources, G.F.; Software, A.N.; Supervision, N.B. and T.D.; Validation, A.N.; Visualization, N.B.; Writing&#x02014;original draft, A.N.; Writing&#x02014;review &#x00026; editing, A.N., N.B., M.M., G.F., T.D., H.B. and S.D.</p></notes><notes><title>Funding</title><p>This work was financially supported by the grant research programme project provided by the Conseil National de la Recherche Scientifique (CNRS-Liban) and implemented in collaboration with the National Center for Remote Sensing (NCRS) and Irstea (Montpellier, France).</p></notes><notes notes-type="COI-statement"><title>Conflicts of Interest</title><p>The authors declare no conflict of interest.</p></notes><ref-list><title>References</title><ref id="B1-sensors-18-02089"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Qadir</surname><given-names>M.</given-names></name><name><surname>Sharma</surname><given-names>B.R.</given-names></name><name><surname>Bruggeman</surname><given-names>A.</given-names></name><name><surname>Choukr-Allah</surname><given-names>R.</given-names></name><name><surname>Karajeh</surname><given-names>F.</given-names></name></person-group><article-title>Non-conventional water resources and opportunities for water augmentation to achieve food security in water scarce countries</article-title><source>Agric. Water Manag.</source><year>2007</year><volume>87</volume><fpage>2</fpage><lpage>22</lpage><pub-id pub-id-type="doi">10.1016/j.agwat.2006.03.018</pub-id></element-citation></ref><ref id="B2-sensors-18-02089"><label>2.</label><element-citation publication-type="gov"><article-title>MoA Resultats Globaux du Module de Base du Recensement de L&#x02019;agriculture</article-title><year>2010</year><comment>Available online: <ext-link ext-link-type="uri" xlink:href="http://www.agriculture.gov.lb/Arabic/DataAndAgriStatistics/OverallAgriStatistics/Pages/default.aspx">http://www.agriculture.gov.lb/Arabic/DataAndAgriStatistics/OverallAgriStatistics/Pages/default.aspx</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2018-04-03">(accessed on 3 April 2018)</date-in-citation></element-citation></ref><ref id="B3-sensors-18-02089"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kussul</surname><given-names>N.</given-names></name><name><surname>Lavreniuk</surname><given-names>M.</given-names></name><name><surname>Skakun</surname><given-names>S.</given-names></name><name><surname>Shelestov</surname><given-names>A.</given-names></name></person-group><article-title>Deep Learning Classification of Land Cover and Crop Types Using Remote Sensing Data</article-title><source>IEEE Geosci. Remote Sens. Lett.</source><year>2017</year><volume>14</volume><fpage>778</fpage><lpage>782</lpage><pub-id pub-id-type="doi">10.1109/LGRS.2017.2681128</pub-id></element-citation></ref><ref id="B4-sensors-18-02089"><label>4.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thenkabail</surname><given-names>P.S.</given-names></name><name><surname>Wu</surname><given-names>Z.</given-names></name></person-group><article-title>An automated cropland classification algorithm (ACCA) for Tajikistan by combining landsat, MODIS, and secondary data</article-title><source>Remote Sens.</source><year>2012</year><volume>4</volume><fpage>2890</fpage><lpage>2918</lpage><pub-id pub-id-type="doi">10.3390/rs4102890</pub-id></element-citation></ref><ref id="B5-sensors-18-02089"><label>5.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beziat</surname><given-names>P.</given-names></name><name><surname>Rivalland</surname><given-names>V.</given-names></name><name><surname>Tallec</surname><given-names>T.</given-names></name><name><surname>Jarosz</surname><given-names>N.</given-names></name><name><surname>Boulet</surname><given-names>G.</given-names></name><name><surname>Gentine</surname><given-names>P.</given-names></name><name><surname>Ceschia</surname><given-names>E.</given-names></name></person-group><article-title>Evaluation of a simple approach for crop evapotranspiration partitioning and analysis of the water budget distribution for several crop species</article-title><source>Agric. For. Meteorol.</source><year>2013</year><volume>177</volume><fpage>46</fpage><lpage>56</lpage><pub-id pub-id-type="doi">10.1016/j.agrformet.2013.03.013</pub-id></element-citation></ref><ref id="B6-sensors-18-02089"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xiao</surname><given-names>Y.</given-names></name><name><surname>Mignolet</surname><given-names>C.</given-names></name><name><surname>Mari</surname><given-names>J.F.</given-names></name><name><surname>Benot</surname><given-names>M.</given-names></name></person-group><article-title>Modeling the spatial distribution of crop sequences at a large regional scale using land-cover survey data: A case from France</article-title><source>Comput. Electron. Agric.</source><year>2014</year><volume>102</volume><fpage>51</fpage><lpage>63</lpage><pub-id pub-id-type="doi">10.1016/j.compag.2014.01.010</pub-id></element-citation></ref><ref id="B7-sensors-18-02089"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wardlow</surname><given-names>B.D.</given-names></name><name><surname>Egbert</surname><given-names>S.L.</given-names></name></person-group><article-title>Large-area crop mapping using time-series MODIS 250m NDVI data: An assessment for the U.S. Central Great Plains</article-title><source>Remote Sens. Environ.</source><year>2008</year><volume>112</volume><fpage>1096</fpage><lpage>1116</lpage><pub-id pub-id-type="doi">10.1016/j.rse.2007.07.019</pub-id></element-citation></ref><ref id="B8-sensors-18-02089"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>C.</given-names></name><name><surname>Xie</surname><given-names>Z.</given-names></name></person-group><article-title>Object-based vegetation mapping in the kissimmee river watershed using hymap data and machine learning techniques</article-title><source>Wetlands</source><year>2013</year><volume>33</volume><fpage>233</fpage><lpage>244</lpage><pub-id pub-id-type="doi">10.1007/s13157-012-0373-x</pub-id></element-citation></ref><ref id="B9-sensors-18-02089"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Do Bendini</surname><given-names>H.N.</given-names></name><name><surname>Sanches</surname><given-names>I.D.</given-names></name><name><surname>Krting</surname><given-names>T.S.</given-names></name><name><surname>Fonseca</surname><given-names>L.M.G.</given-names></name><name><surname>Luiz</surname><given-names>A.J.B.</given-names></name><name><surname>Formaggio</surname><given-names>A.R.</given-names></name></person-group><article-title>Using Landsat 8 image time series for crop mapping in a region of Cerrado, Brazil</article-title><source>Int. Arch. Photogramm. Remote Sens. Spat. Inf. Sci. ISPRS Arch.</source><year>2016</year><volume>41</volume><fpage>845</fpage><lpage>850</lpage><pub-id pub-id-type="doi">10.5194/isprsarchives-XLI-B8-845-2016</pub-id></element-citation></ref><ref id="B10-sensors-18-02089"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lobell</surname><given-names>D.B.</given-names></name><name><surname>Asner</surname><given-names>G.P.</given-names></name></person-group><article-title>Cropland distributions from temporal unmixing of MODIS data</article-title><source>Remote Sens. Environ.</source><year>2004</year><volume>93</volume><fpage>412</fpage><lpage>422</lpage><pub-id pub-id-type="doi">10.1016/j.rse.2004.08.002</pub-id></element-citation></ref><ref id="B11-sensors-18-02089"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>J.</given-names></name><name><surname>Hansen</surname><given-names>M.C.</given-names></name><name><surname>Pittman</surname><given-names>K.</given-names></name><name><surname>Carroll</surname><given-names>M.</given-names></name><name><surname>DiMiceli</surname><given-names>C.</given-names></name></person-group><article-title>Corn and soybean mapping in the United States using MODIS time-series data sets</article-title><source>Agron. J.</source><year>2007</year><volume>99</volume><fpage>1654</fpage><lpage>1664</lpage><pub-id pub-id-type="doi">10.2134/agronj2007.0170</pub-id></element-citation></ref><ref id="B12-sensors-18-02089"><label>12.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brown</surname><given-names>J.C.</given-names></name><name><surname>Kastens</surname><given-names>J.H.</given-names></name><name><surname>Coutinho</surname><given-names>A.C.</given-names></name><name><surname>de Victoria</surname><given-names>D.C.</given-names></name><name><surname>Bishop</surname><given-names>C.R.</given-names></name></person-group><article-title>Classifying multiyear agricultural land use data from Mato Grosso using time-series MODIS vegetation index data</article-title><source>Remote Sens. Environ.</source><year>2013</year><volume>130</volume><fpage>39</fpage><lpage>50</lpage><pub-id pub-id-type="doi">10.1016/j.rse.2012.11.009</pub-id></element-citation></ref><ref id="B13-sensors-18-02089"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wardlow</surname><given-names>B.D.</given-names></name><name><surname>Egbert</surname><given-names>S.L.</given-names></name><name><surname>Kastens</surname><given-names>J.H.</given-names></name></person-group><article-title>Analysis of time-series MODIS 250 m vegetation index data for crop classification in the U.S. Central Great Plains</article-title><source>Remote Sens. Environ.</source><year>2007</year><volume>108</volume><fpage>290</fpage><lpage>310</lpage><pub-id pub-id-type="doi">10.1016/j.rse.2006.11.021</pub-id></element-citation></ref><ref id="B14-sensors-18-02089"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arvor</surname><given-names>D.</given-names></name><name><surname>Jonathan</surname><given-names>M.</given-names></name><name><surname>Meirelles</surname><given-names>M.S.P.</given-names></name><name><surname>Dubreuil</surname><given-names>V.</given-names></name><name><surname>Durieux</surname><given-names>L.</given-names></name></person-group><article-title>Classification of MODIS EVI time series for crop mapping in the state of Mato Grosso, Brazil</article-title><source>Int. J. Remote Sens.</source><year>2011</year><volume>32</volume><fpage>7847</fpage><lpage>7871</lpage><pub-id pub-id-type="doi">10.1080/01431161.2010.531783</pub-id></element-citation></ref><ref id="B15-sensors-18-02089"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hao</surname><given-names>P.</given-names></name><name><surname>Wang</surname><given-names>L.</given-names></name><name><surname>Zhan</surname><given-names>Y.</given-names></name><name><surname>Niu</surname><given-names>Z.</given-names></name></person-group><article-title>Using Moderate-Resolution Temporal NDVI Profiles for High-Resolution Crop Mapping in Years of Absent Ground Reference Data: A Case Study of Bole and Manas Counties in Xinjiang, China</article-title><source>ISPRS Int. J. Geo-Inf.</source><year>2016</year><volume>5</volume><elocation-id>67</elocation-id><pub-id pub-id-type="doi">10.3390/ijgi5050067</pub-id></element-citation></ref><ref id="B16-sensors-18-02089"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Asgarian</surname><given-names>A.</given-names></name><name><surname>Soffianian</surname><given-names>A.</given-names></name><name><surname>Pourmanafi</surname><given-names>S.</given-names></name></person-group><article-title>Crop type mapping in a highly fragmented and heterogeneous agricultural landscape: A case of central Iran using multi-temporal Landsat 8 imagery</article-title><source>Comput. Electron. Agric.</source><year>2016</year><volume>127</volume><fpage>531</fpage><lpage>540</lpage><pub-id pub-id-type="doi">10.1016/j.compag.2016.07.019</pub-id></element-citation></ref><ref id="B17-sensors-18-02089"><label>17.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Aggarwal</surname><given-names>R.</given-names></name><name><surname>Kumar</surname><given-names>A.</given-names></name><name><surname>Raju</surname><given-names>P.L.N.</given-names></name><name><surname>Murthy</surname><given-names>Y.V.N.K.</given-names></name></person-group><article-title>Gaussian kernel based classification approach for wheat identification</article-title><source>Proceedings of the International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences&#x02014;ISPRS Archives</source><conf-loc>Hyderabad, India</conf-loc><conf-date>9&#x02013;12 December 2014</conf-date><volume>Volume XL-8</volume><fpage>671</fpage><lpage>676</lpage></element-citation></ref><ref id="B18-sensors-18-02089"><label>18.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Inglada</surname><given-names>J.</given-names></name><name><surname>Vincent</surname><given-names>A.</given-names></name><name><surname>Arias</surname><given-names>M.</given-names></name><name><surname>Marais-Sicre</surname><given-names>C.</given-names></name></person-group><article-title>Improved early crop type identification by joint use of high temporal resolution SAR and optical image time series</article-title><source>Remote Sens.</source><year>2016</year><volume>8</volume><elocation-id>362</elocation-id><pub-id pub-id-type="doi">10.3390/rs8050362</pub-id></element-citation></ref><ref id="B19-sensors-18-02089"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McNairn</surname><given-names>H.</given-names></name><name><surname>Champagne</surname><given-names>C.</given-names></name><name><surname>Shang</surname><given-names>J.</given-names></name><name><surname>Holmstrom</surname><given-names>D.</given-names></name><name><surname>Reichert</surname><given-names>G.</given-names></name></person-group><article-title>Integration of optical and Synthetic Aperture Radar (SAR) imagery for delivering operational annual crop inventories</article-title><source>ISPRS J. Photogramm. Remote Sens.</source><year>2009</year><volume>64</volume><fpage>434</fpage><lpage>449</lpage><pub-id pub-id-type="doi">10.1016/j.isprsjprs.2008.07.006</pub-id></element-citation></ref><ref id="B20-sensors-18-02089"><label>20.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Immitzer</surname><given-names>M.</given-names></name><name><surname>Vuolo</surname><given-names>F.</given-names></name><name><surname>Atzberger</surname><given-names>C.</given-names></name></person-group><article-title>First experience with Sentinel-2 data for crop and tree species classifications in central Europe</article-title><source>Remote Sens.</source><year>2016</year><volume>8</volume><elocation-id>166</elocation-id><pub-id pub-id-type="doi">10.3390/rs8030166</pub-id></element-citation></ref><ref id="B21-sensors-18-02089"><label>21.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhong</surname><given-names>L.</given-names></name><name><surname>Gong</surname><given-names>P.</given-names></name><name><surname>Biging</surname><given-names>G.S.</given-names></name></person-group><article-title>Efficient corn and soybean mapping with temporal extendability: A multi-year experiment using Landsat imagery</article-title><source>Remote Sens. Environ.</source><year>2014</year><volume>140</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1016/j.rse.2013.08.023</pub-id></element-citation></ref><ref id="B22-sensors-18-02089"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vaudour</surname><given-names>E.</given-names></name><name><surname>Noirot-Cosson</surname><given-names>P.E.</given-names></name><name><surname>Membrive</surname><given-names>O.</given-names></name></person-group><article-title>Early-season mapping of crops and cultural operations using very high spatial resolution Pl&#x000e9;iades images</article-title><source>Int. J. Appl. Earth Obs. Geoinf.</source><year>2015</year><volume>42</volume><fpage>128</fpage><lpage>141</lpage><pub-id pub-id-type="doi">10.1016/j.jag.2015.06.003</pub-id></element-citation></ref><ref id="B23-sensors-18-02089"><label>23.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Skakun</surname><given-names>S.</given-names></name><name><surname>Franch</surname><given-names>B.</given-names></name><name><surname>Vermote</surname><given-names>E.</given-names></name><name><surname>Roger</surname><given-names>J.C.</given-names></name><name><surname>Becker-Reshef</surname><given-names>I.</given-names></name><name><surname>Justice</surname><given-names>C.</given-names></name><name><surname>Kussul</surname><given-names>N.</given-names></name></person-group><article-title>Early season large-area winter crop mapping using MODIS NDVI data, growing degree days information and a Gaussian mixture model</article-title><source>Remote Sens. Environ.</source><year>2017</year><volume>195</volume><fpage>244</fpage><lpage>258</lpage><pub-id pub-id-type="doi">10.1016/j.rse.2017.04.026</pub-id></element-citation></ref><ref id="B24-sensors-18-02089"><label>24.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Darwish</surname><given-names>T.M.</given-names></name><name><surname>Jomaa</surname><given-names>I.</given-names></name><name><surname>Awad</surname><given-names>M.</given-names></name><name><surname>Boumetri</surname><given-names>R.</given-names></name></person-group><article-title>Preliminary contamination hazard assessment of land ressources in central bekaa plain of Lebanon</article-title><source>Leban. Sci. J.</source><year>2008</year><volume>9</volume><fpage>3</fpage><lpage>15</lpage></element-citation></ref><ref id="B25-sensors-18-02089"><label>25.</label><element-citation publication-type="web"><article-title>USAID Litani River Basin Management Support Program-Land Use Crop Classification Analysis for Upper Litani River Basin</article-title><comment>Available online: <ext-link ext-link-type="uri" xlink:href="http://www.databank.com.lb/docs/Land%20use%20and%20crop%20classification%20analysis%20for%20the%20upper%20Litani%20River%20Basin%2DFeb%202012%2Epdf">http://www.databank.com.lb/docs/Land%20use%20and%20crop%20classification%20analysis%20for%20the%20upper%20Litani%20River%20Basin%2DFeb%202012%2Epdf</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2018-05-03">(accessed on 3 May 2018)</date-in-citation></element-citation></ref><ref id="B26-sensors-18-02089"><label>26.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Drusch</surname><given-names>M.</given-names></name><name><surname>Del Bello</surname><given-names>U.</given-names></name><name><surname>Carlier</surname><given-names>S.</given-names></name><name><surname>Colin</surname><given-names>O.</given-names></name><name><surname>Fernandez</surname><given-names>V.</given-names></name><name><surname>Gascon</surname><given-names>F.</given-names></name><name><surname>Hoersch</surname><given-names>B.</given-names></name><name><surname>Isola</surname><given-names>C.</given-names></name><name><surname>Laberinti</surname><given-names>P.</given-names></name><name><surname>Martimort</surname><given-names>P.</given-names></name><etal/></person-group><article-title>Sentinel-2: ESA&#x02019;s Optical High-Resolution Mission for GMES Operational Services</article-title><source>Remote Sens. Environ.</source><year>2012</year><volume>120</volume><fpage>25</fpage><lpage>36</lpage><pub-id pub-id-type="doi">10.1016/j.rse.2011.11.026</pub-id></element-citation></ref><ref id="B27-sensors-18-02089"><label>27.</label><element-citation publication-type="web"><article-title>Europe&#x02019;s Copernicus Website</article-title><comment>Available online: <ext-link ext-link-type="uri" xlink:href="https://scihub.copernicus.eu">https://scihub.copernicus.eu</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2018-02-13">(accessed on 13 February 2018)</date-in-citation></element-citation></ref><ref id="B28-sensors-18-02089"><label>28.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goswami</surname><given-names>S.</given-names></name><name><surname>Gamon</surname><given-names>J.</given-names></name><name><surname>Vargas</surname><given-names>S.</given-names></name><name><surname>Tweedie</surname><given-names>C.</given-names></name></person-group><article-title>Relationships of NDVI, Biomass, and Leaf Area Index (LAI) for six key plant species in Barrow, Alaska</article-title><source>PeerJ</source><year>2015</year><fpage>1</fpage><lpage>17</lpage><pub-id pub-id-type="doi">10.7287/peerj.preprints.11</pub-id></element-citation></ref><ref id="B29-sensors-18-02089"><label>29.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gates</surname><given-names>D.M.</given-names></name><name><surname>Keegan</surname><given-names>H.J.</given-names></name><name><surname>Schleter</surname><given-names>J.C.</given-names></name><name><surname>Weidner</surname><given-names>V.R.</given-names></name></person-group><article-title>Spectral Properties of Plants</article-title><source>Appl. Opt.</source><year>1965</year><volume>4</volume><fpage>11</fpage><pub-id pub-id-type="doi">10.1364/AO.4.000011</pub-id></element-citation></ref><ref id="B30-sensors-18-02089"><label>30.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Turner</surname><given-names>D.P.</given-names></name><name><surname>Cohen</surname><given-names>W.B.</given-names></name><name><surname>Kennedy</surname><given-names>R.E.</given-names></name><name><surname>Fassnacht</surname><given-names>K.S.</given-names></name><name><surname>Briggs</surname><given-names>J.M.</given-names></name></person-group><article-title>Relationships between leaf area index and Landsat TM spectral vegetation indices across three temperate zone sites</article-title><source>Remote Sens. Environ.</source><year>1999</year><volume>70</volume><fpage>52</fpage><lpage>68</lpage><pub-id pub-id-type="doi">10.1016/S0034-4257(99)00057-7</pub-id></element-citation></ref><ref id="B31-sensors-18-02089"><label>31.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Law</surname><given-names>B.</given-names></name><name><surname>Waring</surname><given-names>R.</given-names></name></person-group><article-title>Remote sensing of leaf area index and radiation intercepted by understorey vegetation</article-title><source>Ecol. Appl.</source><year>1994</year><volume>4</volume><fpage>272</fpage><lpage>279</lpage><pub-id pub-id-type="doi">10.2307/1941933</pub-id></element-citation></ref><ref id="B32-sensors-18-02089"><label>32.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haboudane</surname><given-names>D.</given-names></name><name><surname>Miller</surname><given-names>J.R.</given-names></name><name><surname>Pattey</surname><given-names>E.</given-names></name><name><surname>Zarco-Tejada</surname><given-names>P.J.</given-names></name><name><surname>Strachan</surname><given-names>I.B.</given-names></name></person-group><article-title>Hyperspectral vegetation indices and novel algorithms for predicting green LAI of crop canopies: Modeling and validation in the context of precision agriculture</article-title><source>Remote Sens. Environ.</source><year>2004</year><volume>90</volume><fpage>337</fpage><lpage>352</lpage><pub-id pub-id-type="doi">10.1016/j.rse.2003.12.013</pub-id></element-citation></ref><ref id="B33-sensors-18-02089"><label>33.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Di</surname><given-names>K.</given-names></name><name><surname>Wang</surname><given-names>J.</given-names></name><name><surname>Ma</surname><given-names>R.</given-names></name><name><surname>Li</surname><given-names>R.</given-names></name></person-group><article-title>Automatic shoreline extraction from highresolution IKONOS satellite imagery</article-title><source>ASPRS Annu. Conf. Proc.</source><year>2003</year><volume>130</volume><fpage>1</fpage><lpage>4</lpage><pub-id pub-id-type="doi">10.1080/01490410390181180</pub-id></element-citation></ref><ref id="B34-sensors-18-02089"><label>34.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tao</surname><given-names>W.</given-names></name><name><surname>Jin</surname><given-names>H.</given-names></name><name><surname>Zhang</surname><given-names>Y.</given-names></name></person-group><article-title>Color image segmentation based on mean shift and normalized cuts</article-title><source>IEEE Trans. Syst. Man. Cybern. B Cybern.</source><year>2007</year><volume>37</volume><fpage>1382</fpage><lpage>1389</lpage><pub-id pub-id-type="doi">10.1109/TSMCB.2007.902249</pub-id><?supplied-pmid 17926718?><pub-id pub-id-type="pmid">17926718</pub-id></element-citation></ref><ref id="B35-sensors-18-02089"><label>35.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fukunaga</surname><given-names>K.</given-names></name><name><surname>Hostetler</surname><given-names>L.D.</given-names></name></person-group><article-title>The Estimation of the Gradient of a Density Function, with Applications in Pattern Recognition</article-title><source>IEEE Trans. Inf. Theory</source><year>1975</year><volume>21</volume><fpage>32</fpage><lpage>40</lpage><pub-id pub-id-type="doi">10.1109/TIT.1975.1055330</pub-id></element-citation></ref><ref id="B36-sensors-18-02089"><label>36.</label><element-citation publication-type="web"><article-title>Development Team OTB the Orfeo ToolBox Cookbook, a Guide for Non-Developers Updated for OTB-4.0</article-title><year>2014</year><comment>Available online: <ext-link ext-link-type="uri" xlink:href="https://www.orfeo-toolbox.org/packages/archives/Doc/CookBook-4.0.0.pdf">https://www.orfeo-toolbox.org/packages/archives/Doc/CookBook-4.0.0.pdf</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2018-05-03">(accessed on 3 May 2018)</date-in-citation></element-citation></ref><ref id="B37-sensors-18-02089"><label>37.</label><element-citation publication-type="web"><article-title>QGIS Development Team 2018</article-title><comment>Available online: <ext-link ext-link-type="uri" xlink:href="https://www.osgeo.org/projects/qgis/">https://www.osgeo.org/projects/qgis/</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2018-06-25">(accessed on 25 June 2018)</date-in-citation></element-citation></ref><ref id="B38-sensors-18-02089"><label>38.</label><element-citation publication-type="web"><article-title>Optimising Irrigation Practices of Durum Wheat and Spring Barley to Cope with Climate Change Effects in Jordan</article-title><comment>Available online: <ext-link ext-link-type="uri" xlink:href="https://www.researchgate.net/publication/280489038_Optimising_irrigation_practices_of_durum_wheat_and_spring_barley_to_cope_with_climate_change_effects_in_Jordan">https://www.researchgate.net/publication/280489038_Optimising_irrigation_practices_of_durum_wheat_and_spring_barley_to_cope_with_climate_change_effects_in_Jordan</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2018-05-03">(accessed on 3 May 2018)</date-in-citation></element-citation></ref><ref id="B39-sensors-18-02089"><label>39.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olofsson</surname><given-names>P.</given-names></name><name><surname>Foody</surname><given-names>G.M.</given-names></name><name><surname>Herold</surname><given-names>M.</given-names></name><name><surname>Stehman</surname><given-names>S.V.</given-names></name><name><surname>Woodcock</surname><given-names>C.E.</given-names></name><name><surname>Wulder</surname><given-names>M.A.</given-names></name></person-group><article-title>Good practices for estimating area and assessing accuracy of land change</article-title><source>Remote Sens. Environ.</source><year>2014</year><volume>148</volume><fpage>42</fpage><lpage>57</lpage><pub-id pub-id-type="doi">10.1016/j.rse.2014.02.015</pub-id></element-citation></ref><ref id="B40-sensors-18-02089"><label>40.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knipling</surname><given-names>E.</given-names></name></person-group><article-title>Physical and Physiological Basis for the Reflectance of Visible and Near Infrared Radiation from Vegetation</article-title><source>Remote Sens. Environ.</source><year>1970</year><volume>1</volume><fpage>155</fpage><lpage>159</lpage><pub-id pub-id-type="doi">10.1016/S0034-4257(70)80021-9</pub-id></element-citation></ref><ref id="B41-sensors-18-02089"><label>41.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rabideau</surname><given-names>G.S.</given-names></name><name><surname>French</surname><given-names>C.S.</given-names></name><name><surname>Holt</surname><given-names>A.S.</given-names></name></person-group><article-title>The Absorption and Reflection Spectra of Leaves, Chloroplast Suspensions, and Chloroplast Fragments as Measured in an Ulbricht Sphere</article-title><source>Am. J. Bot.</source><year>1946</year><volume>33</volume><fpage>769</fpage><pub-id pub-id-type="doi">10.1002/j.1537-2197.1946.tb12939.x</pub-id></element-citation></ref><ref id="B42-sensors-18-02089"><label>42.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Grime</surname><given-names>J.P.</given-names></name></person-group><article-title>The C-S-R model of primary plant strategies&#x02014;Origins, implications and tests</article-title><source>Plant Evolutionary Biology</source><publisher-name>Springer</publisher-name><publisher-loc>Dordrecht, The Netherlands</publisher-loc><year>1988</year><fpage>371</fpage><lpage>393</lpage></element-citation></ref><ref id="B43-sensors-18-02089"><label>43.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harris</surname><given-names>D.</given-names></name></person-group><article-title>The effects of manure, genotype, seed priming, depth and date of sowing on the emergence and early growth <italic>Sorghum bicolor</italic> (L.) Moench in semi-arid Botswana</article-title><source>Soil Tillage Res.</source><year>1996</year><volume>40</volume><fpage>73</fpage><lpage>88</lpage><pub-id pub-id-type="doi">10.1016/S0167-1987(96)01047-1</pub-id></element-citation></ref><ref id="B44-sensors-18-02089"><label>44.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dasberg</surname><given-names>S.</given-names></name><name><surname>Mendel</surname><given-names>K.</given-names></name></person-group><article-title>The Effect of Soil Water and Aeration on Seed Germination</article-title><source>J. Exp. Bot.</source><year>1971</year><volume>22</volume><fpage>992</fpage><lpage>998</lpage><pub-id pub-id-type="doi">10.1093/jxb/22.4.992</pub-id></element-citation></ref><ref id="B45-sensors-18-02089"><label>45.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>X.</given-names></name><name><surname>Zhang</surname><given-names>S.</given-names></name><name><surname>Shan</surname><given-names>X.</given-names></name><name><surname>Zhu</surname><given-names>Y.G.</given-names></name></person-group><article-title>Toxicity of arsenate and arsenite on germination, seedling growth and amylolytic activity of wheat</article-title><source>Chemosphere</source><year>2005</year><volume>61</volume><fpage>293</fpage><lpage>301</lpage><pub-id pub-id-type="doi">10.1016/j.chemosphere.2005.01.088</pub-id><?supplied-pmid 16168752?><pub-id pub-id-type="pmid">16168752</pub-id></element-citation></ref><ref id="B46-sensors-18-02089"><label>46.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Vallavieille-Pope</surname><given-names>C. De</given-names></name><name><surname>Huber</surname><given-names>L.</given-names></name><name><surname>Leconte</surname><given-names>M.</given-names></name><name><surname>Goyeau</surname><given-names>H.</given-names></name></person-group><article-title>Comparative effects of temperature and interrupted wet periods on germination, penetration, and infection of <italic>Puccinia recondita</italic> f. sp. tritici and <italic>P. striiformis</italic> on</article-title><source>Phytopathology</source><year>1995</year><volume>85</volume><fpage>409</fpage><lpage>415</lpage><pub-id pub-id-type="doi">10.1094/Phyto-85-409</pub-id></element-citation></ref><ref id="B47-sensors-18-02089"><label>47.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lunn</surname><given-names>G.D.</given-names></name><name><surname>Kettlewell</surname><given-names>P.S.</given-names></name><name><surname>Major</surname><given-names>B.J.</given-names></name><name><surname>Scott</surname><given-names>R.K.</given-names></name></person-group><article-title>Variation in dormancy duration of the U.K. wheat cultivar Hornet due to environmental conditions during grain development</article-title><source>Euphytica.</source><year>2002</year><volume>126</volume><fpage>89</fpage><lpage>97</lpage><pub-id pub-id-type="doi">10.1023/A:1019651117813</pub-id></element-citation></ref><ref id="B48-sensors-18-02089"><label>48.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhong</surname><given-names>L.</given-names></name><name><surname>Gong</surname><given-names>P.</given-names></name><name><surname>Biging</surname><given-names>G.S.</given-names></name></person-group><article-title>Phenology-based Crop Classification Algorithm and its implications on Agricultural Water Use Assessments in California&#x02019;s Central Valley</article-title><source>Photogramm. Eng. Remote Sens.</source><year>2012</year><volume>78</volume><fpage>799</fpage><lpage>813</lpage><pub-id pub-id-type="doi">10.14358/PERS.78.8.799</pub-id></element-citation></ref><ref id="B49-sensors-18-02089"><label>49.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jakubauskas</surname><given-names>M.E.</given-names></name><name><surname>Legates</surname><given-names>D.R.</given-names></name><name><surname>Kastens</surname><given-names>J.H.</given-names></name></person-group><article-title>Crop identification using harmonic analysis oftime-series AVHRR NDVI data</article-title><source>Comput. Electron. Agric.</source><year>2002</year><volume>37</volume><fpage>127</fpage><lpage>139</lpage><pub-id pub-id-type="doi">10.1016/S0168-1699(02)00116-3</pub-id></element-citation></ref><ref id="B50-sensors-18-02089"><label>50.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benedetti</surname><given-names>R.</given-names></name><name><surname>Rossini</surname><given-names>P.</given-names></name><name><surname>Taddei</surname><given-names>R.</given-names></name></person-group><article-title>Vegetation classification in the middle Mediterranean area by satellite data</article-title><source>Int. J. Remote Sens.</source><year>1994</year><volume>15</volume><fpage>517</fpage><lpage>520</lpage><pub-id pub-id-type="doi">10.1080/01431169408954098</pub-id></element-citation></ref><ref id="B51-sensors-18-02089"><label>51.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Atzberger</surname><given-names>C.</given-names></name><name><surname>Rembold</surname><given-names>F.</given-names></name></person-group><article-title>Mapping the spatial distribution of winter crops at sub-pixel level using AVHRR NDVI time series and neural nets</article-title><source>Remote Sens.</source><year>2013</year><volume>5</volume><fpage>1335</fpage><lpage>1354</lpage><pub-id pub-id-type="doi">10.3390/rs5031335</pub-id></element-citation></ref><ref id="B52-sensors-18-02089"><label>52.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hochheim</surname><given-names>K.P.</given-names></name><name><surname>Barber</surname><given-names>D.G.</given-names></name></person-group><article-title>Spring wheat yield estimation for western Canada using NOAA NDVI data</article-title><source>Can. J. Remote Sens.</source><year>1998</year><volume>24</volume><fpage>17</fpage><lpage>27</lpage><pub-id pub-id-type="doi">10.1080/07038992.1998.10874687</pub-id></element-citation></ref><ref id="B53-sensors-18-02089"><label>53.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Akram</surname><given-names>M.</given-names></name></person-group><article-title>Growth and Yield Components of Wheat Under Water</article-title><source>Bangladesh J. Agric. Res.</source><year>2011</year><volume>36</volume><fpage>455</fpage><lpage>468</lpage><pub-id pub-id-type="doi">10.3329/bjar.v36i3.9264</pub-id></element-citation></ref><ref id="B54-sensors-18-02089"><label>54.</label><element-citation publication-type="web"><article-title>ESA Website</article-title><comment>Available online: <ext-link ext-link-type="uri" xlink:href="https://sentinel.esa.int/documents/247904/685211/Sentinel-2-Data-Quality-Report">https://sentinel.esa.int/documents/247904/685211/Sentinel-2-Data-Quality-Report</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2018-03-04">(accessed on 4 March 2018)</date-in-citation></element-citation></ref><ref id="B55-sensors-18-02089"><label>55.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gascon</surname><given-names>F.</given-names></name><name><surname>Bouzinac</surname><given-names>C.</given-names></name><name><surname>Th&#x000e9;paut</surname><given-names>O.</given-names></name><name><surname>Jung</surname><given-names>M.</given-names></name><name><surname>Francesconi</surname><given-names>B.</given-names></name><name><surname>Louis</surname><given-names>J.</given-names></name><name><surname>Lonjou</surname><given-names>V.</given-names></name><name><surname>Lafrance</surname><given-names>B.</given-names></name><name><surname>Massera</surname><given-names>S.</given-names></name><name><surname>Gaudel-Vacaresse</surname><given-names>A.</given-names></name><etal/></person-group><article-title>Copernicus Sentinel-2A calibration and products validation status</article-title><source>Remote Sens.</source><year>2017</year><volume>9</volume><elocation-id>584</elocation-id><pub-id pub-id-type="doi">10.3390/rs9060584</pub-id></element-citation></ref><ref id="B56-sensors-18-02089"><label>56.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Skakun</surname><given-names>S.</given-names></name><name><surname>Vermote</surname><given-names>E.</given-names></name><name><surname>Roger</surname><given-names>J.C.</given-names></name><name><surname>Justice</surname><given-names>C.</given-names></name></person-group><article-title>Multispectral Misregistration of Sentinel-2A Images: Analysis and Implications for Potential Applications</article-title><source>IEEE Geosci. Remote Sens. Lett.</source><year>2017</year><volume>14</volume><fpage>2408</fpage><lpage>2412</lpage><pub-id pub-id-type="doi">10.1109/LGRS.2017.2766448</pub-id><?supplied-pmid 29893382?><pub-id pub-id-type="pmid">29893382</pub-id></element-citation></ref><ref id="B57-sensors-18-02089"><label>57.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Skakun</surname><given-names>S.</given-names></name><name><surname>Roger</surname><given-names>J.C.</given-names></name><name><surname>Vermote</surname><given-names>E.F.</given-names></name><name><surname>Masek</surname><given-names>J.G.</given-names></name><name><surname>Justice</surname><given-names>C.O.</given-names></name></person-group><article-title>Automatic sub-pixel co-registration of Landsat-8 Operational Land Imager and Sentinel-2A Multi-Spectral Instrument images using phase correlation and machine learning based mapping</article-title><source>Int. J. Digit. Earth</source><year>2017</year><volume>10</volume><fpage>1253</fpage><lpage>1269</lpage><pub-id pub-id-type="doi">10.1080/17538947.2017.1304586</pub-id></element-citation></ref><ref id="B58-sensors-18-02089"><label>58.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yan</surname><given-names>L.</given-names></name><name><surname>Roy</surname><given-names>D.</given-names></name><name><surname>Zhang</surname><given-names>H.</given-names></name><name><surname>Li</surname><given-names>J.</given-names></name><name><surname>Huang</surname><given-names>H.</given-names></name></person-group><article-title>An automated approach for sub-pixel registration of Landsat-8 Operational Land Imager (OLI) and Sentinel-2 Multi Spectral Instrument (MSI) imagery chyba tak DO PREZENTACJI</article-title><source>Remote Sens.</source><year>2016</year><volume>8</volume><elocation-id>520</elocation-id><pub-id pub-id-type="doi">10.3390/rs8060520</pub-id></element-citation></ref><ref id="B59-sensors-18-02089"><label>59.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scheffler</surname><given-names>D.</given-names></name><name><surname>Hollstein</surname><given-names>A.</given-names></name><name><surname>Diedrich</surname><given-names>H.</given-names></name><name><surname>Segl</surname><given-names>K.</given-names></name><name><surname>Hostert</surname><given-names>P.</given-names></name></person-group><article-title>AROSICS: An automated and robust open-source image co-registration software for multi-sensor satellite data</article-title><source>Remote Sens.</source><year>2017</year><volume>9</volume><elocation-id>676</elocation-id><pub-id pub-id-type="doi">10.3390/rs9070676</pub-id></element-citation></ref><ref id="B60-sensors-18-02089"><label>60.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Abdallah</surname><given-names>L.</given-names></name><name><surname>Shimshoni</surname><given-names>I.</given-names></name></person-group><article-title>Mean Shift Clustering Algorithm for Data with Missing Values</article-title><source>Proceedings of the International Conference on Data Warehousing and Knowledge</source><conf-loc>Munich, Germany</conf-loc><conf-date>2&#x02013;4 September 2014</conf-date><fpage>426</fpage><lpage>438</lpage></element-citation></ref></ref-list></back><floats-group><fig id="sensors-18-02089-f001" orientation="portrait" position="float"><label>Figure 1</label><caption><p>Location of Bekaa plain of Lebanon as well as Sentinel-2 (in orange) tile covering the study area (Landcover/Landuse NCRS-L, 2013).</p></caption><graphic xlink:href="sensors-18-02089-g001"/></fig><fig id="sensors-18-02089-f002" orientation="portrait" position="float"><label>Figure 2</label><caption><p>Different crops calendars at the Bekaa plain (adopted from USAID [<xref rid="B25-sensors-18-02089" ref-type="bibr">25</xref>]).</p></caption><graphic xlink:href="sensors-18-02089-g002"/></fig><fig id="sensors-18-02089-f003" orientation="portrait" position="float"><label>Figure 3</label><caption><p>Simplified flowchart for the preparation of SEWMA NDVI temporal profiles.</p></caption><graphic xlink:href="sensors-18-02089-g003"/></fig><fig id="sensors-18-02089-f004" orientation="portrait" position="float"><label>Figure 4</label><caption><p><italic>SEWMA</italic> (Simple and Effective Wheat Mapping Approach) simplified flowchart.</p></caption><graphic xlink:href="sensors-18-02089-g004"/></fig><fig id="sensors-18-02089-f005" orientation="portrait" position="float"><label>Figure 5</label><caption><p>Mean &#x000b1; standard deviation of <italic>&#x003c1;</italic>RED and <italic>&#x003c1;</italic>NIR temporal profiles of Wheat (<bold>a</bold>) 2016 and (<bold>b</bold>) 2017; Barley (<bold>c</bold>) 2016 and (<bold>d</bold>) 2017 and Triticale (<bold>e</bold>) 2016 and (<bold>f</bold>) 2017.</p></caption><graphic xlink:href="sensors-18-02089-g005"/></fig><fig id="sensors-18-02089-f006" orientation="portrait" position="float"><label>Figure 6</label><caption><p>Mean &#x000b1; standard deviation of <italic>&#x003c1;</italic>RED and <italic>&#x003c1;</italic>NIR temporal profiles of spring potato (<bold>a</bold>) 2016 and (<bold>b</bold>) 2017 and spring vegetables (<bold>c</bold>) 2016 and (<bold>d</bold>) 2017.</p></caption><graphic xlink:href="sensors-18-02089-g006"/></fig><fig id="sensors-18-02089-f007" orientation="portrait" position="float"><label>Figure 7</label><caption><p>NDVI temporal profile of wheat, barley, triticale, spring potato and spring vegetables of 2016 (<bold>a</bold>) and 2017 (<bold>b</bold>) years.</p></caption><graphic xlink:href="sensors-18-02089-g007"/></fig><fig id="sensors-18-02089-f008" orientation="portrait" position="float"><label>Figure 8</label><caption><p>Differences of wheat reference segments when using the thresholds [&#x003bc; + <italic>1</italic>&#x003c3;] (<bold>a</bold>) 2016 when calibrated by 2017 and (<bold>b</bold>) 2017 when calibrated by 2016, [&#x003bc; + <italic>1.5</italic>&#x003c3;] (<bold>c</bold>) 2016 when calibrated by 2017 and (<bold>d</bold>) 2017 when calibrated by 2016 and [&#x003bc; + <italic>2</italic>&#x003c3;] (<bold>e</bold>) 2016 when calibrated by 2017 and (<bold>f</bold>) 2017 when calibrated by 2016.</p></caption><graphic xlink:href="sensors-18-02089-g008a"/><graphic xlink:href="sensors-18-02089-g008b"/></fig><fig id="sensors-18-02089-f009" orientation="portrait" position="float"><label>Figure 9</label><caption><p>Spatial distribution of wheat in the Bekaa plain for years 2016 and 2017.</p></caption><graphic xlink:href="sensors-18-02089-g009"/></fig><table-wrap id="sensors-18-02089-t001" orientation="portrait" position="float"><object-id pub-id-type="pii">sensors-18-02089-t001_Table 1</object-id><label>Table 1</label><caption><p>Day of Year (DOY) of Sentinel-2 images used for both 2016 and 2017 cropping seasons.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Sentinel-2 Image Number</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">1</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">2</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">3</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">4</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">5</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">6</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">7</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">8</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">2016 DOY</td><td align="center" valign="middle" rowspan="1" colspan="1">17</td><td align="center" valign="middle" rowspan="1" colspan="1">47</td><td align="center" valign="middle" rowspan="1" colspan="1">67</td><td align="center" valign="middle" rowspan="1" colspan="1">87</td><td align="center" valign="middle" rowspan="1" colspan="1">97</td><td align="center" valign="middle" rowspan="1" colspan="1">107</td><td align="center" valign="middle" rowspan="1" colspan="1">117</td><td align="center" valign="middle" rowspan="1" colspan="1">137</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2017 DOY</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">11</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">41</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">51</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">71</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">101</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">111</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">131</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">151</td></tr></tbody></table></table-wrap><table-wrap id="sensors-18-02089-t002" orientation="portrait" position="float"><object-id pub-id-type="pii">sensors-18-02089-t002_Table 2</object-id><label>Table 2</label><caption><p>Number of segmented plots visited per cultivations in 2016 and 2017.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Crop</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">2016</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">2017</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">Wheat</td><td align="center" valign="middle" rowspan="1" colspan="1">216</td><td align="center" valign="middle" rowspan="1" colspan="1">348</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Barley</td><td align="center" valign="middle" rowspan="1" colspan="1">59</td><td align="center" valign="middle" rowspan="1" colspan="1">13</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Triticale</td><td align="center" valign="middle" rowspan="1" colspan="1">64</td><td align="center" valign="middle" rowspan="1" colspan="1">17</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Spring potato</td><td align="center" valign="middle" rowspan="1" colspan="1">111</td><td align="center" valign="middle" rowspan="1" colspan="1">117</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Spring vegetables</td><td align="center" valign="middle" rowspan="1" colspan="1">14</td><td align="center" valign="middle" rowspan="1" colspan="1">20</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Fruit trees</td><td align="center" valign="middle" rowspan="1" colspan="1">157</td><td align="center" valign="middle" rowspan="1" colspan="1">190</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Vineyards</td><td align="center" valign="middle" rowspan="1" colspan="1">29</td><td align="center" valign="middle" rowspan="1" colspan="1">33</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Alfalfa</td><td align="center" valign="middle" rowspan="1" colspan="1">11</td><td align="center" valign="middle" rowspan="1" colspan="1">23</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Bare soil</td><td align="center" valign="middle" rowspan="1" colspan="1">7</td><td align="center" valign="middle" rowspan="1" colspan="1">8</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Total</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">668</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">769</td></tr></tbody></table></table-wrap><table-wrap id="sensors-18-02089-t003" orientation="portrait" position="float"><object-id pub-id-type="pii">sensors-18-02089-t003_Table 3</object-id><label>Table 3</label><caption><p>Slope (a) and interception (b) deduced from the already produced linear equations.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Date Year</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">1</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">2</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">3</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">4</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">5</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">6</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">7</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">8</th></tr></thead><tbody><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2016</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">DOY 17</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">DOY 47<break/>a = 1.211<break/>b = 0.111</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">DOY 67<break/>a = 0.670<break/>b = 0.492</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">DOY 87<break/>a = 0.459<break/>b = 0.516</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">DOY 97<break/>a = 0.673<break/>b = 0.287</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">DOY 107<break/>a = 0.442<break/>b = 0.566</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">DOY 117<break/>a = 1.055<break/>b = 0.077</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">DOY 137<break/>a = 1.615<break/>b = &#x02212;0.773</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2017</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">DOY 11</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">DOY 41<break/>a = 0.724<break/>b = 0.138</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">DOY 51<break/>a = 1.042<break/>b = 0.008</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">DOY 71<break/>a = 0.893<break/>b = 0.296</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">DOY 101<break/>a = 0.268<break/>b = 0.464</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">DOY 111<break/>a = 0.759<break/>b = 0.408</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">DOY 131<break/>a = 1.041<break/>b = 0.012</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">DOY 151<break/>a = 1.426<break/>b = &#x02212;0.674</td></tr></tbody></table></table-wrap><table-wrap id="sensors-18-02089-t004" orientation="portrait" position="float"><object-id pub-id-type="pii">sensors-18-02089-t004_Table 4</object-id><label>Table 4</label><caption><p>Overall accuracies of wheat mapping using the three thresholds tested.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Threshold <italic>SEWMA</italic></th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">&#x003bc; + <italic>1</italic>&#x003c3;</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">&#x003bc; + <italic>1.5</italic>&#x003c3;</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">&#x003bc; + <italic>2</italic>&#x003c3;</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">Trained by 2016 and validated by 2017</td><td align="center" valign="middle" rowspan="1" colspan="1">84.0%</td><td align="center" valign="middle" rowspan="1" colspan="1">87.0%</td><td align="center" valign="middle" rowspan="1" colspan="1">84.7%</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Trained by 2017 and validated by 2016</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">80.4%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">82.6%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">79.2%</td></tr></tbody></table></table-wrap><table-wrap id="sensors-18-02089-t005" orientation="portrait" position="float"><object-id pub-id-type="pii">sensors-18-02089-t005_Table 5</object-id><label>Table 5</label><caption><p>Confusion matrix of 2016 wheat classification trained by 2017 data.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">ClassValue</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Not Wheat</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Wheat</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Total</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">User Accuracy</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">Not wheat</td><td align="center" valign="middle" rowspan="1" colspan="1">331</td><td align="center" valign="middle" rowspan="1" colspan="1">104</td><td align="center" valign="middle" rowspan="1" colspan="1">435</td><td align="center" valign="middle" rowspan="1" colspan="1">0.761</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Wheat</td><td align="center" valign="middle" rowspan="1" colspan="1">17</td><td align="center" valign="middle" rowspan="1" colspan="1">244</td><td align="center" valign="middle" rowspan="1" colspan="1">261</td><td align="center" valign="middle" rowspan="1" colspan="1">0.935</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Total</td><td align="center" valign="middle" rowspan="1" colspan="1">348</td><td align="center" valign="middle" rowspan="1" colspan="1">348</td><td align="center" valign="middle" rowspan="1" colspan="1">696</td><td align="center" valign="middle" rowspan="1" colspan="1">
</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Producer Accuracy</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.951</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.701</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.826</td></tr></tbody></table></table-wrap><table-wrap id="sensors-18-02089-t006" orientation="portrait" position="float"><object-id pub-id-type="pii">sensors-18-02089-t006_Table 6</object-id><label>Table 6</label><caption><p>Confusion matrix of 2017 wheat classification trained by 2016 data.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">ClassValue</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Not Wheat</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Wheat</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Total</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">User Accuracy</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">Not wheat</td><td align="center" valign="middle" rowspan="1" colspan="1">189</td><td align="center" valign="middle" rowspan="1" colspan="1">29</td><td align="center" valign="middle" rowspan="1" colspan="1">218</td><td align="center" valign="middle" rowspan="1" colspan="1">0.867</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Wheat</td><td align="center" valign="middle" rowspan="1" colspan="1">27</td><td align="center" valign="middle" rowspan="1" colspan="1">187</td><td align="center" valign="middle" rowspan="1" colspan="1">214</td><td align="center" valign="middle" rowspan="1" colspan="1">0.874</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Total</td><td align="center" valign="middle" rowspan="1" colspan="1">216</td><td align="center" valign="middle" rowspan="1" colspan="1">216</td><td align="center" valign="middle" rowspan="1" colspan="1">432</td><td align="center" valign="middle" rowspan="1" colspan="1">
</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Producer Accuracy</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.875</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.866</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.870</td></tr></tbody></table></table-wrap><table-wrap id="sensors-18-02089-t007" orientation="portrait" position="float"><object-id pub-id-type="pii">sensors-18-02089-t007_Table 7</object-id><label>Table 7</label><caption><p>Areas estimates of wheat cultivated plots in the study area for years 2016 and 2017 (According to Olofsson et al. [<xref rid="B39-sensors-18-02089" ref-type="bibr">39</xref>]).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Year</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Wheat Area Estimated from <italic>SEWMA</italic> (ha) (Error-Corrected Estimates)</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Wheat Area by Lebanese Government (ha)</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">2016</td><td align="center" valign="middle" rowspan="1" colspan="1">11,063 &#x000b1; 1309</td><td align="center" valign="middle" rowspan="1" colspan="1">9073.4</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2017</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">7605 &#x000b1; 1184</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">7877.8</td></tr></tbody></table></table-wrap></floats-group></article>