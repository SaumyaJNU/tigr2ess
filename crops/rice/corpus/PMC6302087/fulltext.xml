<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN" "JATS-archivearticle1.dtd"> 
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName journalpublishing.dtd?><?SourceDTD.Version 2.3?><?ConverterInfo.XSLTName jp2nlmx2.xsl?><?ConverterInfo.Version 1?><front><journal-meta><journal-id journal-id-type="nlm-ta">Front Plant Sci</journal-id><journal-id journal-id-type="iso-abbrev">Front Plant Sci</journal-id><journal-id journal-id-type="publisher-id">Front. Plant Sci.</journal-id><journal-title-group><journal-title>Frontiers in Plant Science</journal-title></journal-title-group><issn pub-type="epub">1664-462X</issn><publisher><publisher-name>Frontiers Media S.A.</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">6302087</article-id><article-id pub-id-type="doi">10.3389/fpls.2018.01834</article-id><article-categories><subj-group subj-group-type="heading"><subject>Plant Science</subject><subj-group><subject>Original Research</subject></subj-group></subj-group></article-categories><title-group><article-title>Potential of UAV-Based Active Sensing for Monitoring Rice Leaf Nitrogen Status</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Li</surname><given-names>Songyang</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/562286/overview"/></contrib><contrib contrib-type="author"><name><surname>Ding</surname><given-names>Xingzhong</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/651691/overview"/></contrib><contrib contrib-type="author"><name><surname>Kuang</surname><given-names>Qianliang</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/641510/overview"/></contrib><contrib contrib-type="author"><name><surname>Ata-UI-Karim</surname><given-names>Syed Tahir</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/317644/overview"/></contrib><contrib contrib-type="author"><name><surname>Cheng</surname><given-names>Tao</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/538981/overview"/></contrib><contrib contrib-type="author"><name><surname>Liu</surname><given-names>Xiaojun</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/324642/overview"/></contrib><contrib contrib-type="author"><name><surname>Tian</surname><given-names>Yongchao</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/561606/overview"/></contrib><contrib contrib-type="author"><name><surname>Zhu</surname><given-names>Yan</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/446195/overview"/></contrib><contrib contrib-type="author"><name><surname>Cao</surname><given-names>Weixing</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author"><name><surname>Cao</surname><given-names>Qiang</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="c001"><sup>*</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/380556/overview"/></contrib></contrib-group><aff id="aff1"><sup>1</sup><institution>National Engineering and Technology Center for Information Agriculture (NETCIA), Key Laboratory for Crop System Analysis and Decision Making, Ministry of Agriculture, Jiangsu Key Laboratory for Information Agriculture, Jiangsu Collaborative Innovation Center for the Technology and Application of Internet of Things, Nanjing Agricultural University</institution>, <addr-line>Nanjing</addr-line>, <country>China</country></aff><aff id="aff2"><sup>2</sup><institution>Key Laboratory of Soil Environment and Pollution Remediation, Institute of Soil Science, Chinese Academy of Sciences</institution>, <addr-line>Nanjing</addr-line>, <country>China</country></aff><author-notes><fn fn-type="edited-by"><p>Edited by: Yann Gu&#x000e9;don, Centre de coop&#x000e9;ration internationale en recherche agronomique pour le d&#x000e9;veloppement (CIRAD), France</p></fn><fn fn-type="edited-by"><p>Reviewed by: Ioannis Konstantinos Christodoulakis, National and Kapodistrian University of Athens, Greece; Francisco M. Padilla, University of Almer&#x000ed;a, Spain</p></fn><corresp id="c001">*Correspondence: Qiang Cao <email>qiangcao@njau.edu.cn</email></corresp><fn fn-type="other" id="fn001"><p>This article was submitted to Technical Advances in Plant Science, a section of the journal Frontiers in Plant Science</p></fn></author-notes><pub-date pub-type="epub"><day>14</day><month>12</month><year>2018</year></pub-date><pub-date pub-type="collection"><year>2018</year></pub-date><volume>9</volume><elocation-id>1834</elocation-id><history><date date-type="received"><day>16</day><month>7</month><year>2018</year></date><date date-type="accepted"><day>27</day><month>11</month><year>2018</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2018 Li, Ding, Kuang, Ata-UI-Karim, Cheng, Liu, Tian, Zhu, Cao and Cao.</copyright-statement><copyright-year>2018</copyright-year><copyright-holder>Li, Ding, Kuang, Ata-UI-Karim, Cheng, Liu, Tian, Zhu, Cao and Cao</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p></license></permissions><abstract><p>Unmanned aerial vehicle (UAV) based active canopy sensors can serve as a promising sensing solution for the estimation of crop nitrogen (N) status with great applicability and flexibility. This study was endeavored to determine the feasibility of UAV-based active sensing to monitor the leaf N status of rice (<italic>Oryza sativa</italic> L.) and to examine the transferability of handheld-based predictive models to UAV-based active sensing. In this 3-year multi-locational study, varied N-rates (0&#x02013;405 kg N ha<sup>&#x02212;1</sup>) field experiments were conducted using five rice varieties. Plant samples and sensing data were collected at critical growth stages for growth analysis and monitoring. The portable active canopy sensor RapidSCAN CS-45 with red, red edge, and near infrared wavebands was used in handheld mode and aerial mode on a gimbal under a multi-rotor UAV. The results showed the great potential of UAV-based active sensing for monitoring rice leaf N status. The vegetation index-based regression models were built and evaluated based on Akaike information criterion and independent validation to predict rice leaf dry matter, leaf area index, and leaf N accumulation. Vegetation indices composed of near-infrared and red edge bands (NDRE or RERVI) acquired at a 1.5 m aviation height had a good performance for the practical application. Future studies are needed on the proper operation mode and means for precision N management with this system.</p></abstract><kwd-group><kwd>active canopy sensor</kwd><kwd>RapidSCAN</kwd><kwd>red edge</kwd><kwd>ultra low-level airborne</kwd><kwd>sensing distance evaluation</kwd></kwd-group><counts><fig-count count="6"/><table-count count="8"/><equation-count count="8"/><ref-count count="61"/><page-count count="14"/><word-count count="9729"/></counts></article-meta></front><body><sec sec-type="intro" id="s1"><title>Introduction</title><p>Nitrogen (N) plays a vital role in improving crop growth and productivity (Novoa and Loomis, <xref rid="B42" ref-type="bibr">1981</xref>; Ata-Ul-Karim et al., <xref rid="B5" ref-type="bibr">2016</xref>). Over 200 million tons of N fertilizers are estimated to be used in 2018 and continue to increase at 1.8% per year (FAO (Food and Agriculture Organization of the United Nations), <xref rid="B17" ref-type="bibr">2015</xref>). However, over-application of N fertilizers is the alarming issue that has caused low N use efficiency, leading to N deposition and water eutrophication (Conant et al., <xref rid="B13" ref-type="bibr">2013</xref>; Liu et al., <xref rid="B32" ref-type="bibr">2013</xref>; Huang et al., <xref rid="B21" ref-type="bibr">2017</xref>). Therefore, it is imperative to develop highly efficient, reliable and practical methods for monitoring crop N status to meet the demand for precision N management (Miao et al., <xref rid="B35" ref-type="bibr">2011</xref>). Several traditional methods, such as the leaf color chart (Alam et al., <xref rid="B2" ref-type="bibr">2005</xref>) or destructive chemical analysis (Asner and Martin, <xref rid="B4" ref-type="bibr">2008</xref>) are limited by low efficiency, small-scale applicability, and professional experience requirements for accurate diagnosis. With the advances of optical sensors and remote sensing technology, crop N-status monitoring, and management based on the spectrum has been widely used in different crops (Saberioon et al., <xref rid="B46" ref-type="bibr">2014</xref>; Padilla et al., <xref rid="B43" ref-type="bibr">2018</xref>).</p><p>Many studies have been conducted on the utilization of spaceborne and airborne passive remote sensing for crop monitoring. Satellite remote sensing provides great possibility for large-scale crop growth monitoring and precision management, for example, satellites images of FORMOSAT-2 were used for rice (<italic>Oryza sativa</italic> L.) N-status monitoring (Huang et al., <xref rid="B22" ref-type="bibr">2015</xref>); however, the quality of remote sensing images from passive sensor-based satellites would be affected by bad weather conditions like cloud and fog, leading to the lack of applicable in-season sensing datasets for crop monitoring. The unmanned aerial vehicle (UAV) emerges as a promising remote sensing platform owing to its flexibility (Yang et al., <xref rid="B58" ref-type="bibr">2017</xref>), and it was widely investigated for crop monitoring with imaging sensors (Maresma et al., <xref rid="B34" ref-type="bibr">2016</xref>). Rice grain yield and leaf area index (LAI) were predicted by multi-temporal vegetation indices (VIs) from UAV-based multispectral imagery (Zhou et al., <xref rid="B60" ref-type="bibr">2017</xref>), and the red edge (720 nm) and near-infrared (800 nm) band-based VIs were found to be more effective in the prediction of yield and LAI. However, despite the development of semi-automatic procedures, image processing, and analysis have still been too specialized and challenging for ordinary consumers until now.</p><p>Non-imaging optical canopy sensors directly collect standardized spectral reflectance with great flexibility in data achievement and processing over imaging sensors. Sensitive wave bands and VIs have been previously utilized for crop N-status estimation using passive hyperspectral canopy sensors (Tian et al., <xref rid="B55" ref-type="bibr">2014</xref>). In addition, passive multispectral sensors were also developed for crop monitoring (Ni et al., <xref rid="B38" ref-type="bibr">2016</xref>), and some of them were mounted on ground vehicle platforms (Pei et al., <xref rid="B44" ref-type="bibr">2014</xref>). Ni et al. (<xref rid="B39" ref-type="bibr">2017</xref>) designed a UAV-mounted crop-growth monitoring system based on a passive sensor with a red band and a near-infrared band, and it was proved to have potential for predicting wheat leaf nitrogen status with Normalized Difference Vegetation Index (NDVI) and Ratio Vegetation Index (RVI).</p><p>Active sensors were developed with an internal light source to avoid the calibration requirements for illumination and the light angle (Holland et al., <xref rid="B20" ref-type="bibr">2012</xref>). One of the superiorities is their potential to solve the problems of cloud cover and time limitations for measurements, which limit the use of passive sensors under such conditions (Stamatiadis et al., <xref rid="B53" ref-type="bibr">2010</xref>). Most studies focus on traditional two-band active canopy sensors (Danielw and Johne, <xref rid="B14" ref-type="bibr">2010</xref>; Samborski et al., <xref rid="B47" ref-type="bibr">2016</xref>), but three-band active canopy sensors like Crop Circle ACS-470 (Holland Scientific Inc., Lincoln, NE, USA) were reported to improve the estimating performance of winter wheat or rice N status as compared to two-band sensors (Cao et al., <xref rid="B10" ref-type="bibr">2015</xref>; Shi et al., <xref rid="B50" ref-type="bibr">2015</xref>). RapidSCAN CS-45 (Holland Scientific Inc., Lincoln, NE, USA) is a small-sized portable three-band active sensor which has been used in precision agriculture. The previous study on rice indicated that VIs calculated from RapidSCAN wavebands could diagnose the rice N nutrition index well (Lu et al., <xref rid="B33" ref-type="bibr">2017</xref>). In addition, studies on wheat, maize, soybean, and potato and soybean also showed the potential of the handheld RapidSCAN sensor to monitor crop N-status, to predict grain yield, and for cultivar selection, as well as for making nitrogen fertilizing recommendation (Bonfil, <xref rid="B7" ref-type="bibr">2016</xref>; Aranguren et al., <xref rid="B3" ref-type="bibr">2018</xref>; Miller et al., <xref rid="B36" ref-type="bibr">2018</xref>).</p><p>Consequently, UAV-based active sensing is expected to offer flexibility, affordability, and applicability for large-scale monitoring compared to handheld active sensing. In addition, researchers paid much attention to combining different sensing data for establishing universal sensing approaches which are suitable for a better sensing performance or wider scale application (Gevaert et al., <xref rid="B18" ref-type="bibr">2015</xref>; Schirrmann et al., <xref rid="B49" ref-type="bibr">2017</xref>). With a unique character of using the same kind of sensor with a similar sensing height, UAV-based active sensing has implied a hypothesis of transferring handheld-based predictive models to UAV-based active sensing.</p><p>However, considering previous studies with manned aircraft (Lamb et al., <xref rid="B29" ref-type="bibr">2009</xref>, <xref rid="B28" ref-type="bibr">2014</xref>) and unmanned aerial vehicles (Krienke et al., <xref rid="B27" ref-type="bibr">2017</xref>), still, little attention has been paid to investigate the possibility of applying active sensors on ultra low-altitude aerial vehicles. A potential issue for these studies was the effective sensing distance to accurately collect crop canopy reflectance. A unique feature of the RapidSCAN CS-45 is its ability to conduct height-independent spectral reflectance measurements named Pseudo Solar Reflectance (PSR) measurements introduced by its manufacturer. Based on this sensor specialty, Krienke et al. (<xref rid="B27" ref-type="bibr">2017</xref>) utilized the RapidSCAN CS-45 on a UAV platform for testing its applicable mode and proving its performance when evaluating maize N variability. In spite of the technical potential, sensing distance evaluation for practical application is still necessary.</p><p>Although the active canopy sensor RapidSCAN CS-45 has been proved to have applicability for diagnosing rice N-status using handheld mode (Lu et al., <xref rid="B33" ref-type="bibr">2017</xref>), the potential of UAV-based active sensing for rice N-status monitoring has not yet been tested. Therefore, the objectives of the current study were two-fold: (1) to determine whether UAV-based active sensing is feasible to monitor rice leaf N-status and (2) to examine the transferability of handheld-based predictive models to UAV-based active sensing.</p></sec><sec sec-type="materials and methods" id="s2"><title>Materials and Methods</title><sec><title>Study Area and Experimental Design</title><p>Field trials were carried out over three rice growing seasons (June&#x02013;October 2015&#x02013;2017) in Jiangsu Province of east China, which is a traditional rice-farming area with a long rice planting history (Figure <xref ref-type="fig" rid="F1">1</xref>). Trials were established at Rugao Experimental Station (32.27&#x000b0;N and 120.75&#x000b0;E, central-eastern Jiangsu) in 2015 and 2016, Sihong Experimental Station (33.37&#x000b0;N and 118.26&#x000b0;E, northern Jiangsu) in 2016, and Lianyungang Experimental Station (34.56&#x000b0;N and 119.32&#x000b0;E, northern Jiangsu) in 2017. Detailed information is presented in Table <xref rid="T1" ref-type="table">1</xref>.</p><fig id="F1" position="float"><label>Figure 1</label><caption><p>Study site: rice experiments conducted at Sihong, Lianyungang, and Rugao Experimental Station in Jiangsu Province of China.</p></caption><graphic xlink:href="fpls-09-01834-g0001"/></fig><table-wrap id="T1" position="float"><label>Table 1</label><caption><p>Description of field experiments conducted for calibration and validation.</p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top" align="left" rowspan="1" colspan="1"><bold>Experiment</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Sensing mode</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Location</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Varieties</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Number of samples</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Transplanting date</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Growth stages of sensing and sampling with DAT (d)</bold></th></tr></thead><tbody><tr><td valign="top" align="left" colspan="7" style="background-color:#bdbec1" rowspan="1"><bold>CALIBRATION EXPERIMENTS</bold></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Experiment 1 2016</td><td valign="top" align="left" rowspan="1" colspan="1">Hand-held</td><td valign="top" align="left" rowspan="1" colspan="1">Sihong</td><td valign="top" align="left" rowspan="1" colspan="1">Lianjing-7, Wuyunjing-24, Ningjing-4</td><td valign="top" align="left" rowspan="1" colspan="1">288</td><td valign="top" align="left" rowspan="1" colspan="1">25 June</td><td valign="top" align="left" rowspan="1" colspan="1">TI (27, 33), SE (39, 47), BT (54, 60), HD (76), FI (96)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Experiment 2 2017</td><td valign="top" align="left" rowspan="1" colspan="1">Hand-held</td><td valign="top" align="left" rowspan="1" colspan="1">Lianyun gang</td><td valign="top" align="left" rowspan="1" colspan="1">Lianjing-15, Zhongdao-1</td><td valign="top" align="left" rowspan="1" colspan="1">336</td><td valign="top" align="left" rowspan="1" colspan="1">19 June</td><td valign="top" align="left" rowspan="1" colspan="1">TI (27), SE (38, 45), BT (52, 62), HD (80), FI (90)</td></tr><tr><td valign="top" align="left" colspan="7" style="background-color:#bdbec1" rowspan="1"><bold>VALIDATION EXPERIMENTS</bold></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>Handheld Sensing</bold></td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Experiment 3 2015</td><td valign="top" align="left" rowspan="1" colspan="1">Hand-held</td><td valign="top" align="left" rowspan="1" colspan="1">Rugao</td><td valign="top" align="left" rowspan="1" colspan="1">Wuyunjing-24</td><td valign="top" align="left" rowspan="1" colspan="1">72</td><td valign="top" align="left" rowspan="1" colspan="1">15 June</td><td valign="top" align="left" rowspan="1" colspan="1">TI (29), SE (39, 45), BT (52, 57, 62)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Experiment 4 2016</td><td valign="top" align="left" rowspan="1" colspan="1">Hand-held</td><td valign="top" align="left" rowspan="1" colspan="1">Rugao</td><td valign="top" align="left" rowspan="1" colspan="1">Wuyunjing-24, Ningjing-4</td><td valign="top" align="left" rowspan="1" colspan="1">96</td><td valign="top" align="left" rowspan="1" colspan="1">15 June</td><td valign="top" align="left" rowspan="1" colspan="1">SE (40), SE (48), BT (57), HD (67)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>UAV-Based Sensing</bold></td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Experiment 2 2017</td><td valign="top" align="left" rowspan="1" colspan="1">UAV-based</td><td valign="top" align="left" rowspan="1" colspan="1">Lianyun gang</td><td valign="top" align="left" rowspan="1" colspan="1">Lianjing-15, Zhongdao-1</td><td valign="top" align="left" rowspan="1" colspan="1">192</td><td valign="top" align="left" rowspan="1" colspan="1">19 June</td><td valign="top" align="left" rowspan="1" colspan="1">SE (45), BT (52, 62),HD (80)</td></tr></tbody></table><table-wrap-foot><p><italic>DAT represents days after transplanting of each sensing and sampling procedure. TI, SE, BT, HD, and FI represent the growth stage of tillering, stem elongation, booting, heading, and filling, respectively</italic>.</p></table-wrap-foot></table-wrap><p>Experiment 1 was conducted at Sihong Experimental Station in 2016, which covered four N rates (0, 120, 240, 360 kg N ha<sup>&#x02212;1</sup>) and three rice varieties. Experiment 2 was conducted at Lianyungang Experimental Station in 2017, which covered four N rates (0, 135, 270, 405 kg N ha<sup>&#x02212;1</sup>), two transplanting ways (pot-seedling and carpet-seedling mechanical transplanting), and three rice varieties. Experiment 3 was conducted at Rugao Experimental Station in 2015, which covered four N rates (0, 60, 150, 240 kg N ha<sup>&#x02212;1</sup>) and one rice variety. Experiment 4 was conducted at Rugao Experimental Station in 2016, which covered four N rates (0, 100, 250, 400 kg N ha<sup>&#x02212;1</sup>) and two rice varieties.</p><p>All field experiments were arranged in a randomized complete block design with three replicates. Each plot size was 56 m<sup>2</sup> (7 &#x000d7; 8 m) in Experiment 1, 120 m<sup>2</sup> (8 &#x000d7; 15 m) in Experiment 2, and 35 m<sup>2</sup> (5 &#x000d7; 7 m) in Experiment 3 and Experiment 4. N fertilizer in all field experiments was applied in the form of granular urea as three splits: 50% before transplanting, 30% at the tillering stage, and 20% at the booting stage. For each plot, based on soil analysis and recommendations from the local agriculture department, 127 kg P<sub>2</sub>O<sub>5</sub> ha<sup>&#x02212;1</sup> was applied before transplanting in the form of Ca(H<sub>2</sub>PO<sub>4</sub>)<sub>2</sub> and 225 kg K<sub>2</sub>O ha<sup>&#x02212;1</sup> was applied as two splits: 50% before transplanting and 50% at the stem elongation stage. Carpet rice seedlings (for all the experiments) and pot rice seedlings (for Experiment 2) were prepared in seedling fields and transplanted into the experimental fields.</p></sec><sec><title>Active Canopy Sensor Data Collection</title><p>The active optical crop canopy sensor RapidSCAN CS-45 with three wavebands, including red (R, 670 nm), red-edge (Re, 730 nm), and near-infrared (NIR, over 780 nm) regions, was used in this study. Spectral reflectance (%) of each band and GPS data can be automatically collected and recorded in the memory module of the sensor at 2.5 Hz (one reading per 0.4 s) by modifying the logging method of the sensor. Data can be exported as a .csv file by PC software. Owing to the lightweight (0.8 kg) and wide measurement range (0.3 to 3 m height above the rice canopy) of the sensor, it is theoretically feasible to mount it on the UAV for practical application.</p><p>The multi-rotor UAV Spreading Wings S1000+ (DJI-Innovations Inc., Shenzhen, China) with DJI D-RTK GNSS system was used to provide a stable flight condition with accurate centimeter-level 3D positioning (Figure <xref ref-type="fig" rid="F2">2</xref>). The RapidSCAN CS-45 sensor was mounted on a customized gimbal in a fixed sensing posture under the UAV. In Experiment 2, controlled by the ground station program, the UAV aviated automatically according to the pre-concerted flight path along the central axis in the row direction of each plot with heights of 1.5 and 2 m above the canopy (resulting in 0.33 and 0.58 m<sup>2</sup> view area), respectively. The heading speed of the UAV was set as 2 m/s.</p><fig id="F2" position="float"><label>Figure 2</label><caption><p>Overview of the sensing equipment used in this study. <bold>(A)</bold> Spreading Wings S1000+ used as the sensing platform for low-altitude rice monitoring; <bold>(B)</bold> Flight controller module with DJI D-RTK GNSS system; <bold>(C)</bold> RapidSCAN CS-45 sensor mounted on a customized gimbal under the UAV; <bold>(D)</bold> RapidSCAN CS-45 sensor in handheld mode for data acquirement.</p></caption><graphic xlink:href="fpls-09-01834-g0002"/></fig><p>Handheld sensing in all experiments was conducted by the operator on approximately the same path as that of the UAV-based sensing using RapidSCAN CS-45. Sensor readings were collected ~1&#x02013;1.5 m above the rice canopy (resulting in 0.15&#x02013;0.33 m<sup>2</sup> view area).</p><p>Sensor data were processed in ArcMap 10.5 (ESRI, Redlands, CA, USA) and assigned to different sampling plots with the GPS position of each reading point. A buffer of 1 m was utilized to exclude data near the plot boundary. The average reflectance values collected by RapidSCAN CS-45 were computed to represent each plot both in UAV and handheld-based sensing. Calculated spectral vegetation indices used in this study are listed in Table <xref rid="T2" ref-type="table">2</xref>.</p><table-wrap id="T2" position="float"><label>Table 2</label><caption><p>Summary of the calculated spectral vegetation indices (VI) selected for this study.</p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top" align="left" rowspan="1" colspan="1"><bold>VI</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Formula</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>References</bold></th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1">Normalized difference red edge (NDRE)</td><td valign="top" align="left" rowspan="1" colspan="1">(NIR&#x02013;Re)/(NIR+Re)</td><td valign="top" align="left" rowspan="1" colspan="1">Barnes et al., <xref rid="B6" ref-type="bibr">2000</xref></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Red edge ratio vegetation index (RERVI)</td><td valign="top" align="left" rowspan="1" colspan="1">NIR/Re</td><td valign="top" align="left" rowspan="1" colspan="1">Jasper et al., <xref rid="B23" ref-type="bibr">2009</xref></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Normalized difference vegetation index (NDVI)</td><td valign="top" align="left" rowspan="1" colspan="1">(NIR&#x02013;R)/(NIR+R)</td><td valign="top" align="left" rowspan="1" colspan="1">Rouse et al., <xref rid="B45" ref-type="bibr">1973</xref></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Ratio vegetation index (RVI)</td><td valign="top" align="left" rowspan="1" colspan="1">NIR/R</td><td valign="top" align="left" rowspan="1" colspan="1">Jordan, <xref rid="B24" ref-type="bibr">1969</xref></td></tr></tbody></table><table-wrap-foot><p><italic>R, Re, and NIR indicate reflectance (%) collected by RapidSCAN at the band region of red, red edge, and near infrared, respectively</italic>.</p></table-wrap-foot></table-wrap></sec><sec><title>Plant Sampling and Measurement</title><p>Rice plant samples were acquired right after collecting sensing data. Destructive plant samples of above-ground parts were randomly collected (three hills per plot) from the sensed plants according to the average number of tillers. The samples were separated into leaves and stems. The separated leaves were scanned by Li-3000c (Li-Cor., Lincoln, NE, USA) to determine the leaf area index (LAI). Each sampled component was put into the oven for enzyme deactivation under 105&#x000b0;C for half an hour, and then under 80&#x000b0;C for 72 h for weighing. The weight of each leaf sample was used to determine the leaf dry matter (LDM). Leaf nitrogen concentration (LNC) was determined by the micro-Kjeldahl method (Bremner and Mulvaney, <xref rid="B9" ref-type="bibr">1982</xref>). Leaf nitrogen accumulation (LNA) was calculated by multiplying LDM and LNC. LDM, LAI, and LNA were selected as the nitrogen indicators in this study.</p></sec><sec><title>Data Analysis</title><p>As shown in Table <xref rid="T1" ref-type="table">1</xref>, to test the possibility of building universal predictive models for different applications, the handheld datasets from Experiment 1 and Experiment 2 were used for VI-based model calibration. The handheld datasets from Experiment 3 and Experiment 4 were used to validate the regression models. For examining the transferability of the models from handheld to UAV sensors, the models derived from the handheld data were applied to the UAV data from Experiment 2. Besides, the validation on UAV data were performed for two sensing heights (1.5 and 2 m above the canopy) to evaluate the stability of the UAV system over two sensing distances.</p><p>The mean value, standard deviation (SD), and coefficient of variation (CV, %) of rice agronomic parameters were calculated using SPSS 25 (SPSS Inc., Chicago, IL, USA). For simplicity and VI comparison purpose, N indicators were first predicted with single VI-based models. Therefore, linear and three types of non-linear models (quadratic, exponential, and power) were built and evaluated between each VI and each N indicator (LDM, LAI, and LNA). The basic function forms of linear (Equation 1), quadratic (Equation 2), exponential (Equation 3), and power (Equation 4) regressions are given by:
<disp-formula id="E1"><label>(1)</label><mml:math id="M1"><mml:mtable class="eqnarray" columnalign="right center left"><mml:mtr><mml:mtd><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mtext>&#x000a0;</mml:mtext><mml:mo>+</mml:mo><mml:mtext>&#x000a0;</mml:mtext><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>x</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
<disp-formula id="E2"><label>(2)</label><mml:math id="M2"><mml:mtable class="eqnarray" columnalign="right center left"><mml:mtr><mml:mtd><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mtext>&#x000a0;</mml:mtext><mml:mo>+</mml:mo><mml:mtext>&#x000a0;</mml:mtext><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mtext>&#x000a0;</mml:mtext><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
<disp-formula id="E3"><label>(3)</label><mml:math id="M3"><mml:mtable class="eqnarray" columnalign="right center left"><mml:mtr><mml:mtd><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>x</mml:mi></mml:mrow></mml:msup></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
<disp-formula id="E4"><label>(4)</label><mml:math id="M4"><mml:mtable class="eqnarray" columnalign="right center left"><mml:mtr><mml:mtd><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mtext>&#x000a0;</mml:mtext><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>where the response variable <italic>y</italic> represents the predicted N indicator (LDM, LAI, or LNA), and <italic>x</italic> represents the VI used for N-status estimation (NDRE, RERVI, NDVI, or RVI). The parameters <italic>a</italic><sub>0</sub>, <italic>a</italic><sub>1</sub>, <italic>b</italic><sub>0</sub>, <italic>b</italic><sub>1</sub>, <italic>b</italic><sub>2</sub>, <italic>c</italic><sub>0</sub>, <italic>c</italic><sub>1</sub>, <italic>d</italic><sub>0</sub>, and <italic>d</italic><sub>1</sub> were estimated using the least square method implemented in the R language environment (R Core Team).</p><p>The coefficient of determination (<italic>R</italic><sup>2</sup>) for each model was calculated to assess the calibration performance. <italic>R</italic><sup>2</sup> provides a measure of how well-observed outcomes are replicated by the model, based on the proportion of total variation of outcomes explained by the model (Draper and Smith, <xref rid="B16" ref-type="bibr">2014</xref>). However, <italic>R</italic><sup>2</sup> is not suitable to evaluate the predictive and fitting performance among models with different forms and different numbers of parameters, due to the risk of overfitting for models with higher <italic>R</italic><sup>2</sup> but more parameters.</p><p>Therefore, the Akaike Information Criterion (AIC) were further used for model selection in this study. The basic viewpoint of AIC is that the selected model is intended to accurately predict future data rather than to infer the &#x0201c;true distribution&#x0201d; of the calibration data (Akaike, <xref rid="B1" ref-type="bibr">1974</xref>; Shmueli, <xref rid="B51" ref-type="bibr">2010</xref>). Since the true predictive performance of a fitted model depends largely on the number of free parameters of the model, the AIC can be used to select model by penalizing for a large number of parameters and discouraging overfitting (Akaike, <xref rid="B1" ref-type="bibr">1974</xref>; Bozdogan, <xref rid="B8" ref-type="bibr">1987</xref>). The AIC is calculated using Equation 5.
<disp-formula id="E5"><label>(5)</label><mml:math id="M5"><mml:mtable class="eqnarray" columnalign="right center left"><mml:mtr><mml:mtd><mml:mtext>AIC</mml:mtext><mml:mo>=</mml:mo><mml:mtext>&#x000a0;</mml:mtext><mml:mn>2</mml:mn><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>2</mml:mn><mml:mtext>ln</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>where <italic>k</italic> is the number of estimated parameters in the model. In this study, including the terms of residual, <italic>k</italic> was 3 for linear, exponential, and power regressions and 4 for quadratic regression. <inline-formula><mml:math id="M7"><mml:mover accent="true"><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> is the maximum likelihood of the model for the data.</p><p>AICs of all the single VI-based regression models were calculated using function AIC in R language environment, which were further verified using self-complied function. The lowest value of AIC indicates the preferable model. The scatter diagrams of the selected VI-based models were plotted using GraphPad Prism 6 (GraphPad Software Inc., San Diego, CA, USA). With <italic>R</italic><sup>2</sup> and AIC, stepwise multiple linear regression models based on spectral reflectance of R, Re, and NIR bands were also evaluated to estimate LDM, LAI, and LNA.</p><p>Prediction for N indicators was further conducted in the independent validation datasets using the models above. The practical validation performance of the models was estimated by comparing <italic>R</italic><sup>2</sup>, relative root mean square error (RRMSE, %) and relative error (RE, %) between the predicted variable and the true observed variable. The higher the <italic>R</italic><sup>2</sup> and the lower the RRMSE and RE, the higher the precision and accuracy of the model for predicting plant N indicators. The formulas of RRMSE and RE are listed as below:
<disp-formula id="E6"><label>(6)</label><mml:math id="M8"><mml:mtable class="eqnarray" columnalign="right center left"><mml:mtr><mml:mtd><mml:mtext>RRMSE&#x000a0;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>%</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>100</mml:mn></mml:mrow><mml:mrow><mml:mover accent="false" class="mml-overline"><mml:mrow><mml:msub><mml:mrow><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo accent="true">&#x000af;</mml:mo></mml:mover></mml:mrow></mml:mfrac><mml:mtext>&#x000a0;</mml:mtext><mml:mo>&#x000d7;</mml:mo><mml:mtext>&#x000a0;</mml:mtext><mml:msqrt><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:mtext>&#x000a0;</mml:mtext><mml:mo>&#x000d7;</mml:mo><mml:mtext>&#x000a0;</mml:mtext><mml:mstyle displaystyle="true"><mml:munderover accentunder="false" accent="false"><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover></mml:mstyle><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msqrt></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
<disp-formula id="E7"><label>(7)</label><mml:math id="M9"><mml:mtable class="eqnarray" columnalign="right center left"><mml:mtr><mml:mtd><mml:mtext>RE&#x000a0;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>%</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>100</mml:mn><mml:mtext>&#x000a0;</mml:mtext><mml:mo>&#x000d7;</mml:mo><mml:mtext>&#x000a0;</mml:mtext><mml:msqrt><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:mtext>&#x000a0;</mml:mtext><mml:mo>&#x000d7;</mml:mo><mml:mtext>&#x000a0;</mml:mtext><mml:mstyle displaystyle="true"><mml:munderover accentunder="false" accent="false"><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover></mml:mstyle><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msqrt></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>where <italic>P</italic><sub><italic>i</italic></sub> and <italic>O</italic><sub><italic>i</italic></sub> are the predicted and observed value of the N indicator (LDM, LAI or LNA), respectively. <inline-formula><mml:math id="M10"><mml:mover accent="false" class="mml-overline"><mml:mrow><mml:msub><mml:mrow><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo accent="true">&#x000af;</mml:mo></mml:mover></mml:math></inline-formula> is the mean of observed value of the N indicator. <italic>n</italic> is the number of samples.</p></sec></sec><sec sec-type="results" id="s3"><title>Results</title><sec><title>Variability of Rice Leaf N-Status Indicators</title><p>Nitrogen-status indicators (LDM, LAI, and LNA) of rice varied greatly across different N rates, management practices, varieties, growth stages, sites, and years (Table <xref rid="T3" ref-type="table">3</xref>). For the calibration dataset, the LNA exhibited the most significant variation, with a CV of 73.92%, followed by LAI and LDM with a CV of 60.84 and 59.63%, respectively. Similar results were observed for the calibration dataset and validation datasets of handheld and UAV-based sensing. In total, 624 samples which have a wide range of LDM (51.93 kg ha<sup>&#x02212;1</sup> to 5313.40 kg ha<sup>&#x02212;1</sup>), LAI (0.13 to 10.34), and LNA (0.96 kg ha<sup>&#x02212;1</sup> to 192.61 kg ha<sup>&#x02212;1</sup>) were involved in the calibration experiments. The large variability of these parameters was supposed to cover the major possible situation and make it conceivable to evaluate the potential of using the RapidSCAN sensor for estimating and diagnosing rice leaf N status.</p><table-wrap id="T3" position="float"><label>Table 3</label><caption><p>Descriptive statistics of leaf dry matter (LDM), leaf area index (LAI), and leaf nitrogen accumulation (LNA) across different growth stages, varieties, sites, and years.</p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top" align="left" rowspan="1" colspan="1"><bold>Parameters</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>N</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Min</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Max</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Mean</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>SD</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>CV (%)</bold></th></tr></thead><tbody><tr><td valign="top" align="left" colspan="7" style="background-color:#bdbec1" rowspan="1"><bold>CALIBRATION DATASET</bold></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">LDM (kg ha<sup>&#x02212;1</sup>)</td><td valign="top" align="left" rowspan="1" colspan="1">624</td><td valign="top" align="left" rowspan="1" colspan="1">51.93</td><td valign="top" align="left" rowspan="1" colspan="1">5313.40</td><td valign="top" align="left" rowspan="1" colspan="1">1991.17</td><td valign="top" align="left" rowspan="1" colspan="1">1187.40</td><td valign="top" align="left" rowspan="1" colspan="1">59.63</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">LAI</td><td valign="top" align="left" rowspan="1" colspan="1">624</td><td valign="top" align="left" rowspan="1" colspan="1">0.13</td><td valign="top" align="left" rowspan="1" colspan="1">10.34</td><td valign="top" align="left" rowspan="1" colspan="1">3.60</td><td valign="top" align="left" rowspan="1" colspan="1">2.19</td><td valign="top" align="left" rowspan="1" colspan="1">60.84</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">LNA (kg ha<sup>&#x02212;1</sup>)</td><td valign="top" align="left" rowspan="1" colspan="1">624</td><td valign="top" align="left" rowspan="1" colspan="1">0.96</td><td valign="top" align="left" rowspan="1" colspan="1">192.61</td><td valign="top" align="left" rowspan="1" colspan="1">58.57</td><td valign="top" align="left" rowspan="1" colspan="1">43.29</td><td valign="top" align="left" rowspan="1" colspan="1">73.92</td></tr><tr><td valign="top" align="left" colspan="7" style="background-color:#bdbec1" rowspan="1"><bold>VALIDATION DATASET (HANDHELD)</bold></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">LDM (kg ha<sup>&#x02212;1</sup>)</td><td valign="top" align="left" rowspan="1" colspan="1">168</td><td valign="top" align="left" rowspan="1" colspan="1">165.19</td><td valign="top" align="left" rowspan="1" colspan="1">3589.63</td><td valign="top" align="left" rowspan="1" colspan="1">1580.72</td><td valign="top" align="left" rowspan="1" colspan="1">778.92</td><td valign="top" align="left" rowspan="1" colspan="1">49.28</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">LAI</td><td valign="top" align="left" rowspan="1" colspan="1">168</td><td valign="top" align="left" rowspan="1" colspan="1">0.29</td><td valign="top" align="left" rowspan="1" colspan="1">6.84</td><td valign="top" align="left" rowspan="1" colspan="1">2.70</td><td valign="top" align="left" rowspan="1" colspan="1">1.38</td><td valign="top" align="left" rowspan="1" colspan="1">51.23</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">LNA (kg ha<sup>&#x02212;1</sup>)</td><td valign="top" align="left" rowspan="1" colspan="1">168</td><td valign="top" align="left" rowspan="1" colspan="1">5.19</td><td valign="top" align="left" rowspan="1" colspan="1">117.38</td><td valign="top" align="left" rowspan="1" colspan="1">46.36</td><td valign="top" align="left" rowspan="1" colspan="1">24.38</td><td valign="top" align="left" rowspan="1" colspan="1">52.60</td></tr><tr><td valign="top" align="left" colspan="7" style="background-color:#bdbec1" rowspan="1"><bold>VALIDATION DATASET (UAV-BASED)</bold></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">LDM (kg ha<sup>&#x02212;1</sup>)</td><td valign="top" align="left" rowspan="1" colspan="1">192</td><td valign="top" align="left" rowspan="1" colspan="1">1238.73</td><td valign="top" align="left" rowspan="1" colspan="1">5313.40</td><td valign="top" align="left" rowspan="1" colspan="1">2906.11</td><td valign="top" align="left" rowspan="1" colspan="1">895.18</td><td valign="top" align="left" rowspan="1" colspan="1">30.80</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">LAI</td><td valign="top" align="left" rowspan="1" colspan="1">192</td><td valign="top" align="left" rowspan="1" colspan="1">2.25</td><td valign="top" align="left" rowspan="1" colspan="1">10.34</td><td valign="top" align="left" rowspan="1" colspan="1">5.54</td><td valign="top" align="left" rowspan="1" colspan="1">1.74</td><td valign="top" align="left" rowspan="1" colspan="1">31.40</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">LNA (kg ha<sup>&#x02212;1</sup>)</td><td valign="top" align="left" rowspan="1" colspan="1">192</td><td valign="top" align="left" rowspan="1" colspan="1">41.75</td><td valign="top" align="left" rowspan="1" colspan="1">187.36</td><td valign="top" align="left" rowspan="1" colspan="1">97.81</td><td valign="top" align="left" rowspan="1" colspan="1">35.50</td><td valign="top" align="left" rowspan="1" colspan="1">36.29</td></tr></tbody></table></table-wrap></sec><sec><title>Relationship Between N-Status Indicators and VIs Derived From Handheld System</title><p>The relationships between each N-status indicator and each VI were built using handheld data acquired from Experiment 1 and Experiment 2 (Table <xref rid="T4" ref-type="table">4</xref>). The performance of using individual VIs to estimate rice LDM, LAI, and LNA varied with the form of selected VI (NDRE, RERVI, NDVI, or RVI) and model type (linear, exponential, power, or quadratic regression model) across different growth stages, treatments, sites, and years.</p><table-wrap id="T4" position="float"><label>Table 4</label><caption><p><italic>R</italic><sup>2</sup> and AIC of the regression models between single VI (NDRE, RERVI, NDVI, or RVI) calculated from handheld sensing data (Experiment 1 and Experiment 2) and each rice N-status indicators (LDM, LAI, or LNA) across different stages of rice growth.</p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top" align="left" rowspan="1" colspan="1"><bold>N Indicator</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Model</bold></th><th valign="top" align="center" colspan="4" style="border-bottom: thin solid #000000;" rowspan="1"><italic><bold>R</bold></italic><sup><bold><bold>2</bold></bold></sup></th><th valign="top" align="center" colspan="4" style="border-bottom: thin solid #000000;" rowspan="1"><bold>AIC</bold></th></tr><tr><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1"/><th valign="top" align="center" rowspan="1" colspan="1"><bold>NDRE</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>RERVI</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>NDVI</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>RVI</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>NDRE</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>RERVI</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>NDVI</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>RVI</bold></th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1">LDM</td><td valign="top" align="center" rowspan="1" colspan="1">L</td><td valign="top" align="center" rowspan="1" colspan="1">0.73</td><td valign="top" align="center" rowspan="1" colspan="1">0.76</td><td valign="top" align="center" rowspan="1" colspan="1">0.62</td><td valign="top" align="center" rowspan="1" colspan="1">0.72</td><td valign="top" align="center" rowspan="1" colspan="1">9797.46</td><td valign="top" align="center" rowspan="1" colspan="1">9714.13</td><td valign="top" align="center" rowspan="1" colspan="1">10015.26</td><td valign="top" align="center" rowspan="1" colspan="1"><bold>9814.69</bold></td></tr><tr><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1">Q</td><td valign="top" align="center" rowspan="1" colspan="1">0.77</td><td valign="top" align="center" rowspan="1" colspan="1">0.77</td><td valign="top" align="center" rowspan="1" colspan="1">0.71</td><td valign="top" align="center" rowspan="1" colspan="1">0.72</td><td valign="top" align="center" rowspan="1" colspan="1">9700.58</td><td valign="top" align="center" rowspan="1" colspan="1"><bold>9689.73</bold></td><td valign="top" align="center" rowspan="1" colspan="1">9837.87</td><td valign="top" align="center" rowspan="1" colspan="1">9816.58</td></tr><tr><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1">E</td><td valign="top" align="center" rowspan="1" colspan="1">0.77</td><td valign="top" align="center" rowspan="1" colspan="1">0.76</td><td valign="top" align="center" rowspan="1" colspan="1">0.72</td><td valign="top" align="center" rowspan="1" colspan="1">0.67</td><td valign="top" align="center" rowspan="1" colspan="1"><bold>9690.36</bold></td><td valign="top" align="center" rowspan="1" colspan="1">9724.91</td><td valign="top" align="center" rowspan="1" colspan="1"><bold>9813.97</bold></td><td valign="top" align="center" rowspan="1" colspan="1">9912.96</td></tr><tr><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1">P</td><td valign="top" align="center" rowspan="1" colspan="1">0.76</td><td valign="top" align="center" rowspan="1" colspan="1">0.77</td><td valign="top" align="center" rowspan="1" colspan="1">0.71</td><td valign="top" align="center" rowspan="1" colspan="1">0.72</td><td valign="top" align="center" rowspan="1" colspan="1">9711.62</td><td valign="top" align="center" rowspan="1" colspan="1">9693.34</td><td valign="top" align="center" rowspan="1" colspan="1">9837.56</td><td valign="top" align="center" rowspan="1" colspan="1">9818.67</td></tr><tr style="border-top: thin solid #000000;"><td valign="top" align="left" rowspan="1" colspan="1">LAI</td><td valign="top" align="center" rowspan="1" colspan="1">L</td><td valign="top" align="center" rowspan="1" colspan="1">0.73</td><td valign="top" align="center" rowspan="1" colspan="1">0.79</td><td valign="top" align="center" rowspan="1" colspan="1">0.57</td><td valign="top" align="center" rowspan="1" colspan="1">0.69</td><td valign="top" align="center" rowspan="1" colspan="1">1938.76</td><td valign="top" align="center" rowspan="1" colspan="1">1829.15</td><td valign="top" align="center" rowspan="1" colspan="1">2223.73</td><td valign="top" align="center" rowspan="1" colspan="1">2024.99</td></tr><tr><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1">Q</td><td valign="top" align="center" rowspan="1" colspan="1">0.79</td><td valign="top" align="center" rowspan="1" colspan="1">0.79</td><td valign="top" align="center" rowspan="1" colspan="1">0.68</td><td valign="top" align="center" rowspan="1" colspan="1">0.69</td><td valign="top" align="center" rowspan="1" colspan="1">1790.44</td><td valign="top" align="center" rowspan="1" colspan="1"><bold>1773.23</bold></td><td valign="top" align="center" rowspan="1" colspan="1">2062.38</td><td valign="top" align="center" rowspan="1" colspan="1"><bold>2023.95</bold></td></tr><tr><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1">E</td><td valign="top" align="center" rowspan="1" colspan="1">0.79</td><td valign="top" align="center" rowspan="1" colspan="1">0.77</td><td valign="top" align="center" rowspan="1" colspan="1">0.69</td><td valign="top" align="center" rowspan="1" colspan="1">0.66</td><td valign="top" align="center" rowspan="1" colspan="1"><bold>1783.84</bold></td><td valign="top" align="center" rowspan="1" colspan="1">1774.63</td><td valign="top" align="center" rowspan="1" colspan="1"><bold>2053.46</bold></td><td valign="top" align="center" rowspan="1" colspan="1">2061.91</td></tr><tr><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1">P</td><td valign="top" align="center" rowspan="1" colspan="1">0.78</td><td valign="top" align="center" rowspan="1" colspan="1">0.79</td><td valign="top" align="center" rowspan="1" colspan="1">0.67</td><td valign="top" align="center" rowspan="1" colspan="1">0.69</td><td valign="top" align="center" rowspan="1" colspan="1">1872.64</td><td valign="top" align="center" rowspan="1" colspan="1">1774.85</td><td valign="top" align="center" rowspan="1" colspan="1">2123.53</td><td valign="top" align="center" rowspan="1" colspan="1">2025.00</td></tr><tr style="border-top: thin solid #000000;"><td valign="top" align="left" rowspan="1" colspan="1">LNA</td><td valign="top" align="center" rowspan="1" colspan="1">L</td><td valign="top" align="center" rowspan="1" colspan="1">0.74</td><td valign="top" align="center" rowspan="1" colspan="1">0.79</td><td valign="top" align="center" rowspan="1" colspan="1">0.54</td><td valign="top" align="center" rowspan="1" colspan="1">0.69</td><td valign="top" align="center" rowspan="1" colspan="1">5646.06</td><td valign="top" align="center" rowspan="1" colspan="1">5494.90</td><td valign="top" align="center" rowspan="1" colspan="1">6000.31</td><td valign="top" align="center" rowspan="1" colspan="1">5755.80</td></tr><tr><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1">Q</td><td valign="top" align="center" rowspan="1" colspan="1">0.82</td><td valign="top" align="center" rowspan="1" colspan="1">0.83</td><td valign="top" align="center" rowspan="1" colspan="1">0.67</td><td valign="top" align="center" rowspan="1" colspan="1">0.70</td><td valign="top" align="center" rowspan="1" colspan="1">5395.70</td><td valign="top" align="center" rowspan="1" colspan="1">5368.26</td><td valign="top" align="center" rowspan="1" colspan="1">5785.49</td><td valign="top" align="center" rowspan="1" colspan="1">5735.20</td></tr><tr><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1">E</td><td valign="top" align="center" rowspan="1" colspan="1">0.83</td><td valign="top" align="center" rowspan="1" colspan="1">0.82</td><td valign="top" align="center" rowspan="1" colspan="1">0.70</td><td valign="top" align="center" rowspan="1" colspan="1">0.66</td><td valign="top" align="center" rowspan="1" colspan="1"><bold>5365.18</bold></td><td valign="top" align="center" rowspan="1" colspan="1">5400.18</td><td valign="top" align="center" rowspan="1" colspan="1"><bold>5732.86</bold></td><td valign="top" align="center" rowspan="1" colspan="1">5797.87</td></tr><tr><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1">P</td><td valign="top" align="center" rowspan="1" colspan="1">0.82</td><td valign="top" align="center" rowspan="1" colspan="1">0.83</td><td valign="top" align="center" rowspan="1" colspan="1">0.69</td><td valign="top" align="center" rowspan="1" colspan="1">0.70</td><td valign="top" align="center" rowspan="1" colspan="1">5400.34</td><td valign="top" align="center" rowspan="1" colspan="1"><bold>5366.70</bold></td><td valign="top" align="center" rowspan="1" colspan="1">5748.31</td><td valign="top" align="center" rowspan="1" colspan="1"><bold>5731.78</bold></td></tr></tbody></table><table-wrap-foot><p><italic>L, Q, E, and P represent linear, quadratic, exponential, and power regression models, respectively. The numbers in bold represent the best model form for each VI to predict each N indicator based on AIC</italic>.</p></table-wrap-foot></table-wrap><p>Based on the AIC values of the models in Table <xref rid="T4" ref-type="table">4</xref>, the VIs calculated from NIR and Re reflectance (NDRE and RERVI) had preferable performance across different types of models as compared to VIs calculated from NIR and R reflectance (NDVI and RVI) for estimating LDM, LAI, and LNA, respectively. By comparing the models of the same type (linear, quadratic, exponential, and power models respectively), NDRE and RERVI had higher <italic>R</italic><sup>2</sup> values over NDVI and RVI for estimating rice leaf N indicators.</p><p>A total of 12 best models were selected for each N indicator and each VI based on AIC. Scatter diagrams of the selected models are presented in Figure <xref ref-type="fig" rid="F3">3</xref>. Overall, RERVI had great potential for estimating LDM (<italic>R</italic><sup>2</sup> = 0.77) and LAI (<italic>R</italic><sup>2</sup> = 0.79) with quadratic regression models, and the NDRE had the lowest AIC in exponential model for LNA prediction (<italic>R</italic><sup>2</sup> = 0.83). On the other side, obvious saturation effect and relatively poor predictive results were shown by NDVI in the scatter diagrams. For practical application, the predictive models were further evaluated in the following validation analysis.</p><fig id="F3" position="float"><label>Figure 3</label><caption><p>The best relationships based on AIC between each rice leaf N indicator [LDM <bold>(A&#x02013;D)</bold>, LAI <bold>(E&#x02013;H)</bold>, and LNA <bold>(I&#x02013;L)</bold>] and each VI by active canopy sensor RapidSCAN CS-45 across different growth stages, sites, and N treatments from the calibration experiments.</p></caption><graphic xlink:href="fpls-09-01834-g0003"/></fig></sec><sec><title>Validation of the Relationships Between N-Status Indicators and VIs Using Handheld Data</title><p>The regression models between VIs and N-status indicators selected in this study were further evaluated with other handheld sensing data acquired from validation experiments (Table <xref rid="T5" ref-type="table">5</xref>). The scatter diagrams for the best handheld validation results of VI-based predictions (determined by the lowest RE) are shown in Figure <xref ref-type="fig" rid="F4">4</xref>.</p><table-wrap id="T5" position="float"><label>Table 5</label><caption><p>Validation results of the selected single VI-based models for estimating N-status indicators with handheld sensing data.</p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top" align="center" rowspan="1" colspan="1"><bold>VI</bold></th><th valign="top" align="center" colspan="4" style="border-bottom: thin solid #000000;" rowspan="1"><bold>LDM</bold></th><th valign="top" align="center" colspan="4" style="border-bottom: thin solid #000000;" rowspan="1"><bold>LAI</bold></th><th valign="top" align="center" colspan="4" style="border-bottom: thin solid #000000;" rowspan="1"><bold>LNA</bold></th></tr><tr><th rowspan="1" colspan="1"/><th valign="top" align="center" rowspan="1" colspan="1"><bold>Type</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold><italic>R</italic><sup><bold>2</bold></sup></bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>RRMSE</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>RE</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Type</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>R<sup><bold>2</bold></sup></bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>RRMSE</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>RE</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Type</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>R<sup><bold>2</bold></sup></bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>RRMSE</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>RE</bold></th></tr></thead><tbody><tr><td valign="top" align="center" rowspan="1" colspan="1">NDRE</td><td valign="top" align="center" rowspan="1" colspan="1">E</td><td valign="top" align="center" rowspan="1" colspan="1">0.73</td><td valign="top" align="center" rowspan="1" colspan="1">30.5%</td><td valign="top" align="center" rowspan="1" colspan="1">36.0%</td><td valign="top" align="center" rowspan="1" colspan="1">E</td><td valign="top" align="center" rowspan="1" colspan="1">0.75</td><td valign="top" align="center" rowspan="1" colspan="1">28.6%</td><td valign="top" align="center" rowspan="1" colspan="1">32.7%</td><td valign="top" align="center" rowspan="1" colspan="1">E</td><td valign="top" align="center" rowspan="1" colspan="1">0.78</td><td valign="top" align="center" rowspan="1" colspan="1">37.2%</td><td valign="top" align="center" rowspan="1" colspan="1">29.8%</td></tr><tr><td valign="top" align="center" rowspan="1" colspan="1">RERVI</td><td valign="top" align="center" rowspan="1" colspan="1">Q</td><td valign="top" align="center" rowspan="1" colspan="1">0.73</td><td valign="top" align="center" rowspan="1" colspan="1">30.0%</td><td valign="top" align="center" rowspan="1" colspan="1">32.0%</td><td valign="top" align="center" rowspan="1" colspan="1">Q</td><td valign="top" align="center" rowspan="1" colspan="1">0.75</td><td valign="top" align="center" rowspan="1" colspan="1">29.2%</td><td valign="top" align="center" rowspan="1" colspan="1">33.1%</td><td valign="top" align="center" rowspan="1" colspan="1">P</td><td valign="top" align="center" rowspan="1" colspan="1">0.78</td><td valign="top" align="center" rowspan="1" colspan="1">36.9%</td><td valign="top" align="center" rowspan="1" colspan="1">29.2%</td></tr><tr><td valign="top" align="center" rowspan="1" colspan="1">NDVI</td><td valign="top" align="center" rowspan="1" colspan="1">E</td><td valign="top" align="center" rowspan="1" colspan="1">0.47</td><td valign="top" align="center" rowspan="1" colspan="1">42.4%</td><td valign="top" align="center" rowspan="1" colspan="1">55.2%</td><td valign="top" align="center" rowspan="1" colspan="1">E</td><td valign="top" align="center" rowspan="1" colspan="1">0.41</td><td valign="top" align="center" rowspan="1" colspan="1">50.0%</td><td valign="top" align="center" rowspan="1" colspan="1">64.6%</td><td valign="top" align="center" rowspan="1" colspan="1">E</td><td valign="top" align="center" rowspan="1" colspan="1">0.48</td><td valign="top" align="center" rowspan="1" colspan="1">45.7%</td><td valign="top" align="center" rowspan="1" colspan="1">55.3%</td></tr><tr><td valign="top" align="center" rowspan="1" colspan="1">RVI</td><td valign="top" align="center" rowspan="1" colspan="1">L</td><td valign="top" align="center" rowspan="1" colspan="1">0.46</td><td valign="top" align="center" rowspan="1" colspan="1">41.8%</td><td valign="top" align="center" rowspan="1" colspan="1">56.2%</td><td valign="top" align="center" rowspan="1" colspan="1">Q</td><td valign="top" align="center" rowspan="1" colspan="1">0.40</td><td valign="top" align="center" rowspan="1" colspan="1">48.4%</td><td valign="top" align="center" rowspan="1" colspan="1">65.0%</td><td valign="top" align="center" rowspan="1" colspan="1">P</td><td valign="top" align="center" rowspan="1" colspan="1">0.47</td><td valign="top" align="center" rowspan="1" colspan="1">42.8%</td><td valign="top" align="center" rowspan="1" colspan="1">51.7%</td></tr></tbody></table><table-wrap-foot><p><italic>L, Q, E, and P represent linear, quadratic, exponential, and power regression models, respectively</italic>.</p></table-wrap-foot></table-wrap><fig id="F4" position="float"><label>Figure 4</label><caption><p>Validation results of LDM <bold>(A)</bold>, LAI <bold>(B)</bold>, and LNA <bold>(C)</bold> for single VI-based predictions using validation datasets of handheld (HH) sensing.</p></caption><graphic xlink:href="fpls-09-01834-g0004"/></fig><p>In the validation results between the predicted and observed N indicators, comparing NDRE with NDVI and RERVI with RVI, the VIs calculated from NIR and Re reflectance had lower RRMSE and RE than the VIs calculated from NIR and R reflectance. This showed the great potential of NDRE and RERVI for N-status estimation.</p><p>Considering the relatively slight variation of RRMSE across different VI-based models to estimate each N-status indicator, REs were compared to evaluate the models for the best handheld data-based validation (Figure <xref ref-type="fig" rid="F4">4</xref>). For LDM, RERVI performed the best using a quadratic regression model (RRMSE = 30.0%, and RE = 32.0%) in validation. While for LAI estimation, using an exponential regression model, NDRE performed better than other selected models (RRMSE = 28.6%, and RE = 32.7%). RERVI had the best validation performance by using a power regression model to estimate LNA (RRMSE = 36.9%, and RE = 29.2%).</p></sec><sec><title>Validation of the Models Between N-Status Indicators and VIs Using UAV-Based Data</title><p>All the selected models were also evaluated with UAV-based data from validation experiments for testing the feasibility of applying the UAV-based RapidSCAN CS-45 for monitoring rice leaf N-status with models derived from handheld data (Table <xref rid="T6" ref-type="table">6</xref>). The UAV-based data contain two parts which were achieved from the UAV-based sensing with a 1.5 and 2 m height above the rice canopy, respectively. Scatter diagrams for UAV-based validation results of VI-based predictions with the best models (determined by the lowest RE) are shown in Figure <xref ref-type="fig" rid="F5">5</xref>.</p><table-wrap id="T6" position="float"><label>Table 6</label><caption><p>Validation results of the selected single VI-based models for estimating rice N-status indicators with UAV-based sensing data.</p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top" align="center" rowspan="1" colspan="1"><bold>VI</bold></th><th valign="top" align="center" colspan="4" style="border-bottom: thin solid #000000;" rowspan="1"><bold>LDM</bold></th><th valign="top" align="center" colspan="4" style="border-bottom: thin solid #000000;" rowspan="1"><bold>LAI</bold></th><th valign="top" align="center" colspan="4" style="border-bottom: thin solid #000000;" rowspan="1"><bold>LNA</bold></th></tr><tr><th rowspan="1" colspan="1"/><th valign="top" align="center" rowspan="1" colspan="1"><bold>Type</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>R<sup><bold>2</bold></sup></bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>RRMSE</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>RE</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Type</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>R<sup><bold>2</bold></sup></bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>RRMSE</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>RE</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Type</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>R<sup><bold>2</bold></sup></bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>RRMSE</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>RE</bold></th></tr></thead><tbody><tr><td valign="top" align="center" colspan="13" style="background-color:#bdbec1" rowspan="1"><bold>VALIDATION DATA: UAV-1.5 M</bold></td></tr><tr><td valign="top" align="center" rowspan="1" colspan="1">NDRE</td><td valign="top" align="center" rowspan="1" colspan="1">E</td><td valign="top" align="center" rowspan="1" colspan="1">0.74</td><td valign="top" align="center" rowspan="1" colspan="1">15.9%</td><td valign="top" align="center" rowspan="1" colspan="1">18.3%</td><td valign="top" align="center" rowspan="1" colspan="1">E</td><td valign="top" align="center" rowspan="1" colspan="1">0.67</td><td valign="top" align="center" rowspan="1" colspan="1">18.0%</td><td valign="top" align="center" rowspan="1" colspan="1">19.7%</td><td valign="top" align="center" rowspan="1" colspan="1">E</td><td valign="top" align="center" rowspan="1" colspan="1">0.71</td><td valign="top" align="center" rowspan="1" colspan="1">19.8%</td><td valign="top" align="center" rowspan="1" colspan="1">21.0%</td></tr><tr><td valign="top" align="center" rowspan="1" colspan="1">RERVI</td><td valign="top" align="center" rowspan="1" colspan="1">Q</td><td valign="top" align="center" rowspan="1" colspan="1">0.74</td><td valign="top" align="center" rowspan="1" colspan="1">16.0%</td><td valign="top" align="center" rowspan="1" colspan="1">18.6%</td><td valign="top" align="center" rowspan="1" colspan="1">Q</td><td valign="top" align="center" rowspan="1" colspan="1">0.67</td><td valign="top" align="center" rowspan="1" colspan="1">18.1%</td><td valign="top" align="center" rowspan="1" colspan="1">19.2%</td><td valign="top" align="center" rowspan="1" colspan="1">P</td><td valign="top" align="center" rowspan="1" colspan="1">0.71</td><td valign="top" align="center" rowspan="1" colspan="1">20.0%</td><td valign="top" align="center" rowspan="1" colspan="1">20.8%</td></tr><tr><td valign="top" align="center" rowspan="1" colspan="1">NDVI</td><td valign="top" align="center" rowspan="1" colspan="1">E</td><td valign="top" align="center" rowspan="1" colspan="1">0.49</td><td valign="top" align="center" rowspan="1" colspan="1">23.0%</td><td valign="top" align="center" rowspan="1" colspan="1">24.9%</td><td valign="top" align="center" rowspan="1" colspan="1">E</td><td valign="top" align="center" rowspan="1" colspan="1">0.46</td><td valign="top" align="center" rowspan="1" colspan="1">24.5%</td><td valign="top" align="center" rowspan="1" colspan="1">25.6%</td><td valign="top" align="center" rowspan="1" colspan="1">E</td><td valign="top" align="center" rowspan="1" colspan="1">0.48</td><td valign="top" align="center" rowspan="1" colspan="1">29.5%</td><td valign="top" align="center" rowspan="1" colspan="1">31.6%</td></tr><tr><td valign="top" align="center" rowspan="1" colspan="1">RVI</td><td valign="top" align="center" rowspan="1" colspan="1">L</td><td valign="top" align="center" rowspan="1" colspan="1">0.51</td><td valign="top" align="center" rowspan="1" colspan="1">23.9%</td><td valign="top" align="center" rowspan="1" colspan="1">25.1%</td><td valign="top" align="center" rowspan="1" colspan="1">Q</td><td valign="top" align="center" rowspan="1" colspan="1">0.48</td><td valign="top" align="center" rowspan="1" colspan="1">25.8%</td><td valign="top" align="center" rowspan="1" colspan="1">26.4%</td><td valign="top" align="center" rowspan="1" colspan="1">P</td><td valign="top" align="center" rowspan="1" colspan="1">0.49</td><td valign="top" align="center" rowspan="1" colspan="1">31.7%</td><td valign="top" align="center" rowspan="1" colspan="1">32.5%</td></tr><tr><td valign="top" align="center" colspan="13" style="background-color:#bdbec1" rowspan="1"><bold>VALIDATION DATA: UAV-2 M</bold></td></tr><tr><td valign="top" align="center" rowspan="1" colspan="1">NDRE</td><td valign="top" align="center" rowspan="1" colspan="1">E</td><td valign="top" align="center" rowspan="1" colspan="1">0.45</td><td valign="top" align="center" rowspan="1" colspan="1">24.7%</td><td valign="top" align="center" rowspan="1" colspan="1">28.8%</td><td valign="top" align="center" rowspan="1" colspan="1">E</td><td valign="top" align="center" rowspan="1" colspan="1">0.35</td><td valign="top" align="center" rowspan="1" colspan="1">26.7%</td><td valign="top" align="center" rowspan="1" colspan="1">32.5%</td><td valign="top" align="center" rowspan="1" colspan="1">E</td><td valign="top" align="center" rowspan="1" colspan="1">0.38</td><td valign="top" align="center" rowspan="1" colspan="1">30.6%</td><td valign="top" align="center" rowspan="1" colspan="1">37.0%</td></tr><tr><td valign="top" align="center" rowspan="1" colspan="1">RERVI</td><td valign="top" align="center" rowspan="1" colspan="1">L</td><td valign="top" align="center" rowspan="1" colspan="1">0.45</td><td valign="top" align="center" rowspan="1" colspan="1">23.8%</td><td valign="top" align="center" rowspan="1" colspan="1">28.7%</td><td valign="top" align="center" rowspan="1" colspan="1">Q</td><td valign="top" align="center" rowspan="1" colspan="1">0.35</td><td valign="top" align="center" rowspan="1" colspan="1">26.3%</td><td valign="top" align="center" rowspan="1" colspan="1">31.5%</td><td valign="top" align="center" rowspan="1" colspan="1">P</td><td valign="top" align="center" rowspan="1" colspan="1">0.38</td><td valign="top" align="center" rowspan="1" colspan="1">31.0%</td><td valign="top" align="center" rowspan="1" colspan="1">36.9%</td></tr><tr><td valign="top" align="center" rowspan="1" colspan="1">NDVI</td><td valign="top" align="center" rowspan="1" colspan="1">E</td><td valign="top" align="center" rowspan="1" colspan="1">0.31</td><td valign="top" align="center" rowspan="1" colspan="1">26.4%</td><td valign="top" align="center" rowspan="1" colspan="1">26.6%</td><td valign="top" align="center" rowspan="1" colspan="1">E</td><td valign="top" align="center" rowspan="1" colspan="1">0.25</td><td valign="top" align="center" rowspan="1" colspan="1">29.1%</td><td valign="top" align="center" rowspan="1" colspan="1">30.1%</td><td valign="top" align="center" rowspan="1" colspan="1">E</td><td valign="top" align="center" rowspan="1" colspan="1">0.30</td><td valign="top" align="center" rowspan="1" colspan="1">33.0%</td><td valign="top" align="center" rowspan="1" colspan="1">31.7%</td></tr><tr><td valign="top" align="center" rowspan="1" colspan="1">RVI</td><td valign="top" align="center" rowspan="1" colspan="1">L</td><td valign="top" align="center" rowspan="1" colspan="1">0.31</td><td valign="top" align="center" rowspan="1" colspan="1">26.7%</td><td valign="top" align="center" rowspan="1" colspan="1">26.6%</td><td valign="top" align="center" rowspan="1" colspan="1">Q</td><td valign="top" align="center" rowspan="1" colspan="1">0.25</td><td valign="top" align="center" rowspan="1" colspan="1">29.6%</td><td valign="top" align="center" rowspan="1" colspan="1">30.4%</td><td valign="top" align="center" rowspan="1" colspan="1">P</td><td valign="top" align="center" rowspan="1" colspan="1">0.30</td><td valign="top" align="center" rowspan="1" colspan="1">33.9%</td><td valign="top" align="center" rowspan="1" colspan="1">31.4%</td></tr></tbody></table><table-wrap-foot><p><italic>L, Q, E, and P represent linear, quadratic, exponential, and power regression models, respectively</italic>.</p></table-wrap-foot></table-wrap><fig id="F5" position="float"><label>Figure 5</label><caption><p>Validation results of LDM <bold>(A)</bold>, LAI <bold>(B)</bold>, and LNA <bold>(C)</bold> for single VI-based predictions using validation datasets of UAV-based sensing.</p></caption><graphic xlink:href="fpls-09-01834-g0005"/></fig><p>Compared with the validation performance of models from 2 m UAV-based data, VIs calculated from the same bands of 1.5 m UAV-based data better estimated LDM, LAI, and LNA. Hence, the best validation results were all from 1.5 m UAV-based datasets. This showed that the height of 1.5 m above the rice canopy is a suitable flight height for monitoring rice leaf N-status with the UAV-based RapidSCAN CS-45 sensor.</p><p>Similar to the validation results of handheld data, the results of <italic>R</italic><sup>2</sup>, RRMSE, and RE reveal that NDRE and RERVI had better performance than NDVI and RVI from the 1.5 m height sensing dataset. Determined by the REs, the best validation result for LDM estimation was presented in Figure 5 with NDRE-based exponential model (RRMSE = 15.9%, and RE = 18.3%). While RERVI performed the best for LAI (RRMSE = 18.1%, and RE = 19.2%) and LNA (RRMSE = 20.0%, and RE = 20.8%) monitoring in the UAV-based validation result based on the quadratic model and power model, respectively.</p></sec><sec><title>Stepwise Multiple Linear Regression Analysis</title><p>The handheld sensing data from the calibration experiments were pooled together to build stepwise regression models with reflectance of NIR, R, and Re bands to estimate N-status indicators in the calibration experiments (Table <xref rid="T7" ref-type="table">7</xref>). The results indicated that 74.6% of LDM variability could be explained with NIR and Re bands. The first chosen band for LAI was also the NIR band, followed by the Re band (<italic>R</italic><sup>2</sup> = 0.751). In contrast to the results of LDM and LAI, the R band was also chosen in the stepwise multiple linear regression models to estimate LNA after NIR and Re bands, and 77.6% of the variability of LNA could be explained. As one of the input selection rules of stepwise multiple linear regression, the AIC of the models decreased following the steps for LDM, LAI, and LNA estimation. The calibration and validation results (Table <xref rid="T8" ref-type="table">8</xref>) based on AIC indicated that these models did not perform better than the best VI-based models, as shown above.</p><table-wrap id="T7" position="float"><label>Table 7</label><caption><p>Stepwise multiple linear regression models based on RapidSCAN CS-45 bands (R, Re, and NIR, %) for estimating rice N-status indicators across growth stages.</p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top" align="left" rowspan="1" colspan="1"><bold>N Indicator</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Step</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Regression equation</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>R<sup><bold>2</bold></sup></bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>AIC</bold></th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1">LDM</td><td valign="top" align="left" rowspan="1" colspan="1">1</td><td valign="top" align="left" rowspan="1" colspan="1">199.902 * NIR-5466.137</td><td valign="top" align="left" rowspan="1" colspan="1">0.734</td><td valign="top" align="left" rowspan="1" colspan="1">9784.10</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">(kg ha<sup>&#x02212;1</sup>)</td><td valign="top" align="left" rowspan="1" colspan="1">2</td><td valign="top" align="left" rowspan="1" colspan="1">154.231 * NIR-182.546 * Re-136.377</td><td valign="top" align="left" rowspan="1" colspan="1">0.746</td><td valign="top" align="left" rowspan="1" colspan="1">9757.17</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">LAI</td><td valign="top" align="left" rowspan="1" colspan="1">1</td><td valign="top" align="left" rowspan="1" colspan="1">0.370 * NIR-10.189</td><td valign="top" align="left" rowspan="1" colspan="1">0.739</td><td valign="top" align="left" rowspan="1" colspan="1">1915.78</td></tr><tr><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">2</td><td valign="top" align="left" rowspan="1" colspan="1">0.285 * NIR-0.336 * Re-0.379</td><td valign="top" align="left" rowspan="1" colspan="1">0.751</td><td valign="top" align="left" rowspan="1" colspan="1">1888.42</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">LNA</td><td valign="top" align="left" rowspan="1" colspan="1">1</td><td valign="top" align="left" rowspan="1" colspan="1">7.393 * NIR-217.223</td><td valign="top" align="left" rowspan="1" colspan="1">0.755</td><td valign="top" align="left" rowspan="1" colspan="1">5599.62</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">(kg ha<sup>&#x02212;1</sup>)</td><td valign="top" align="left" rowspan="1" colspan="1">2</td><td valign="top" align="left" rowspan="1" colspan="1">5.834 * NIR-6.229 * Re - 35.348</td><td valign="top" align="left" rowspan="1" colspan="1">0.766</td><td valign="top" align="left" rowspan="1" colspan="1">5574.12</td></tr><tr><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">3</td><td valign="top" align="left" rowspan="1" colspan="1">6.932 * NIR-6.767-Re + 2.259 * R-84.355</td><td valign="top" align="left" rowspan="1" colspan="1">0.776</td><td valign="top" align="left" rowspan="1" colspan="1">5549.28</td></tr></tbody></table><table-wrap-foot><p><italic>R, Re, and NIR represent reflectance (%) of red (670 nm), red edge (730 nm), and near-infrared (780 nm) bands, respectively</italic>.</p></table-wrap-foot></table-wrap><table-wrap id="T8" position="float"><label>Table 8</label><caption><p>Validation results of the stepwise multiple linear regression models based on spectral reflectance of RapidSCAN CS-45 wavebands (R, Re, and NIR) for estimating rice N-status indicators with data acquired from handheld sensing, and UAV-based sensing of a 1.5 or 2 m height above the rice canopy.</p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top" align="left" rowspan="1" colspan="1"><bold>N-status indicators</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>R<sup><bold>2</bold></sup></bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>RRMSE</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>RE</bold></th></tr></thead><tbody><tr><td valign="top" align="left" colspan="4" style="background-color:#bdbec1" rowspan="1"><bold>VALIDATION DATA: HANDHELD (EXPERIMENT 3 AND EXPERIMENT 4)</bold></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">LDM (kg ha<sup>&#x02212;1</sup>)</td><td valign="top" align="center" rowspan="1" colspan="1">0.73</td><td valign="top" align="center" rowspan="1" colspan="1">27.6%</td><td valign="top" align="center" rowspan="1" colspan="1">32.2%</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">LAI</td><td valign="top" align="center" rowspan="1" colspan="1">0.74</td><td valign="top" align="center" rowspan="1" colspan="1">26.9%</td><td valign="top" align="center" rowspan="1" colspan="1">32.4%</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">LNA (kg ha<sup>&#x02212;1</sup>)</td><td valign="top" align="center" rowspan="1" colspan="1">0.80</td><td valign="top" align="center" rowspan="1" colspan="1">38.9%</td><td valign="top" align="center" rowspan="1" colspan="1">58.2%</td></tr><tr><td valign="top" align="left" colspan="4" style="background-color:#bdbec1" rowspan="1"><bold>VALIDATION DATA: UAV-1.5 M (EXPERIMENT 2)</bold></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">LDM (kg ha<sup>&#x02212;1</sup>)</td><td valign="top" align="center" rowspan="1" colspan="1">0.71</td><td valign="top" align="center" rowspan="1" colspan="1">18.1%</td><td valign="top" align="center" rowspan="1" colspan="1">20.7%</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">LAI</td><td valign="top" align="center" rowspan="1" colspan="1">0.65</td><td valign="top" align="center" rowspan="1" colspan="1">20.8%</td><td valign="top" align="center" rowspan="1" colspan="1">21.3%</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">LNA (kg ha<sup>&#x02212;1</sup>)</td><td valign="top" align="center" rowspan="1" colspan="1">0.69</td><td valign="top" align="center" rowspan="1" colspan="1">22.5%</td><td valign="top" align="center" rowspan="1" colspan="1">23.1%</td></tr><tr><td valign="top" align="left" colspan="4" style="background-color:#bdbec1" rowspan="1"><bold>VALIDATION DATA: UAV-2 M (EXPERIMENT 2)</bold></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">LDM (kg ha<sup>&#x02212;1</sup>)</td><td valign="top" align="center" rowspan="1" colspan="1">0.38</td><td valign="top" align="center" rowspan="1" colspan="1">24.9%</td><td valign="top" align="center" rowspan="1" colspan="1">29.8%</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">LAI</td><td valign="top" align="center" rowspan="1" colspan="1">0.29</td><td valign="top" align="center" rowspan="1" colspan="1">27.0%</td><td valign="top" align="center" rowspan="1" colspan="1">32.3%</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">LNA (kg ha<sup>&#x02212;1</sup>)</td><td valign="top" align="center" rowspan="1" colspan="1">0.27</td><td valign="top" align="center" rowspan="1" colspan="1">31.4%</td><td valign="top" align="center" rowspan="1" colspan="1">39.5%</td></tr></tbody></table></table-wrap></sec></sec><sec sec-type="discussion" id="s4"><title>Discussion</title><sec><title>Potential of UAV-Based Active Sensing for Rice N-Status Monitoring</title><p>UAV-based active sensing, as a new exploration of the low-altitude sensing method, is expected to be outstanding for crop N-status monitoring. But for testing the feasibility of the sensing system, it is critical to consider its superiorities compared to traditional methods and its actual performance from experimental results.</p><p>Ground-based sensing using handheld or ground vehicle-mounted spectrometers is recognized to be capable of describing crop trait expression and nutrient monitoring (Saberioon et al., <xref rid="B46" ref-type="bibr">2014</xref>; Yang et al., <xref rid="B58" ref-type="bibr">2017</xref>); however, the data collection instability, low sensing efficiency, and high cost are its limiting factors (Yang et al., <xref rid="B58" ref-type="bibr">2017</xref>). The paddy field condition has an influence on the sensing speed stability of ground-based sensing, which leads to spectral data variability and instability, and the footprints or wheel ruts may increase the influence and cause roots injured. The low sensing efficiency was shown in an example where more than 40 h were needed to collect 20,000 plots' spectral data on single rows using a single vehicle at speed about 0.56 m per second, and it would be more time-consuming by handheld sensing (about 0.5 m per second walking in paddy fields; White et al., <xref rid="B57" ref-type="bibr">2012</xref>). By contrast, UAV-based sensing has advantages regarding the sensing stability (controlled with an automatic ground station program), high sensing efficiency (e.g., with a 2 m per second heading aerial speed in this study), and relatively low cost (Yang et al., <xref rid="B58" ref-type="bibr">2017</xref>).</p><p>Traditional UAV-based sensing focuses on image-based utilization, and relevant studies differ a lot over the sensor use and crop species. UAV image-based sensing for crop monitoring is related to several issues like image capturing and mosaicing, geometric correction, spectral radiation processing, and useful feature extraction (Zhang and Kovacs, <xref rid="B59" ref-type="bibr">2012</xref>; Yang et al., <xref rid="B58" ref-type="bibr">2017</xref>). These complex processes have critical effects on the data compatibility, are time-consuming, and are closely related to the operator's experience (Zhang and Kovacs, <xref rid="B59" ref-type="bibr">2012</xref>). The standard utilization process and data output form are still lacking for the practical utilization of UAV image-based sensing for crop nitrogen estimation, which limits the eurytopic model building and high throughout plant-phenotypic data analysis using diverse datasets from different studies. By collecting standard spectral reflectance directly without data processing, UAV-based active sensing has convenience regarding data collection, and it is easy-to-use for common consumers compared to image-based sensing. In addition, a low sensing height offers the UAV-based active sensing with potential ability to collect more spectral information under canopy surface compared to UAV-based passive monitoring (Holland et al., <xref rid="B20" ref-type="bibr">2012</xref>; Yang et al., <xref rid="B58" ref-type="bibr">2017</xref>).</p><p>For testing the actual performance of UAV-based active sensing for rice leaf N monitoring, RapidSCAN CS-45 was chosen in this study. According to the manufacturer's instructions, the sensor can distinguish its own light signal from that of surrounding ambient light by modulating the light source (by rapidly pulsing the light source on and off many times a second). Therefore, this technology named PSR measurement ensures a degree of data stability within an effective sensing distance (0.3&#x02013;3 m above the canopy as introduced by the manufacturer), and this leads to the possibility of building universal predictive models for handheld and UAV-based sensing.</p><p>From the study of Krienke et al. (<xref rid="B27" ref-type="bibr">2017</xref>), a highly significant linear relationship was found between NDRE from handheld and UAV-based RapidSCAN sensing on a maize canopy, yet, the handheld data showed less variation as compared to UAV-based data collected with a fluctuating height from 0.5 to 1.5 m. Therefore, in this study, AIC-based optimum predictive models were built based on handheld datasets to estimate rice LDM (<italic>R</italic><sup>2</sup> = 0.77), LAI (<italic>R</italic><sup>2</sup> = 0.79), and LNA (<italic>R</italic><sup>2</sup> = 0.83), and it was also validated by independent handheld and UAV-based data for testing the model performance and the transferability of handheld-based sensing models to the UAV-based active sensing. The results showed great potential both for handheld and UAV-based sensing.</p></sec><sec><title>Evaluation of N-Status Prediction and Analysis for Saturation Effect of NDVI</title><p>An obvious saturation effect was observed with NDVI for crop N-status prediction as shown in Figure <xref ref-type="fig" rid="F3">3</xref>. NDVI saturation is a common view in previous studies. For example, NDVI achieved by the active canopy sensor GreenSeeker (Trimble Navigation Limited, Sunnyvale, CA, USA) could explain 80% of wheat biomass variability (Cao et al., <xref rid="B10" ref-type="bibr">2015</xref>); however, the saturation effect of NDVI is obviously existent. The applicability of NDVI for crop nutrition monitoring is probably due to the high transmittance of the NIR band and a degree of function of the red band (Knipling, <xref rid="B26" ref-type="bibr">1970</xref>). This leads to the saturation effect of NDVI (Thenkabail et al., <xref rid="B54" ref-type="bibr">2000</xref>).</p><p>Therefore, using wavelengths with similar penetration into the plant canopy may be one of the methods employed to overcome the NDVI saturation problems (Niel and McVicar, <xref rid="B40" ref-type="bibr">2004</xref>). The existing research has shown that the saturation problem could be reduced by the Re band, and Re-based VIs could be better correlated with crop N status (Delegido et al., <xref rid="B15" ref-type="bibr">2013</xref>). Re-radiation penetrates deeper into crop canopies due to lower absorption by chlorophyll compared to radiation at the red waveband. Therefore, the sensitivity of Re reflectance is higher than R reflectance (Kanke et al., <xref rid="B25" ref-type="bibr">2012</xref>; Zhou et al., <xref rid="B61" ref-type="bibr">2018</xref>). Considering the four kinds of vegetation indices selected in this study for rice N-status monitoring, the VIs calculated from NIR, and Re reflectance (NDRE or RERVI) performed better than the VIs calculated from NIR and R reflectance (NDVI or RVI) both in handheld and UAV-based datasets. With similar results, Re-based vegetation indices using Crop Circle ACS-470 sensor and satellite remote sensing images improved plant concentration and uptake estimation for maize (Li et al., <xref rid="B30" ref-type="bibr">2014</xref>). Moreover, NDRE and RERVI also performed more stably in UAV-based experiments in this study.</p><p>Another method consists in using ratio vegetation indices. The saturation effect is related to the normalization effect from the formula of normalized VIs, which could be avoided by the ratio VI to some degree (Gnyp et al., <xref rid="B19" ref-type="bibr">2014</xref>). According to Cao et al. (<xref rid="B10" ref-type="bibr">2015</xref>), RVI significantly reduced the saturation effect of NDVI for estimating aboveground biomass of wheat. Based on linear models (Table <xref rid="T4" ref-type="table">4</xref>), when comparing RVI with NDVI and RERVI with NDRE, the ratio VIs performed better for the N indicator prediction as compared to the normalized VIs (calculated by the same wavebands) in this study.</p><p>The RVI based on NIR and Re band (RERVI) was a great choice which combined two sides above. According to the potato experiment conducted by Zhou et al. (<xref rid="B61" ref-type="bibr">2018</xref>), a linear relationship was found between N concentration and RERVI, and this agrees with the fact that RERVI increased linearly with canopy chlorophyll content, as indicated by radiative transfer models from Clevers and Kooistra (<xref rid="B12" ref-type="bibr">2012</xref>). RERVI also had a good performance in calibration results compared to other VIs with linear regression models in this study.</p><p>For considering the three wavebands together, stepwise multiple linear regression analysis (SMLR) was conducted for N-status monitoring. Nevertheless, the multiple regression models did not perform significantly better than the best VI-based models. As shown by the stepwise linear regression results from the research by Cao et al. (<xref rid="B10" ref-type="bibr">2015</xref>), with Crop Circle ACS-470 employed on wheat across all growth stages, 53% of aboveground biomass variability and 67% of plant N uptake could be explained with two to three bands. However, the validation results also indicated that the stepwise linear regression models did not perform better than the best VI-based models. This is probably for the reason that only two or three bands were used for SMLR. If four to ten discrete wavebands could be used for SMLR, the performance of N-status monitoring would be significantly improved (Nguyen et al., <xref rid="B37" ref-type="bibr">2007</xref>; Cao et al., <xref rid="B11" ref-type="bibr">2013</xref>).</p><p>Besides, not only SMLR, but also some other models or methods such as support vector machines (SVM), artificial neural networks (ANN), and random forest (RF), have also been proved to have potential for monitoring crop N-status(Noh et al., <xref rid="B41" ref-type="bibr">2006</xref>; Wang et al., <xref rid="B56" ref-type="bibr">2013</xref>; Liang et al., <xref rid="B31" ref-type="bibr">2015</xref>). Superior methods (e.g., SVM, ANN, or RF) need to be tested in future studies of combining various spectral, spatial, and environmental information for a better crop N-status prediction.</p></sec><sec><title>Considerations for Practical Utilization of UAV-Based Active Sensing</title><p>This study has shown that the UAV mounted active canopy sensor is feasible for monitoring rice N-status, yet some points, including sensing distance, canopy perturbance from air movement, and the slightly unstable flight condition caused by the aerodynamic ground effect of a low-altitude flight, still need to be addressed for the practical use of this sensing system.</p><p>The first issue is the suitable sensing distance which differs a lot over sensor types. For instance, spectral data of Crop Circle ACS-210 were befittingly collected on an aircraft at an altitude of 3&#x02013;5 m above ground level on corn (Lamb et al., <xref rid="B29" ref-type="bibr">2009</xref>). The suitable measuring height was between 0.4 and 1.2 m above the wheat canopy with a passive sensor mounted on a sensor support on a UAV (Ni et al., <xref rid="B39" ref-type="bibr">2017</xref>). The sensing distance is directly reflected in the flight height above the canopy in this study, as the sensor posture has been fixed by the gimbal. Our validation results of the UAV-based dataset, which indicates that the height of 1.5 m above the rice canopy is much more suitable for rice N-status monitoring than 2 m, were in consensus with the result of distance sensitivity study on the turf grass canopy with UAV-mounted RapidSCAN CS-45 by Krienke et al. (<xref rid="B27" ref-type="bibr">2017</xref>). And this shows that spectral reflectance was affected by sensing distance and the UAV-based RapidSCAN sensor operated effectively within a range of 0.5&#x02013;1.5 m above the canopy.</p><p>Canopy perturbance from air movement generated by the UAV is also crucial to be considered while using UAV based data acquisition. The factors influencing canopy perturbance are numerous, which include but are not limited to flight height, speed, posture, surrounding air condition and air velocities influenced by aircraft design. In the study of a UAV-based passive sensor by Ni et al. (<xref rid="B39" ref-type="bibr">2017</xref>), after numerical computational fluid dynamics simulations, solar sensors, and two-band sensors were designed and fixed on the two ends of a long sensor support to avoid the down-wash flow field below the UAV and the system should be applied in a hovering state. However, long sensor support is not suitable for this study considering the dynamic flight state and the sensor character. In view of the technical restriction, computational fluid dynamics simulations were not conducted in this study. While, as shown in Figure <xref ref-type="fig" rid="F6">6</xref>, via several attempts by visual checks, the perturbed canopy area (marked by the yellow box) was at the back of the sensed area when the UAV was controlled to aviate with a height of above 1.5 m and heading speed of over 2 m/s.</p><fig id="F6" position="float"><label>Figure 6</label><caption><p>Top view and practical sensing state of the UAV-based sensing system with RapidSCAN CS-45. The height of the sensor under the UAV is 1.5 m above the rice canopy and flight speed in the heading direction is 2 m/s. The arrow symbol shows the heading flight direction of the UAV. The yellow box with increased brightness shows the perturbed canopy area generated by the UAV via a visual check.</p></caption><graphic xlink:href="fpls-09-01834-g0006"/></fig><p>Besides, sometimes a slightly unstable flight condition would be caused by the aerodynamic ground effect of a low-altitude flight, even though the effect is much lighter on multi-rotor UAVs than single-rotor helicopters (Sanchez-Cuevas et al., <xref rid="B48" ref-type="bibr">2017</xref>). Real-Time Kinematic GPS (RTK GPS) is a powerful technology, which can provide centimeter-level high accuracy 3D positioning of UAVs (Spockeli, <xref rid="B52" ref-type="bibr">2015</xref>). Therefore, to overcome the unstable condition caused by the aerodynamic ground effect, an RTK system designed for UAV is highly recommended. As shown in the UAV commissioning before the actual experiments in this study, flight condition is much more stable with the DJI D-RTK GNSS System than non-RTK utilization.</p><p>The height of 1 m above the rice canopy was also considered in the first test of UAV-based active sensing in Experiment 2. However, obvious canopy perturbance was generated under the UAV in that sensing mode. Moreover, the flight condition was unstable with a 1 m-height setting, and the flight height fluctuated from about a 0.5 to 1.2 m height above the canopy even with the D-RTK GNSS system. For data stability and experiment security, UAV-based sensing at a 1 m-height was canceled in the following tests. This unstable flight condition was probably caused by mixed reasons of the aerodynamic ground effect and the technical lack of accurate aerial positioning for proximal flight.</p></sec></sec><sec sec-type="conclusions" id="s5"><title>Conclusion</title><p>The calibration and validation results showed the great potential of active canopy sensor RapidSCAN CS-45 to monitor rice leaf N-status using both handheld and UAV-mounted modes. Great transferability of handheld-based predictive models to UAV-based sensing was verified by the UAV data-based validation experiment. Based on model evaluation and selection by AIC, 77, 79, and 83% of the variability in LDM, LAI, and LNA were explained with the optimal VI-based regression models derived from the calibration datasets, respectively. Considering different data acquired from UAV-based sensing and handheld sensing, NDRE and RERVI exhibited a much better performance in estimating rice N-status than the traditional R-based vegetation indices (NDVI and RVI), which also displayed great potential in overcoming the saturation problem of NDVI.</p><p>The present study has put forward a novel way of monitoring rice leaf N-status by the application of a multi-rotor unmanned aerial vehicle with a portable active canopy sensor. The height of 1.5 m above the rice canopy with a heading speed of 2 m/s was suitable for practical use. Future investigations are still needed to consider the combined effect of flight height, speed, canopy perturbance, ground effect, and new low-altitude location technology. Additionally, the entire automation workflow of data collection, processing for N status prediction, and management need to be developed for this sensing system in the future.</p></sec><sec id="s6"><title>Author Contributions</title><p>QC, YT, YZ, and WC conceived and designed the experiments. SL, XD and QK performed the experiments. SL and QC analyzed the data and wrote the original manuscript. SA, TC, XL, YT, YZ, and WC reviewed and revised the manuscript. All authors read and approved the final manuscript.</p><sec><title>Conflict of Interest Statement</title><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p></sec></sec></body><back><ack><p>We would like to thank Jun He, Zhonghua Li, and Jiameng Ni from the College of Agriculture in Nanjing Agricultural University for their field work and contributions to data collection. We would also like to thank Jufang Wang from the College of Foreign Studies in Nanjing Agricultural University for her contributions to English corrections.</p></ack><fn-group><fn fn-type="financial-disclosure"><p><bold>Funding.</bold> This research was funded by the National Key Research and Development Program (2016YFD0300608), the Fundamental Research Funds for the Central University (KYZ201502, KJQN201725), the National Natural Science Foundation of China (31601222), the Natural Science Foundation of Jiangsu Province (BK20150663), the Academic Program Development of Jiangsu Higher Education Institutions (PAPD), and the project for Student Research Training (SRT) in the College of Agriculture of Nanjing Agricultural University (1711C02).</p></fn></fn-group><ref-list><title>References</title><ref id="B1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Akaike</surname><given-names>H.</given-names></name></person-group> (<year>1974</year>). <article-title>A new look at the statistical model identification</article-title>. <source>IEEE Trans. Automatic Control</source>
<volume>19</volume>, <fpage>716</fpage>&#x02013;<lpage>723</lpage>. <pub-id pub-id-type="doi">10.1109/TAC.1974.1100705</pub-id></mixed-citation></ref><ref id="B2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alam</surname><given-names>M. M.</given-names></name><name><surname>Ladha</surname><given-names>J. K.</given-names></name><name><surname>Khan</surname><given-names>S. R.</given-names></name><name><surname>Foyjunnessa Harun-ur-Rashid</surname></name><name><surname>Khan</surname><given-names>A. H.</given-names></name><etal/></person-group> (<year>2005</year>). <article-title>Leaf color chart for managing nitrogen fertilizer in lowland rice in Bangladesh</article-title>. <source>Agron. J.</source>
<volume>97</volume>, <fpage>949</fpage>&#x02013;<lpage>959</lpage>. <pub-id pub-id-type="doi">10.2134/agronj2004.0206</pub-id></mixed-citation></ref><ref id="B3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aranguren</surname><given-names>M.</given-names></name><name><surname>Castell&#x000f3;n</surname><given-names>A.</given-names></name><name><surname>Aizpurua</surname><given-names>A.</given-names></name></person-group> (<year>2018</year>). <article-title>Topdressing nitrogen recommendation in wheat after applying organic manures: the use of field diagnostic tools</article-title>. <source>Nutr. Cycl. Agroecosyst.</source>
<volume>110</volume>, <fpage>89</fpage>&#x02013;<lpage>103</lpage>. <pub-id pub-id-type="doi">10.1007/S10705-017-9865-7</pub-id></mixed-citation></ref><ref id="B4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Asner</surname><given-names>G. P.</given-names></name><name><surname>Martin</surname><given-names>R. E.</given-names></name></person-group> (<year>2008</year>). <article-title>Spectral and chemical analysis of tropical forests: scaling from leaf to canopy levels</article-title>. <source>Remote Sens. Environ.</source>
<volume>112</volume>, <fpage>3958</fpage>&#x02013;<lpage>3970</lpage>. <pub-id pub-id-type="doi">10.1016/j.rse.2008.07.003</pub-id></mixed-citation></ref><ref id="B5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ata-Ul-Karim</surname><given-names>S. T.</given-names></name><name><surname>Liu</surname><given-names>X.</given-names></name><name><surname>Lu</surname><given-names>Z.</given-names></name><name><surname>Yuan</surname><given-names>Z.</given-names></name><name><surname>Zhu</surname><given-names>Y.</given-names></name><name><surname>Cao</surname><given-names>W.</given-names></name></person-group> (<year>2016</year>). <article-title>In-season estimation of rice grain yield using critical nitrogen dilution curve</article-title>. <source>Field Crops Res.</source>
<volume>195</volume>, <fpage>1</fpage>&#x02013;<lpage>8</lpage>. <pub-id pub-id-type="doi">10.1016/j.fcr.2016.04.027</pub-id></mixed-citation></ref><ref id="B6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barnes</surname><given-names>E. M.</given-names></name><name><surname>Clarke</surname><given-names>T. R.</given-names></name><name><surname>Richards</surname><given-names>S. E.</given-names></name><name><surname>Colaizzi</surname><given-names>P. D.</given-names></name><name><surname>Haberland</surname><given-names>J.</given-names></name><name><surname>Kostrzewski</surname><given-names>M.</given-names></name><etal/></person-group> (<year>2000</year>). <article-title>Coincident detection of crop water stress, nitrogen status and canopy density using ground-based multispectral data</article-title>, in <source>Proceedings of the Fifth International Conference on Precision Agriculture</source>, Madison, WI, 16&#x02013;19 July <volume>2000</volume>, <fpage>1</fpage>&#x02013;<lpage>15</lpage>.</mixed-citation></ref><ref id="B7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bonfil</surname><given-names>D. J.</given-names></name></person-group> (<year>2016</year>). <article-title>Wheat phenomics in the field by RapidScan: NDVI vs. NDRE</article-title>. <source>Israel J. Plant Sci.</source>
<volume>2016</volume>, <fpage>1</fpage>&#x02013;<lpage>14</lpage>. <pub-id pub-id-type="doi">10.1080/07929978.2016.1249135</pub-id></mixed-citation></ref><ref id="B8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bozdogan</surname><given-names>H.</given-names></name></person-group> (<year>1987</year>). <article-title>Model selection and Akaike's information criterion (AIC): the general theory and its analytical extensions</article-title>. <source>Psychometrika</source>
<volume>52</volume>, <fpage>345</fpage>&#x02013;<lpage>370</lpage>. <pub-id pub-id-type="doi">10.1007/BF02294361</pub-id></mixed-citation></ref><ref id="B9"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bremner</surname><given-names>J. M.</given-names></name><name><surname>Mulvaney</surname><given-names>C. S.</given-names></name></person-group> (<year>1982</year>). <article-title>Nitrogen-Total</article-title>, in <source>Methods of Soil Analysis, Part 2.</source> eds <person-group person-group-type="editor"><name><surname>Page</surname><given-names>A. L.</given-names></name><name><surname>Miller</surname><given-names>R. H.</given-names></name><name><surname>Keeney</surname><given-names>D.R.</given-names></name></person-group> (<publisher-loc>Madison, WI</publisher-loc>: <publisher-name>American Society of Agronomy</publisher-name>), <fpage>595</fpage>&#x02013;<lpage>624</lpage>.</mixed-citation></ref><ref id="B10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cao</surname><given-names>Q.</given-names></name><name><surname>Miao</surname><given-names>Y.</given-names></name><name><surname>Feng</surname><given-names>G.</given-names></name><name><surname>Gao</surname><given-names>X.</given-names></name><name><surname>Li</surname><given-names>F.</given-names></name><name><surname>Liu</surname><given-names>B.</given-names></name><etal/></person-group> (<year>2015</year>). <article-title>Active canopy sensing of winter wheat nitrogen status: an evaluation of two sensor systems</article-title>. <source>Comput. Electron. Agricult.</source>
<volume>112</volume>, <fpage>54</fpage>&#x02013;<lpage>67</lpage>. <pub-id pub-id-type="doi">10.1016/j.compag.2014.08.012</pub-id></mixed-citation></ref><ref id="B11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cao</surname><given-names>Q.</given-names></name><name><surname>Miao</surname><given-names>Y.</given-names></name><name><surname>Wang</surname><given-names>H.</given-names></name><name><surname>Huang</surname><given-names>S.</given-names></name><name><surname>Cheng</surname><given-names>S.</given-names></name><name><surname>Khosla</surname><given-names>R.</given-names></name><etal/></person-group> (<year>2013</year>). <article-title>Non-destructive estimation of rice plant nitrogen status with Crop Circle multispectral active canopy sensor</article-title>. <source>Field Crops Res.</source>
<volume>154</volume>, <fpage>133</fpage>&#x02013;<lpage>144</lpage>. <pub-id pub-id-type="doi">10.1016/j.fcr.2013.08.005</pub-id></mixed-citation></ref><ref id="B12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clevers</surname><given-names>J. G. P. W.</given-names></name><name><surname>Kooistra</surname><given-names>L.</given-names></name></person-group> (<year>2012</year>). <article-title>Using hyperspectral remote sensing data for retrieving canopy chlorophyll and nitrogen content</article-title>. <source>IEEE J. Select. Top. Appl. Earth Observ. Remote Sens.</source>
<volume>5</volume>, <fpage>574</fpage>&#x02013;<lpage>583</lpage>. <pub-id pub-id-type="doi">10.1109/JSTARS.2011.2176468</pub-id></mixed-citation></ref><ref id="B13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Conant</surname><given-names>R. T.</given-names></name><name><surname>Berdanier</surname><given-names>A. B.</given-names></name><name><surname>Grace</surname><given-names>P. R.</given-names></name></person-group> (<year>2013</year>). <article-title>Patterns and trends in nitrogen use and nitrogen recovery efficiency in world agriculture</article-title>. <source>Global Biogeochem. Cycles</source>
<volume>27</volume>, <fpage>558</fpage>&#x02013;<lpage>566</lpage>. <pub-id pub-id-type="doi">10.1002/gbc.20053</pub-id></mixed-citation></ref><ref id="B14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Danielw</surname><given-names>B.</given-names></name><name><surname>Johne</surname><given-names>S.</given-names></name></person-group> (<year>2010</year>). <article-title>Using active canopy sensors to quantify corn nitrogen stress and nitrogen application rate</article-title>. <source>Agron. J.</source>
<volume>102</volume>, <fpage>964</fpage>&#x02013;<lpage>971</lpage>. <pub-id pub-id-type="doi">10.2134/agronj2010.0004</pub-id></mixed-citation></ref><ref id="B15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Delegido</surname><given-names>J.</given-names></name><name><surname>Verrelst</surname><given-names>J.</given-names></name><name><surname>Meza</surname><given-names>C. M.</given-names></name><name><surname>Rivera</surname><given-names>J. P.</given-names></name><name><surname>Alonso</surname><given-names>L.</given-names></name><name><surname>Moreno</surname><given-names>J.</given-names></name></person-group> (<year>2013</year>). <article-title>A red-edge spectral index for remote sensing estimation of green LAI over agroecosystems</article-title>. <source>Eur. J. Agron.</source>
<volume>46</volume>, <fpage>42</fpage>&#x02013;<lpage>52</lpage>. <pub-id pub-id-type="doi">10.1016/j.eja.2012.12.001</pub-id></mixed-citation></ref><ref id="B16"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Draper</surname><given-names>N. R.</given-names></name><name><surname>Smith</surname><given-names>H.</given-names></name></person-group> (<year>2014</year>). <article-title>Fitting a straight line by least squares</article-title>, in <source>Applied Regression Analysis</source> (<publisher-loc>John Wiley &#x00026; Sons, Ltd</publisher-loc>), <fpage>15</fpage>&#x02013;<lpage>46</lpage>. <pub-id pub-id-type="doi">10.1002/9781118625590.ch1</pub-id></mixed-citation></ref><ref id="B17"><mixed-citation publication-type="book"><person-group person-group-type="author"><collab>FAO (Food and Agriculture Organization of the United Nations)</collab></person-group> (<year>2015</year>). <source>The State of Food Insecurity in the World 2015</source>. <publisher-loc>Rome</publisher-loc>. <?supplied-pmid 28140324?></mixed-citation></ref><ref id="B18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gevaert</surname><given-names>C. M.</given-names></name><name><surname>Suomalainen</surname><given-names>J.</given-names></name><name><surname>Tang</surname><given-names>J.</given-names></name><name><surname>Kooistra</surname><given-names>L.</given-names></name></person-group> (<year>2015</year>). <article-title>Generation of spectral&#x02013;temporal response surfaces by combining multispectral satellite and hyperspectral UAV imagery for precision agriculture applications</article-title>. <source>IEEE J. Select. Topics Appl. Earth Observ. Remote Sens.</source>
<volume>8</volume>, <fpage>3140</fpage>&#x02013;<lpage>3146</lpage>. <pub-id pub-id-type="doi">10.1109/JSTARS.2015.2406339</pub-id></mixed-citation></ref><ref id="B19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gnyp</surname><given-names>M. L.</given-names></name><name><surname>Miao</surname><given-names>Y.</given-names></name><name><surname>Yuan</surname><given-names>F.</given-names></name><name><surname>Ustin</surname><given-names>S. L.</given-names></name><name><surname>Yu</surname><given-names>K.</given-names></name><name><surname>Yao</surname><given-names>Y.</given-names></name><etal/></person-group> (<year>2014</year>). <article-title>Hyperspectral canopy sensing of paddy rice aboveground biomass at different growth stages</article-title>. <source>Field Crops Res.</source>
<volume>155</volume>, <fpage>42</fpage>&#x02013;<lpage>55</lpage>. <pub-id pub-id-type="doi">10.1016/j.fcr.2013.09.023</pub-id></mixed-citation></ref><ref id="B20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holland</surname><given-names>K. H.</given-names></name><name><surname>Lamb</surname><given-names>D. W.</given-names></name><name><surname>Schepers</surname><given-names>J. S.</given-names></name></person-group> (<year>2012</year>). <article-title>Radiometry of proximal active optical sensors (AOS) for agricultural sensing</article-title>. <source>IEEE J. Select. Topics Appl. Earth Observ. Remote Sens.</source>
<volume>5</volume>, <fpage>1793</fpage>&#x02013;<lpage>1802</lpage>. <pub-id pub-id-type="doi">10.1109/JSTARS.2012.2198049</pub-id></mixed-citation></ref><ref id="B21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>J.</given-names></name><name><surname>Xu</surname><given-names>C.</given-names></name><name><surname>Ridoutt</surname><given-names>B. G.</given-names></name><name><surname>Wang</surname><given-names>X.</given-names></name><name><surname>Ren</surname><given-names>P.</given-names></name></person-group> (<year>2017</year>). <article-title>Nitrogen and phosphorus losses and eutrophication potential associated with fertilizer application to cropland in China</article-title>. <source>J. Cleaner Product.</source>
<volume>159</volume>, <fpage>171</fpage>&#x02013;<lpage>179</lpage>. <pub-id pub-id-type="doi">10.1016/J.JCLEPRO.2017.05.008</pub-id></mixed-citation></ref><ref id="B22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>S.</given-names></name><name><surname>Miao</surname><given-names>Y.</given-names></name><name><surname>Zhao</surname><given-names>G.</given-names></name><name><surname>Yuan</surname><given-names>F.</given-names></name><name><surname>Ma</surname><given-names>X.</given-names></name><name><surname>Tan</surname><given-names>C.</given-names></name><etal/></person-group> (<year>2015</year>). <article-title>Satellite remote sensing-based in-season diagnosis of rice nitrogen status in Northeast China</article-title>. <source>Remote Sens.</source>
<volume>7</volume>, <fpage>10646</fpage>&#x02013;<lpage>10667</lpage>. <pub-id pub-id-type="doi">10.3390/rs70810646</pub-id></mixed-citation></ref><ref id="B23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jasper</surname><given-names>J.</given-names></name><name><surname>Reusch</surname><given-names>S.</given-names></name><name><surname>Link</surname><given-names>A.</given-names></name></person-group> (<year>2009</year>). <article-title>Active sensing of the N status of wheat using optimized wavelength combination: impact of seed rate, variety and growth stage</article-title>, in <source>Precision agriculture '09. Papers Presented at the European Conference on Precision Agriculture</source>, <volume>Wageningen</volume>, <fpage>23</fpage>&#x02013;<lpage>30</lpage>.</mixed-citation></ref><ref id="B24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jordan</surname><given-names>C. F.</given-names></name></person-group> (<year>1969</year>). <article-title>Derivation of leaf-area index from quality of light on the forest floor</article-title>. <source>Ecology</source>
<volume>50</volume>, <fpage>663</fpage>&#x02013;<lpage>666</lpage>. <pub-id pub-id-type="doi">10.2307/1936256</pub-id></mixed-citation></ref><ref id="B25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kanke</surname><given-names>Y.</given-names></name><name><surname>Raun</surname><given-names>W.</given-names></name><name><surname>Solie</surname><given-names>J.</given-names></name><name><surname>Stone</surname><given-names>M.</given-names></name><name><surname>Taylor</surname><given-names>R.</given-names></name></person-group> (<year>2012</year>). <article-title>Red edge as a potential index for detecting differences in plant nitrogen status in winter wheat</article-title>. <source>J. Plant Nutr.</source>
<volume>35</volume>, <fpage>1526</fpage>&#x02013;<lpage>1541</lpage>. <pub-id pub-id-type="doi">10.1080/01904167.2012.689912</pub-id></mixed-citation></ref><ref id="B26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knipling</surname><given-names>E. B.</given-names></name></person-group> (<year>1970</year>). <article-title>Physical and physiological basis for the reflectance of visible and near-infrared radiation from vegetation</article-title>. <source>Remote Sens. Environ.</source>
<volume>1</volume>, <fpage>155</fpage>&#x02013;<lpage>159</lpage>. <pub-id pub-id-type="doi">10.1016/S0034-4257(70)80021-9</pub-id></mixed-citation></ref><ref id="B27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krienke</surname><given-names>B.</given-names></name><name><surname>Ferguson</surname><given-names>R. B.</given-names></name><name><surname>Schlemmer</surname><given-names>M.</given-names></name><name><surname>Holland</surname><given-names>K.</given-names></name><name><surname>Marx</surname><given-names>D.</given-names></name><name><surname>Eskridge</surname><given-names>K.</given-names></name></person-group> (<year>2017</year>). <article-title>Using an unmanned aerial vehicle to evaluate nitrogen variability and height effect with an active crop canopy sensor</article-title>. <source>Precis. Agric.</source>
<volume>18</volume>, <fpage>900</fpage>&#x02013;<lpage>915</lpage>. <pub-id pub-id-type="doi">10.1007/s11119-017-9534-5</pub-id></mixed-citation></ref><ref id="B28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lamb</surname><given-names>D. W.</given-names></name><name><surname>Schneider</surname><given-names>D. A.</given-names></name><name><surname>Stanley</surname><given-names>J. N.</given-names></name></person-group> (<year>2014</year>). <article-title>Combination active optical and passive thermal infrared sensor for low-level airborne crop sensing</article-title>. <source>Precis. Agric.</source>
<volume>15</volume>, <fpage>523</fpage>&#x02013;<lpage>531</lpage>. <pub-id pub-id-type="doi">10.1007/s11119-014-9350-0</pub-id></mixed-citation></ref><ref id="B29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lamb</surname><given-names>D. W.</given-names></name><name><surname>Trotter</surname><given-names>M. G.</given-names></name><name><surname>Schneider</surname><given-names>D. A.</given-names></name></person-group> (<year>2009</year>). <article-title>Ultra low-level airborne (ULLA) sensing of crop canopy reflectance: a case study using a CropCircle<sup>TM</sup> sensor</article-title>. <source>Comput. Electron. Agric.</source>
<volume>69</volume>, <fpage>86</fpage>&#x02013;<lpage>91</lpage>. <pub-id pub-id-type="doi">10.1016/j.compag.2009.07.004</pub-id></mixed-citation></ref><ref id="B30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>F.</given-names></name><name><surname>Miao</surname><given-names>Y.</given-names></name><name><surname>Feng</surname><given-names>G.</given-names></name><name><surname>Yuan</surname><given-names>F.</given-names></name><name><surname>Yue</surname><given-names>S.</given-names></name><name><surname>Gao</surname><given-names>X.</given-names></name><etal/></person-group> (<year>2014</year>). <article-title>Improving estimation of summer maize nitrogen status with red edge-based spectral vegetation indices</article-title>. <source>Field Crops Res.</source>
<volume>157</volume>, <fpage>111</fpage>&#x02013;<lpage>123</lpage>. <pub-id pub-id-type="doi">10.1016/j.fcr.2013.12.018</pub-id></mixed-citation></ref><ref id="B31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liang</surname><given-names>L.</given-names></name><name><surname>Di</surname><given-names>L.</given-names></name><name><surname>Zhang</surname><given-names>L.</given-names></name><name><surname>Deng</surname><given-names>M.</given-names></name><name><surname>Qin</surname><given-names>Z.</given-names></name><name><surname>Zhao</surname><given-names>S.</given-names></name><etal/></person-group> (<year>2015</year>). <article-title>Estimation of crop LAI using hyperspectral vegetation indices and a hybrid inversion method</article-title>. <source>Remote Sens. Environ.</source>
<volume>165</volume>, <fpage>123</fpage>&#x02013;<lpage>134</lpage>. <pub-id pub-id-type="doi">10.1016/j.rse.2015.04.032</pub-id></mixed-citation></ref><ref id="B32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>X.</given-names></name><name><surname>Zhang</surname><given-names>Y.</given-names></name><name><surname>Han</surname><given-names>W.</given-names></name><name><surname>Tang</surname><given-names>A.</given-names></name><name><surname>Shen</surname><given-names>J.</given-names></name><name><surname>Cui</surname><given-names>Z.</given-names></name><etal/></person-group>. (<year>2013</year>). <article-title>Enhanced nitrogen deposition over China</article-title>. <source>Nature</source>
<volume>494</volume>, <fpage>459</fpage>&#x02013;<lpage>462</lpage>. <pub-id pub-id-type="doi">10.1038/NATURE11917</pub-id><?supplied-pmid 23426264?><pub-id pub-id-type="pmid">23426264</pub-id></mixed-citation></ref><ref id="B33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lu</surname><given-names>J.</given-names></name><name><surname>Miao</surname><given-names>Y.</given-names></name><name><surname>Shi</surname><given-names>W.</given-names></name><name><surname>Li</surname><given-names>J.</given-names></name><name><surname>Yuan</surname><given-names>F.</given-names></name></person-group> (<year>2017</year>). <article-title>Evaluating different approaches to non-destructive nitrogen status diagnosis of rice using portable RapidSCAN active canopy sensor</article-title>. <source>Sci. Rep.</source>
<volume>7</volume>:<fpage>14073</fpage>. <pub-id pub-id-type="doi">10.1038/s41598-017-14597-1</pub-id><?supplied-pmid 29074943?><pub-id pub-id-type="pmid">29074943</pub-id></mixed-citation></ref><ref id="B34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maresma</surname><given-names>&#x000c1;.</given-names></name><name><surname>Ariza</surname><given-names>M.</given-names></name><name><surname>Mart&#x000ed;nez</surname><given-names>E.</given-names></name><name><surname>Lloveras</surname><given-names>J.</given-names></name><name><surname>Mart&#x000ed;nez-Casasnovas</surname><given-names>J.</given-names></name></person-group> (<year>2016</year>). <article-title>Analysis of vegetation indices to determine nitrogen application and yield prediction in maize (Zea mays L.) from a standard UAV service</article-title>. <source>Remote Sens.</source>
<volume>8</volume>:<fpage>973</fpage>
<pub-id pub-id-type="doi">10.3390/rs8120973</pub-id></mixed-citation></ref><ref id="B35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miao</surname><given-names>Y.</given-names></name><name><surname>Stewart</surname><given-names>B. A.</given-names></name><name><surname>Zhang</surname><given-names>F.</given-names></name></person-group> (<year>2011</year>). <article-title>Long-term experiments for sustainable nutrient management in China. a review</article-title>. <source>Agron. Sustain. Dev.</source>
<volume>31</volume>, <fpage>397</fpage>&#x02013;<lpage>414</lpage>. <pub-id pub-id-type="doi">10.1051/agro/2010034</pub-id></mixed-citation></ref><ref id="B36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>J. J.</given-names></name><name><surname>Schepers</surname><given-names>J. S.</given-names></name><name><surname>Shapiro</surname><given-names>C. A.</given-names></name><name><surname>Arneson</surname><given-names>N. J.</given-names></name><name><surname>Eskridge</surname><given-names>K. M.</given-names></name><name><surname>Oliveira</surname><given-names>M. C.</given-names></name><etal/></person-group> (<year>2018</year>). <article-title>Characterizing soybean vigor and productivity using multiple crop canopy sensor readings</article-title>. <source>Field Crops Res.</source>
<volume>216</volume>, <fpage>22</fpage>&#x02013;<lpage>31</lpage>. <pub-id pub-id-type="doi">10.1016/j.fcr.2017.11.006</pub-id></mixed-citation></ref><ref id="B37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nguyen</surname><given-names>H. T.</given-names></name><name><surname>Lee</surname><given-names>K. J.</given-names></name><name><surname>Fu</surname><given-names>J. D.</given-names></name><name><surname>Yan</surname><given-names>Y. F.</given-names></name><name><surname>Lee</surname><given-names>B. W.</given-names></name><name><surname>Stafford</surname><given-names>J. V.</given-names></name></person-group> (<year>2007</year>). <article-title>Estimating rice shoot biomass and nitrogen concentration from hyperspectral canopy reflectance data using the first derivative and multiple stepwise regression analyses</article-title>, in <source>Precision Agriculture '07. Papers Presented at the European Conference on Precision Agriculture</source>, <volume>Skiathos</volume>, <fpage>3</fpage>&#x02013;<lpage>6</lpage> June <volume>2007</volume>, <fpage>643</fpage>&#x02013;<lpage>650</lpage>.</mixed-citation></ref><ref id="B38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ni</surname><given-names>J.</given-names></name><name><surname>Dong</surname><given-names>J.</given-names></name><name><surname>Zhang</surname><given-names>J.</given-names></name><name><surname>Pang</surname><given-names>F.</given-names></name><name><surname>Cao</surname><given-names>W.</given-names></name><name><surname>Zhu</surname><given-names>Y.</given-names></name></person-group> (<year>2016</year>). <article-title>The spectral calibration method for a crop nitrogen sensor</article-title>. <source>Sensor Rev.</source>
<volume>36</volume>, <fpage>48</fpage>&#x02013;<lpage>56</lpage>. <pub-id pub-id-type="doi">10.1108/sr-04-2015-0051</pub-id></mixed-citation></ref><ref id="B39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ni</surname><given-names>J.</given-names></name><name><surname>Yao</surname><given-names>L.</given-names></name><name><surname>Zhang</surname><given-names>J.</given-names></name><name><surname>Cao</surname><given-names>W.</given-names></name><name><surname>Zhu</surname><given-names>Y.</given-names></name><name><surname>Tai</surname><given-names>X.</given-names></name></person-group> (<year>2017</year>). <article-title>Development of an unmanned aerial vehicle-borne crop-growth monitoring system</article-title>. <source>Sensors</source>
<volume>17</volume>:<fpage>502</fpage>. <pub-id pub-id-type="doi">10.3390/s17030502</pub-id><?supplied-pmid 28273815?><pub-id pub-id-type="pmid">28273815</pub-id></mixed-citation></ref><ref id="B40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niel</surname><given-names>T. G. V.</given-names></name><name><surname>McVicar</surname><given-names>T. R.</given-names></name></person-group> (<year>2004</year>). <article-title>Current and potential uses of optical remote sensing in rice-based irrigation systems: a review</article-title>. <source>Austr. J. Agric. Res.</source>
<volume>55</volume>, <fpage>155</fpage>&#x02013;<lpage>185</lpage>. <pub-id pub-id-type="doi">10.1071/AR03149</pub-id></mixed-citation></ref><ref id="B41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Noh</surname><given-names>H.</given-names></name><name><surname>Zhang</surname><given-names>Q.</given-names></name><name><surname>Shin</surname><given-names>B.</given-names></name><name><surname>Han</surname><given-names>S.</given-names></name><name><surname>Feng</surname><given-names>L.</given-names></name></person-group> (<year>2006</year>). <article-title>A neural network model of maize crop nitrogen stress assessment for a multi-spectral imaging sensor</article-title>. <source>Biosyst. Eng.</source>
<volume>94</volume>, <fpage>477</fpage>&#x02013;<lpage>485</lpage>. <pub-id pub-id-type="doi">10.1016/j.biosystemseng.2006.04.009</pub-id></mixed-citation></ref><ref id="B42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Novoa</surname><given-names>R.</given-names></name><name><surname>Loomis</surname><given-names>R. S.</given-names></name></person-group> (<year>1981</year>). <article-title>Nitrogen and plant production</article-title>. <source>Plant Soil</source>
<volume>58</volume>, <fpage>177</fpage>&#x02013;<lpage>204</lpage>. <pub-id pub-id-type="doi">10.1007/BF02180053</pub-id></mixed-citation></ref><ref id="B43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Padilla</surname><given-names>F. M.</given-names></name><name><surname>Gallardo</surname><given-names>M.</given-names></name><name><surname>Pe&#x000f1;a-Fleitas</surname><given-names>M. T.</given-names></name><name><surname>de Souza</surname><given-names>R.</given-names></name><name><surname>Thompson</surname><given-names>R. B.</given-names></name></person-group> (<year>2018</year>). <article-title>Proximal optical sensors for nitrogen management of vegetable crops: a review</article-title>. <source>Sensors</source>
<volume>18</volume>:<fpage>2083</fpage>. <pub-id pub-id-type="doi">10.3390/s18072083</pub-id><?supplied-pmid 29958482?><pub-id pub-id-type="pmid">29958482</pub-id></mixed-citation></ref><ref id="B44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pei</surname><given-names>W.</given-names></name><name><surname>Lan</surname><given-names>Y. B.</given-names></name><name><surname>Luo</surname><given-names>X. W.</given-names></name><name><surname>Zhou</surname><given-names>Z. Y.</given-names></name><name><surname>Wang</surname><given-names>Z. G.</given-names></name><name><surname>Wang</surname><given-names>Y. H.</given-names></name></person-group> (<year>2014</year>). <article-title>Integrated sensor system for monitoring rice growth conditions based on unmanned ground vehicle system</article-title>. <source>Int. J. Agric. Biol. Eng.</source>
<volume>7</volume>, <fpage>75</fpage>&#x02013;<lpage>81</lpage>. <pub-id pub-id-type="doi">10.3965/j.ijabe.20140702.009</pub-id></mixed-citation></ref><ref id="B45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rouse</surname><given-names>J. W.</given-names></name><name><surname>Haas</surname><given-names>R. H.</given-names></name><name><surname>Schell</surname><given-names>J. A.</given-names></name><name><surname>Deering</surname><given-names>D. W.</given-names></name></person-group> (<year>1973</year>). <article-title>Monitoring vegetation systems in the Great Plains with ERTS (Earth Resources Technology Satellite)</article-title>, in <source>Proceedings of Third Earth Resources Technology Satellite Symposium</source>, Greenbelt, ON, <volume>Canada</volume>, <fpage>10</fpage>&#x02013;<lpage>14</lpage> December <volume>1973</volume>, <fpage>309</fpage>&#x02013;<lpage>317</lpage>. Available at: <ext-link ext-link-type="uri" xlink:href="https://ntrs.nasa.gov/search.jsp?R=19740022614">https://ntrs.nasa.gov/search.jsp?R=19740022614</ext-link> (Accessed June 6, 2018)</mixed-citation></ref><ref id="B46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saberioon</surname><given-names>M.</given-names></name><name><surname>Amin</surname><given-names>M. S. M.</given-names></name><name><surname>Gholizadeh</surname><given-names>A.</given-names></name><name><surname>Ezri</surname><given-names>M. H.</given-names></name></person-group> (<year>2014</year>). <article-title>A review of optical methods for assessing nitrogen contents during rice growth</article-title>. <source>Appl. Eng. Agric.</source>
<volume>30</volume>, <fpage>657</fpage>&#x02013;<lpage>669</lpage>. <pub-id pub-id-type="doi">10.13031/AEA.30.10478</pub-id></mixed-citation></ref><ref id="B47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Samborski</surname><given-names>S. M</given-names></name><name><surname>Gozdowski</surname><given-names>D.</given-names></name><name><surname>Stepien</surname><given-names>M.</given-names></name><name><surname>Walsh</surname><given-names>O. S</given-names></name><name><surname>Leszczynska</surname><given-names>E.</given-names></name></person-group> (<year>2016</year>). <article-title>On-farm evaluation of an active optical sensor performance for variable nitrogen application in winter wheat</article-title>. <source>Eur. J. Agron.</source>
<volume>74</volume>, <fpage>56</fpage>&#x02013;<lpage>67</lpage>. <pub-id pub-id-type="doi">10.1016/j.eja.2015.11.020</pub-id></mixed-citation></ref><ref id="B48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sanchez-Cuevas</surname><given-names>P.</given-names></name><name><surname>Heredia</surname><given-names>G.</given-names></name><name><surname>Ollero</surname><given-names>A.</given-names></name></person-group> (<year>2017</year>). <article-title>Characterization of the aerodynamic ground effect and its influence in multirotor control</article-title>. <source>Int. J. Aerospace Eng.</source>
<volume>2017</volume>, <fpage>1</fpage>&#x02013;<lpage>17</lpage>. <pub-id pub-id-type="doi">10.1155/2017/1823056</pub-id></mixed-citation></ref><ref id="B49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schirrmann</surname><given-names>M.</given-names></name><name><surname>Hamdorf</surname><given-names>A.</given-names></name><name><surname>Giebel</surname><given-names>A.</given-names></name><name><surname>Gleiniger</surname><given-names>F.</given-names></name><name><surname>Pflanz</surname><given-names>M.</given-names></name><name><surname>Dammer</surname><given-names>K.-H.</given-names></name></person-group> (<year>2017</year>). <article-title>Regression kriging for improving crop height models fusing ultra-sonic sensing with UAV imagery</article-title>. <source>Remote Sens.</source>
<volume>9</volume>:<fpage>665</fpage>
<pub-id pub-id-type="doi">10.3390/RS9070665</pub-id></mixed-citation></ref><ref id="B50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shi</surname><given-names>W.</given-names></name><name><surname>Lu</surname><given-names>J.</given-names></name><name><surname>Miao</surname><given-names>Y.</given-names></name><name><surname>Cao</surname><given-names>Q.</given-names></name><name><surname>Shen</surname><given-names>J.</given-names></name><name><surname>Wang</surname><given-names>H.</given-names></name><etal/></person-group> (<year>2015</year>). <article-title>Evaluating a crop circle active canopy sensor-based precision nitrogen management strategy for rice in Northeast China</article-title>, in <source>2015 Fourth International Conference on Agro-Geoinformatics (Agro-geoinformatics)</source>, Istanbul, 20-24 July <volume>2015</volume>, <fpage>261</fpage>&#x02013;<lpage>264</lpage>. <pub-id pub-id-type="doi">10.1109/Agro-Geoinformatics.2015.7248112</pub-id></mixed-citation></ref><ref id="B51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shmueli</surname><given-names>G.</given-names></name></person-group> (<year>2010</year>). <article-title>To explain or to predict?</article-title>
<source>Stat. Sci.</source>
<volume>25</volume>, <fpage>289</fpage>&#x02013;<lpage>310</lpage>. <pub-id pub-id-type="doi">10.1214/10-STS330</pub-id></mixed-citation></ref><ref id="B52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spockeli</surname><given-names>B. A.</given-names></name></person-group> (<year>2015</year>). <source>Integration of RTK GPS and IMU for Accurate UAV Positioning</source>. master's thesis. Trondheim: Norwegian University of Science and Technology.</mixed-citation></ref><ref id="B53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stamatiadis</surname><given-names>S.</given-names></name><name><surname>Taskos</surname><given-names>D.</given-names></name><name><surname>Tsadila</surname><given-names>E.</given-names></name><name><surname>Christofides</surname><given-names>C.</given-names></name><name><surname>Tsadilas</surname><given-names>C.</given-names></name><name><surname>Schepers</surname><given-names>J. S.</given-names></name></person-group> (<year>2010</year>). <article-title>Comparison of passive and active canopy sensors for the estimation of vine biomass production</article-title>. <source>Precision Agric.</source>
<volume>11</volume>, <fpage>306</fpage>&#x02013;<lpage>315</lpage>. <pub-id pub-id-type="doi">10.1007/S11119-009-9131-3</pub-id></mixed-citation></ref><ref id="B54"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thenkabail</surname><given-names>P. S.</given-names></name><name><surname>Smith</surname><given-names>R. B.</given-names></name><name><surname>Pauw</surname><given-names>E. D.</given-names></name></person-group> (<year>2000</year>). <article-title>Hyperspectral vegetation indices and their relationships with agricultural characteristics</article-title>. <source>Remote Sens. Environ.</source>
<volume>71</volume>, <fpage>158</fpage>&#x02013;<lpage>182</lpage>. <pub-id pub-id-type="doi">10.1016/S0034-4257(99)00067-X</pub-id></mixed-citation></ref><ref id="B55"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tian</surname><given-names>Y.-C.</given-names></name><name><surname>Gu</surname><given-names>K.-J.</given-names></name><name><surname>Chu</surname><given-names>X.</given-names></name><name><surname>Yao</surname><given-names>X.</given-names></name><name><surname>Cao</surname><given-names>W.-X.</given-names></name><name><surname>Zhu</surname><given-names>Y.</given-names></name></person-group> (<year>2014</year>). <article-title>Comparison of different hyperspectral vegetation indices for canopy leaf nitrogen concentration estimation in rice</article-title>. <source>Plant Soil</source>
<volume>376</volume>, <fpage>193</fpage>&#x02013;<lpage>209</lpage>. <pub-id pub-id-type="doi">10.1007/s11104-013-1937-0</pub-id></mixed-citation></ref><ref id="B56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>F.</given-names></name><name><surname>Huang</surname><given-names>J.</given-names></name><name><surname>Wang</surname><given-names>Y.</given-names></name><name><surname>Liu</surname><given-names>Z.</given-names></name><name><surname>Zhang</surname><given-names>F.</given-names></name></person-group> (<year>2013</year>). <article-title>Estimating nitrogen concentration in rape from hyperspectral data at canopy level using support vector machines</article-title>. <source>Precision Agric.</source>
<volume>14</volume>, <fpage>172</fpage>&#x02013;<lpage>183</lpage>. <pub-id pub-id-type="doi">10.1007/s11119-012-9285-2</pub-id></mixed-citation></ref><ref id="B57"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>White</surname><given-names>J. W.</given-names></name><name><surname>Andrade-Sanchez</surname><given-names>P.</given-names></name><name><surname>Gore</surname><given-names>M. A.</given-names></name><name><surname>Bronson</surname><given-names>K. F.</given-names></name><name><surname>Coffelt</surname><given-names>T. A.</given-names></name><name><surname>Conley</surname><given-names>M. M.</given-names></name><etal/></person-group> (<year>2012</year>). <article-title>Field-based phenomics for plant genetics research</article-title>. <source>Field Crops Res.</source>
<volume>133</volume>, <fpage>101</fpage>&#x02013;<lpage>112</lpage>. <pub-id pub-id-type="doi">10.1016/j.fcr.2012.04.003</pub-id></mixed-citation></ref><ref id="B58"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>G.</given-names></name><name><surname>Liu</surname><given-names>J.</given-names></name><name><surname>Zhao</surname><given-names>C.</given-names></name><name><surname>Li</surname><given-names>Z.</given-names></name><name><surname>Huang</surname><given-names>Y.</given-names></name><name><surname>Yu</surname><given-names>H.</given-names></name><etal/></person-group>. (<year>2017</year>). <article-title>Unmanned aerial vehicle remote sensing for field-based crop phenotyping: current status and perspectives</article-title>. <source>Front. Plant Sci.</source>
<volume>8</volume>:<fpage>1111</fpage>. <pub-id pub-id-type="doi">10.3389/fpls.2017.01111</pub-id><?supplied-pmid 28713402?><pub-id pub-id-type="pmid">28713402</pub-id></mixed-citation></ref><ref id="B59"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>C.</given-names></name><name><surname>Kovacs</surname><given-names>J. M.</given-names></name></person-group> (<year>2012</year>). <article-title>The application of small unmanned aerial systems for precision agriculture: a review</article-title>. <source>Precis. Agric.</source>
<volume>13</volume>, <fpage>693</fpage>&#x02013;<lpage>712</lpage>. <pub-id pub-id-type="doi">10.1007/s11119-012-9274-5</pub-id></mixed-citation></ref><ref id="B60"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>X.</given-names></name><name><surname>Zheng</surname><given-names>H. B.</given-names></name><name><surname>Xu</surname><given-names>X. Q.</given-names></name><name><surname>He</surname><given-names>J. Y.</given-names></name><name><surname>Ge</surname><given-names>X. K.</given-names></name><name><surname>Yao</surname><given-names>X.</given-names></name><etal/></person-group> (<year>2017</year>). <article-title>Predicting grain yield in rice using multi-temporal vegetation indices from UAV-based multispectral and digital imagery</article-title>. <source>ISPRS J. Photogrammetry Remote Sens.</source>
<volume>130</volume>, <fpage>246</fpage>&#x02013;<lpage>255</lpage>. <pub-id pub-id-type="doi">10.1016/j.isprsjprs.2017.05.003</pub-id></mixed-citation></ref><ref id="B61"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>Z.</given-names></name><name><surname>Jabloun</surname><given-names>M.</given-names></name><name><surname>Plauborg</surname><given-names>F.</given-names></name><name><surname>Andersen</surname><given-names>M. N.</given-names></name></person-group> (<year>2018</year>). <article-title>Using ground-based spectral reflectance sensors and photography to estimate shoot N concentration and dry matter of potato</article-title>. <source>Comput. Electron. Agric.</source>
<volume>144</volume>, <fpage>154</fpage>&#x02013;<lpage>163</lpage>. <pub-id pub-id-type="doi">10.1016/j.compag.2017.12.005</pub-id></mixed-citation></ref></ref-list></back></article>