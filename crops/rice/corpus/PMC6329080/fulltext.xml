<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN" "JATS-archivearticle1.dtd"> 
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName A++V2.4.dtd?><?SourceDTD.Version 2.4?><?ConverterInfo.XSLTName springer2nlmx2.xsl?><?ConverterInfo.Version 1?><front><journal-meta><journal-id journal-id-type="nlm-ta">Plant Methods</journal-id><journal-id journal-id-type="iso-abbrev">Plant Methods</journal-id><journal-title-group><journal-title>Plant Methods</journal-title></journal-title-group><issn pub-type="epub">1746-4811</issn><publisher><publisher-name>BioMed Central</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">6329080</article-id><article-id pub-id-type="publisher-id">386</article-id><article-id pub-id-type="doi">10.1186/s13007-019-0386-z</article-id><article-categories><subj-group subj-group-type="heading"><subject>Software</subject></subj-group></article-categories><title-group><article-title>Plant Screen Mobile: an open-source mobile device app for plant trait analysis</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-6722-5437</contrib-id><name><surname>M&#x000fc;ller-Linow</surname><given-names>Mark</given-names></name><address><email>m.mueller-linow@fz-juelich.de</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Wilhelm</surname><given-names>Jens</given-names></name><address><email>j.wilhelm@fz-juelich.de</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Briese</surname><given-names>Christoph</given-names></name><address><email>christoph.briese@dlr.de</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Wojciechowski</surname><given-names>Tobias</given-names></name><address><email>t.wojciechowski@fz-juelich.de</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Schurr</surname><given-names>Ulrich</given-names></name><address><email>u.schurr@fz-juelich.de</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Fiorani</surname><given-names>Fabio</given-names></name><address><email>f.fiorani@fz-juelich.de</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2297 375X</institution-id><institution-id institution-id-type="GRID">grid.8385.6</institution-id><institution>IBG-2: Plant Sciences, Institute for Bio- and Geosciences, Forschungszentrum J&#x000fc;lich, </institution></institution-wrap>52425 J&#x000fc;lich, Germany </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0000 8983 7915</institution-id><institution-id institution-id-type="GRID">grid.7551.6</institution-id><institution>Present Address: German Aerospace Center (DLR), </institution></institution-wrap>Lilienthalplatz 7, 38108 Brunswick, Germany </aff></contrib-group><pub-date pub-type="epub"><day>11</day><month>1</month><year>2019</year></pub-date><pub-date pub-type="pmc-release"><day>11</day><month>1</month><year>2019</year></pub-date><pub-date pub-type="collection"><year>2019</year></pub-date><volume>15</volume><elocation-id>2</elocation-id><history><date date-type="received"><day>3</day><month>8</month><year>2018</year></date><date date-type="accepted"><day>4</day><month>1</month><year>2019</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2019</copyright-statement><license license-type="OpenAccess"><license-p><bold>Open Access</bold>This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p></license></permissions><abstract id="Abs1"><sec><title>Background</title><p id="Par1">The development of leaf area is one of the fundamental variables to quantify plant growth and physiological function and is therefore widely used to characterize genotypes and their interaction with the environment. To date, analysis of leaf area often requires elaborate and destructive measurements or imaging-based methods accompanied by automation that may result in costly solutions. Consequently in recent years there is an increasing trend towards simple and affordable sensor solutions and methodologies. A major focus is currently on harnessing the potential of applications developed for smartphones that provide access to analysis tools to a wide user basis. However, most existing applications entail significant manual effort during data acquisition and analysis.</p></sec><sec><title>Results</title><p id="Par2">With the development of <italic>Plant Screen Mobile</italic> we provide a suitable smartphone solution for estimating digital proxies of leaf area and biomass in various imaging scenarios in the lab, greenhouse and in the field. To distinguish between plant tissue and background the core of the application comprises different classification approaches that can be parametrized by users delivering results on-the-fly. We demonstrate the practical applications of computing projected leaf area based on two case studies with <italic>Eragrostis</italic> and <italic>Musa</italic> plants. These studies showed highly significant correlations with destructive measurements of leaf area and biomass from both ground truth measurements and estimations from well-established screening systems.</p></sec><sec><title>Conclusions</title><p id="Par3">We show that a smartphone together with our analysis tool <italic>Plant Screen Mobile</italic> is a suitable platform for rapid quantification of leaf and shoot development of various plant architectures. Beyond the estimation of projected leaf area the app can also be used to quantify color and shape parameters of other plant material including seeds and flowers.</p></sec><sec><title>Electronic supplementary material</title><p>The online version of this article (10.1186/s13007-019-0386-z) contains supplementary material, which is available to authorized users.</p></sec></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>Plant image segmentation</kwd><kwd>Image analysis</kwd><kwd>Mobile application</kwd><kwd>Android</kwd><kwd>Machine learning</kwd><kwd>Projected leaf area</kwd></kwd-group><funding-group><award-group><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100002347</institution-id><institution>Bundesministerium f&#x000fc;r Bildung und Forschung</institution></institution-wrap></funding-source><award-id>031A053</award-id><award-id>031A258I</award-id><award-id>01DP17023</award-id><principal-award-recipient><name><surname>M&#x000fc;ller-Linow</surname><given-names>Mark</given-names></name><name><surname>Wojciechowski</surname><given-names>Tobias</given-names></name></principal-award-recipient></award-group></funding-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; The Author(s) 2019</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Background</title><p id="Par24">The evaluation of leaf area development addresses one of the most important issues in plant phenotyping, but poses one of the biggest challenges at the same time. This key parameter characterizes the interface between canopy and atmosphere, which regulates photosynthetic activity and transpiration processes and is used to monitor shoot growth and to model plant and environment interactions ([<xref ref-type="bibr" rid="CR1">1</xref>] and references therein). The high diversity of canopy structures at different growth stages results in a number of technical problems, like measurable canopy size, perspective limitations depending on view-angles, and self-occlusions within the canopy. Accordingly, a variety of imaging-based methodological developments and commercial solutions emerged in the last years (for a good overview, see [<xref ref-type="bibr" rid="CR1">1</xref>&#x02013;<xref ref-type="bibr" rid="CR3">3</xref>]). They include non-invasive and indirect methods, which make use of radiative transfer models [<xref ref-type="bibr" rid="CR4">4</xref>] and which measure at different angles and levels within the canopy [<xref ref-type="bibr" rid="CR5">5</xref>], direct non-invasive methods like hand-held scanners [<xref ref-type="bibr" rid="CR2">2</xref>], and laser-scanning [<xref ref-type="bibr" rid="CR6">6</xref>, <xref ref-type="bibr" rid="CR7">7</xref>]. Many of these methods entail specifically developed hardware and consequently potentially significant investment costs. Alternative approaches that are easy to implement and cost-efficient at the same time became increasingly important. A first step in this direction were camera-based applications that make use of new image analysis tools. However, most of the published methods using this methodology are still invasive, i.e. they require the detachment of the leaves from the plant stem [<xref ref-type="bibr" rid="CR8">8</xref>&#x02013;<xref ref-type="bibr" rid="CR10">10</xref>]. Leaves are then placed on an imaging plane with a suitable background providing optimal contrast, often using a reference pattern for metric conversion of pixel data. Such approaches facilitate leaf segmentation and reduce perspective effects during image acquisition, resulting in sufficiently precise and accurate leaf area measurements of single leaves. For example, Rico-Garcia et al. [<xref ref-type="bibr" rid="CR8">8</xref>] tested a Computer Aided Design (CAD)-based approach against their image processing suite in tomato and corn and obtained a maximum error of ~&#x02009;4% with a deviation of ~&#x02009;3%; the error was defined as the percentage of over- or under-estimated leaf area. However, at the same time these methodologies are usually restricted to smaller sample sizes, mainly due to the time-consuming process of leaf sampling and image acquisition. Many scientific questions require screening setups, where the growth of whole plants is monitored over an extended period of time starting at germination and seedling stages. Those are exactly the conditions, where non-invasive imaging approaches have very good opportunities for applications. At the same time the processing capabilities of mobile phones as well as the quality of built-in cameras improved drastically such that smartphones can now be used for various purposes ranging from documentation and classification of samples to quantitative analysis based on pixel and color information of digital pictures [<xref ref-type="bibr" rid="CR11">11</xref>]. A number of beneficial features promote this current trend. Mobile phones do not replace just cameras, but provide capability to run the analysis tasks on-board, independent of additional hardware and other infrastructure like network connection (e.g., for upload and server-based analysis), or external power supply. However, the number of published mobile phone applications, specifically developed for plant phenotyping tasks, is still limited to specific cases. Intaravanne et al. [<xref ref-type="bibr" rid="CR12">12</xref>, <xref ref-type="bibr" rid="CR13">13</xref>] developed two applications, which focus on the analysis of color properties of banana fruits and rice leaves to determine the ripeness and nitrogen content, respectively. In seed phenotyping smartphone applications were used for automated characterization of seed morphology in crops [<xref ref-type="bibr" rid="CR14">14</xref>, <xref ref-type="bibr" rid="CR15">15</xref>]. Another study used a smartphone for automated berry counting in grapevine in the field [<xref ref-type="bibr" rid="CR16">16</xref>]. Leaf Doctor [<xref ref-type="bibr" rid="CR17">17</xref>] is a mobile application, which analyzes color images to quantify the severity of different diseases that result in visible color changes of the leaf surface. Confalonieri et al. [<xref ref-type="bibr" rid="CR18">18</xref>] applied the radiative transfer model and estimated the gap fraction in rice plantations with a smartphone application that segments canopy from the sky.</p><p id="Par25">With <italic>Plant Screen Mobile</italic> we contribute a new approach for Android-based smart phones, which uses both on-board camera and processing unit for the analysis of shoot and leaf images, in particular. <italic>Plant Screen Mobile</italic> provides a portfolio of segmentation approaches, which enable the user to detect the target plant even in the absence of a contrasting background and furthermore under various illumination conditions. It can make use of the internal device storage, does not require external processing time, and is therefore suitable for studies in growth chambers, greenhouses, and in the field, where access to a network or computers is not guaranteed. The application completes the analysis with the possibility of geometric calibration and extracting traits like projected leaf are (PLA) and shape parameters like object size and perimeter from the images. Furthermore we implemented genetic parameter optimization for color segmentation. We tested its applicability to several test cases. We present an evaluation of its performance by comparison to measurements with typical lab camera setups, based on destructive measurements.</p></sec><sec id="Sec2"><title>Implementation</title><p id="Par26"><italic>Plant Screen Mobile</italic> (further denoted as PSM) was developed with Android Studio (Google Inc.) using the OpenCV-libraries for image processing and analysis tasks. It works on mobile phones with Android OS 4.0 (Ice Cream Sandwich). All computations were performed on a Samsung Galaxy S6 smartphone. An overview on the basic processing modes of PSM is illustrated in the flowchart in Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>.<fig id="Fig1"><label>Fig.&#x000a0;1</label><caption><p>Flowchart of implemented processes: the main process (both on-the-fly and batch mode) start with the <italic>image acquisition</italic> as input and ends with analyzed traits. <italic>Image calibration</italic> allows to convert pixel metric into real-world values. Additionally, <italic>training data</italic> can be used to optimize parameters for HSV segmentation</p></caption><graphic xlink:href="13007_2019_386_Fig1_HTML" id="MO1"/></fig>
</p><sec id="Sec3"><title>Image acquisition and display</title><p id="Par27">The main interface of <italic>Plant Screen Mobile</italic> displays a live image from the front camera at a maximum resolution of 1920&#x02009;&#x000d7;&#x02009;1080px (Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>a). Images are either stored for later processing (e.g. to speed up image acquisition) or analyzed immediately with a given parameter set (Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>b, c). In the latter case each implemented algorithm is directly applied to the live image, results are displayed on-the-fly and can be stored as masked images. In this mode no additional traits are computed. To reach the desired camera orientation PSM includes a level tool that uses the smartphone&#x02019;s accelerometer. During adjustment tilt angles are continuously displayed and horizontal (top-view) or vertical (side-view) camera orientations are indicated as information on the live screen. If necessary the smartphone illumination headlight may be switched on to optimize capturing conditions. Different visualizations like single channel display in RGB (red, green, blue color space) or HSV (hue, saturation, value color space) and a color information tool for the screen center pixels help to judge the imaging situation and to parameterize the filters. If images are analyzed at a different time from acquisition or imported from other sources, PSM provides batch operation for multiple images with one of the pre-selected processing modes that will be explained in the following together with a pre-specified parameter set. Segmented image results are stored and computed traits, evaluation date, and time are exported to CSV files.<fig id="Fig2"><label>Fig.&#x000a0;2</label><caption><p>On-the-fly segmentation of a Virginia mallow plant (<italic>Sida hermaphrodita</italic>). <bold>a</bold> Image of a <italic>Sida</italic> plant; <bold>b</bold> live view image displaying the on-the-fly HSV-segmentation of the imaged seedling (live view image was taken from a slightly different angle); RGB-camera values are first converted into HSV color space and then binarized using the parametrization of the HSV-filter in <bold>c</bold> lower and upper thresholds of the HSV-filter are adjusted such that the resulting plant mask can be analyzed for projected leaf area and other plant traits</p></caption><graphic xlink:href="13007_2019_386_Fig2_HTML" id="MO2"/></fig>
</p></sec><sec id="Sec4"><title>Image segmentation</title><p id="Par28">We implemented three image segmentation methods based on single channel thresholding (i), greenness thresholding (ii) and HSV-thresholding (iii) that deliver binary outputs to mask the image background. Selecting a suitable method depends on different factors. First of all, the image capture conditions determine which method is applicable or not. In the absence of color information, e.g. when imaging roots, the lightness is the main classifier and simple gray value thresholding should be sufficient. This method requires less computational power, but tends to lower accuracy in imaging situations with unequal illumination. If leaves are imaged under controlled conditions and classification is not disturbed other image &#x02018;contaminants&#x02019; like algae or weed, greenness thresholding would be the method of choice. Requiring only one thresholding value it is far easier to parametrize, compared e.g. to HSV thresholding, which needs 6 parameters. Albeit higher computational costs, the last approach is suitable in more difficult imaging situations, were additional classifiers like saturation or lightness are needed. We tested the principal segmentation capabilities and performance differences between greenness and HSV thresholding and highlighted results in the Additional file <xref rid="MOESM1" ref-type="media">1</xref>. <list list-type="simple"><list-item><label>(i)</label><p id="Par29"><italic>Single-channel thresholding</italic> When color is not the primary feature to distinguish between object and background, image segmentation via single-channel thresholding is a suitable method with respect to computational time and memory. We implemented three threshold operations that are employed on grayscale representation of the RGB color space: simple thresholding, adaptive thresholding, and OTSU&#x02019;s method [<xref ref-type="bibr" rid="CR19">19</xref>]. In simple thresholding intensity values of each image pixel are compared to a global threshold <italic>&#x003b1;</italic> resulting in a binary mask <italic>B</italic> with values of 1 indicating intensity values above <italic>&#x003b1;</italic> and 0 otherwise. These values are attributed to plant and non-plant pixels. This can be sufficient, if plants are homogeneously illuminated in front of a black background. In adaptive thresholding, which accounts for local variations in illumination, <italic>&#x003b1;</italic> is calculated separately for each pixel using the surrounding region of a preset size. The comparison is either based on averaged intensities (adaptive mean), or on the Gaussian weighted sum (adaptive Gaussian). In Otsu&#x02019;s method threshold <italic>&#x003b1;</italic> is automatically calculated and applied to the entire image. The integral part is an estimation of <italic>&#x003b1;</italic>, which splits up the intensity distribution such that resultant distributions display low intra-variance and high inter-variance. If necessary, the image can be inverted before applying any threshold operation, e.g. to segment dark objects in front of a brighter background.</p></list-item><list-item><label>(ii)</label><p id="Par30"><italic>Greenness thresholding</italic> Many plant phenotyping applications require the segmentation of green plant tissue. Various suitable approaches with low computational costs have been introduced and tested in different application scenarios that compute greenness indices on the base of RGB channel intensities <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$I_{R } I_{G}$$\end{document}</tex-math><mml:math id="M2"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:msub><mml:mi>I</mml:mi><mml:mi>G</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="13007_2019_386_Article_IEq1.gif"/></alternatives></inline-formula>, and <inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$I_{B}$$\end{document}</tex-math><mml:math id="M4"><mml:msub><mml:mi>I</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="13007_2019_386_Article_IEq2.gif"/></alternatives></inline-formula> [<xref ref-type="bibr" rid="CR20">20</xref>, <xref ref-type="bibr" rid="CR21">21</xref>]. We implemented three well-known greenness measures: the Green Chromatic Coordinate (GCC) [<xref ref-type="bibr" rid="CR20">20</xref>], the Vegetative Index (VEG) [<xref ref-type="bibr" rid="CR22">22</xref>] and the Excess Green Excess Red Index (ExGR) [<xref ref-type="bibr" rid="CR23">23</xref>]. All indices can filtered by a single thresholding operation with parameter<italic>&#x003b1;</italic>. In these greenness definitions a pixel <inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$I\left( {x,y} \right)$$\end{document}</tex-math><mml:math id="M6"><mml:mrow><mml:mi>I</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="13007_2019_386_Article_IEq3.gif"/></alternatives></inline-formula> at position (<italic>x y</italic>) is classified to <italic>B</italic> according to:</p><p id="Par31">
<disp-formula id="Equa"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{GCC:}}\quad B\left( {x,y} \right) = \left\{ {\begin{array}{*{20}l} {1\quad } \hfill &#x00026; {if\quad \frac{{I_{G} \left( {x,y} \right)}}{{I_{R} \left( {x,y} \right) + I_{G} \left( {x,y} \right) + I_{B} \left( {x,y} \right)}} &#x0003e; \alpha } \hfill \\ {0\quad } \hfill &#x00026; {otherwise} \hfill \\ \end{array} } \right.$$\end{document}</tex-math><mml:math id="M8" display="block"><mml:mrow><mml:mtext>GCC:</mml:mtext><mml:mspace width="1em"/><mml:mi>B</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfenced close="" open="{" separators=""><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mn>1</mml:mn><mml:mspace width="1em"/></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="1em"/><mml:mfrac><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac><mml:mo>&#x0003e;</mml:mo><mml:mi>&#x003b1;</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:mrow><mml:mn>0</mml:mn><mml:mspace width="1em"/></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="italic">otherwise</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="13007_2019_386_Article_Equa.gif" position="anchor"/></alternatives></disp-formula>
</p><p id="Par32">
<disp-formula id="Equb"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{VEG:}}\quad B\left( {x,y} \right) = \left\{ {\begin{array}{*{20}l} {1\quad } \hfill &#x00026; {if\quad \frac{{I_{G} \left( {x,y} \right)}}{{I_{R} \left( {x,y} \right)^{{2/3}} *I_{B} \left( {x,y} \right)^{{1/3}} }} &#x0003e; \alpha } \hfill \\ {0\quad } \hfill &#x00026; {otherwise} \hfill \\ \end{array} } \right.$$\end{document}</tex-math><mml:math id="M10" display="block"><mml:mrow><mml:mtext>VEG:</mml:mtext><mml:mspace width="1em"/><mml:mi>B</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfenced close="" open="{" separators=""><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mn>1</mml:mn><mml:mspace width="1em"/></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="1em"/><mml:mfrac><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:msup><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mrow><mml:mn>2</mml:mn><mml:mo stretchy="false">/</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mrow/><mml:mo>&#x02217;</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:msup><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mrow><mml:mn>1</mml:mn><mml:mo stretchy="false">/</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>&#x0003e;</mml:mo><mml:mi>&#x003b1;</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:mrow><mml:mn>0</mml:mn><mml:mspace width="1em"/></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="italic">otherwise</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="13007_2019_386_Article_Equb.gif" position="anchor"/></alternatives></disp-formula>
</p><p id="Par33"><disp-formula id="Equc"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{ExGR:}}\quad B\left( {x,y} \right) = \left\{ {\begin{array}{*{20}l} {1\quad } \hfill &#x00026; {if\quad 3I_{G}^{\prime } \left( {x,y} \right) - 2.4I_{R}^{\prime } \left( {x,y} \right) - I_{B}^{\prime } \left( {x,y} \right) &#x0003e; \alpha } \hfill \\ {0\quad } \hfill &#x00026; {otherwise} \hfill \\ \end{array} } \right.$$\end{document}</tex-math><mml:math id="M12" display="block"><mml:mrow><mml:mtext>ExGR:</mml:mtext><mml:mspace width="1em"/><mml:mi>B</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfenced close="" open="{" separators=""><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mn>1</mml:mn><mml:mspace width="1em"/></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="1em"/><mml:mn>3</mml:mn><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mo>&#x02032;</mml:mo></mml:msubsup><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>-</mml:mo><mml:mn>2.4</mml:mn><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mo>&#x02032;</mml:mo></mml:msubsup><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>-</mml:mo><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mo>&#x02032;</mml:mo></mml:msubsup><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>&#x0003e;</mml:mo><mml:mi>&#x003b1;</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:mrow><mml:mn>0</mml:mn><mml:mspace width="1em"/></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="italic">otherwise</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="13007_2019_386_Article_Equc.gif" position="anchor"/></alternatives></disp-formula>with<inline-formula id="IEq4"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$I_{R}^{{\prime }} \left( {x,y} \right) = \frac{{I_{R} \left( {x,y} \right)}}{{I_{R} \left( {x,y} \right) + I_{G} \left( {x,y} \right) + I_{B} \left( {x,y} \right)}};$$\end{document}</tex-math><mml:math id="M14"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mo>&#x02032;</mml:mo></mml:msubsup><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac><mml:mo>&#x0037e;</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="13007_2019_386_Article_IEq4.gif"/></alternatives></inline-formula>
<inline-formula id="IEq5"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$I_{G}^{{\prime }} \left( {x,y} \right) = \frac{{I_{G} \left( {x,y} \right)}}{{I_{R} \left( {x,y} \right) + I_{G} \left( {x,y} \right) + I_{B} \left( {x,y} \right)}};$$\end{document}</tex-math><mml:math id="M16"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mo>&#x02032;</mml:mo></mml:msubsup><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac><mml:mo>&#x0037e;</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="13007_2019_386_Article_IEq5.gif"/></alternatives></inline-formula>
<inline-formula id="IEq6"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$I_{R}^{{\prime }} \left( {x,y} \right) = \frac{{I_{B} \left( {x,y} \right)}}{{I_{R} \left( {x,y} \right) + I_{G} \left( {x,y} \right) + I_{B} \left( {x,y} \right)}}.$$\end{document}</tex-math><mml:math id="M18"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mo>&#x02032;</mml:mo></mml:msubsup><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="13007_2019_386_Article_IEq6.gif"/></alternatives></inline-formula></p></list-item></list></p><p id="Par35">Despite their name, greenness filters are not highly sensitive to green colors only but also to the adjacent colors in the spectrum. In the presence of both blue-green and yellow-green colors these filters are rather unspecific and parametrization of alpha becomes increasingly difficult. In these cases we find that the HSV filter is a good alternative.<list list-type="simple"><list-item><label>(iii)</label><p id="Par36"><italic>HSV thresholding</italic> This segmentation approach is widely used and well established in plant phenotyping (for details see e.g. [<xref ref-type="bibr" rid="CR24">24</xref>]). It usually outperforms RGB-based segmentations, when color is the key feature of interest. In the HSV color space Hue (H) is associated with the dominant wavelength of captured light, saturation (S) is inversely proportional to the amount of white light mixed with hue, while value (V) is given by the maximum radiance in all RGB color channels. Because color is only represented by Hue, thresholding operations are far easier to apply and to adapt to different segmentation tasks. HSV thresholding requires a conversion from RGB to HSV color space. After that, thresholding operations are applied as follows with defined ranges for each channel in <italic>I</italic>:</p><p id="Par37">
<disp-formula id="Equd"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$B\left( {x,y} \right) = \left\{ {\begin{array}{*{20}l} 1 \hfill &#x00026; {{\text{if}}\quad \begin{array}{*{20}l} {H_{{min}} &#x0003c; I_{H} \left( {x,y} \right) &#x0003c; H_{{max}} } \hfill \\ {S_{{min}} &#x0003c; I_{S} \left( {x,y} \right) &#x0003c; S_{{max}} } \hfill \\ {V_{{min}} &#x0003c; I_{V} \left( {x,y} \right) &#x0003c; V_{{max}} } \hfill \\ \end{array} } \hfill \\ 0 \hfill &#x00026; {otherwise} \hfill \\ \end{array} } \right.$$\end{document}</tex-math><mml:math id="M20" display="block"><mml:mrow><mml:mi>B</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfenced close="" open="{" separators=""><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mtext>if</mml:mtext><mml:mspace width="1em"/><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mi mathvariant="italic">min</mml:mi></mml:mrow></mml:msub><mml:mo>&#x0003c;</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mi>H</mml:mi></mml:msub><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>&#x0003c;</mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mi mathvariant="italic">max</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi mathvariant="italic">min</mml:mi></mml:mrow></mml:msub><mml:mo>&#x0003c;</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>&#x0003c;</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi mathvariant="italic">max</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi mathvariant="italic">min</mml:mi></mml:mrow></mml:msub><mml:mo>&#x0003c;</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mi>V</mml:mi></mml:msub><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>&#x0003c;</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi mathvariant="italic">max</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:mn>0</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="italic">otherwise</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="13007_2019_386_Article_Equd.gif" position="anchor"/></alternatives></disp-formula>
</p></list-item></list>
</p></sec><sec id="Sec5"><title>HSV parameter optimization via a genetic algorithm</title><p id="Par38">To optimize HSV-segmentation results the PSM app computes suitable parameter sets from example images using a genetic algorithm for parameter optimization [<xref ref-type="bibr" rid="CR25">25</xref>, <xref ref-type="bibr" rid="CR26">26</xref>]. This supervised approach requires at least one training image together with the ground truth, which is a binary image, where the target object (e.g. plant pixels) are labelled with ones and background pixels with zeros. PSM does not contain tools to produce ground truth images, but other software is suitable for this task. We recommend to use a computer or tablet with a larger screen for this purpose. The genetic algorithm starts with a population of <italic>k</italic> potential solutions (individuals), each of them with a set of parameters <italic>G</italic> (genome). During the iterative optimization process (<italic>i</italic> generations) the genome is altered by bio-inspired operations such as mutation, crossing and selection. In our case, the genome G consists of 6 thresholds:<disp-formula id="Eque"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$G = ( H_{min} |H_{max} |S_{min} |S_{max} |V_{min} |V_{max} )$$\end{document}</tex-math><mml:math id="M22" display="block"><mml:mrow><mml:mi>G</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mi mathvariant="italic">min</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mi mathvariant="italic">max</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi mathvariant="italic">min</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi mathvariant="italic">max</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi mathvariant="italic">min</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi mathvariant="italic">max</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><graphic xlink:href="13007_2019_386_Article_Eque.gif" position="anchor"/></alternatives></disp-formula>
</p><p id="Par39">The quality of optimization is evaluated via a fitness function <italic>f</italic>, which needs to be customized to the problem and parameter set. Here, <italic>f</italic> is defined as the percentage of correctly classified values.</p><p id="Par40">The genetic optimization algorithm consists of the following steps:<list list-type="bullet"><list-item><p id="Par41"><italic>Step 1 </italic>create a start population of k individuals with random values in the ranges of H, S and V.</p></list-item><list-item><p id="Par42"><italic>Step 2 </italic>calculate fitness f for each individual.</p></list-item><list-item><p id="Par43"><italic>Step 3 </italic>select the <italic>n</italic>-best individuals for reproduction.</p></list-item><list-item><p id="Par44"><italic>Step 4 </italic>create new offspring from every combination from the <italic>n</italic>-best individuals with crossing overs at probability P<sub><italic>C</italic></sub> (crossing over rate).</p></list-item><list-item><p id="Par45"><italic>Step 5 </italic>mutate each gene of each individual from the genepool with probability P<sub><italic>m</italic></sub> (mutation rate) and random value within range M (mutation range); continue with Step 2.</p></list-item></list>
</p><p id="Par46">We tested this approach with sample images from the banana dataset (see &#x0201c;<xref rid="Sec7" ref-type="sec">Results</xref>&#x0201d;). We split images into training and validation sets, each with 40 samples. We acquired ground truth image masks for both sets via HSV segmentation with individual parameter sets for each image and subsequent manual correction of the labels. In the genetic algorithm we choose a population of <inline-formula id="IEq7"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k = 20$$\end{document}</tex-math><mml:math id="M24"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>20</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="13007_2019_386_Article_IEq7.gif"/></alternatives></inline-formula> individuals at <inline-formula id="IEq8"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i = 250$$\end{document}</tex-math><mml:math id="M26"><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>250</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="13007_2019_386_Article_IEq8.gif"/></alternatives></inline-formula> generations with a mutation rate of <inline-formula id="IEq9"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P_{M} = 0.1$$\end{document}</tex-math><mml:math id="M28"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>M</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="13007_2019_386_Article_IEq9.gif"/></alternatives></inline-formula> and a mutation range of <inline-formula id="IEq10"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M = \pm 1\%$$\end{document}</tex-math><mml:math id="M30"><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mo>&#x000b1;</mml:mo><mml:mn>1</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="13007_2019_386_Article_IEq10.gif"/></alternatives></inline-formula> (of each respective channel range). The <inline-formula id="IEq11"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n = 5$$\end{document}</tex-math><mml:math id="M32"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="13007_2019_386_Article_IEq11.gif"/></alternatives></inline-formula> individuals with highest fitness scores <italic>f</italic> were crossed with each other with <inline-formula id="IEq12"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P_{C} = 0.5$$\end{document}</tex-math><mml:math id="M34"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>C</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="13007_2019_386_Article_IEq12.gif"/></alternatives></inline-formula> creating new individuals for the next generation. To determine the best configuration for <italic>G</italic> we processes all training images in one turn, repeated this process 20 times and computed the average fitness function <inline-formula id="IEq13"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\bar{f}$$\end{document}</tex-math><mml:math id="M36"><mml:mover accent="true"><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">&#x000af;</mml:mo></mml:mrow></mml:mover></mml:math><inline-graphic xlink:href="13007_2019_386_Article_IEq13.gif"/></alternatives></inline-formula> of the best performing individual. Figure&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>a shows the performance of the best performing individual in comparison to the average performance of the entire population for the first 20 generations. After 250 generations the fitness reached a value of <inline-formula id="IEq14"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\bar{f} = 99.87 \pm 0.02\%$$\end{document}</tex-math><mml:math id="M38"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">&#x000af;</mml:mo></mml:mrow></mml:mover><mml:mo>=</mml:mo><mml:mn>99.87</mml:mn><mml:mo>&#x000b1;</mml:mo><mml:mn>0.02</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="13007_2019_386_Article_IEq14.gif"/></alternatives></inline-formula> (no substantial progress <inline-formula id="IEq15"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\bar{f}$$\end{document}</tex-math><mml:math id="M40"><mml:mover accent="true"><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">&#x000af;</mml:mo></mml:mrow></mml:mover></mml:math><inline-graphic xlink:href="13007_2019_386_Article_IEq15.gif"/></alternatives></inline-formula> could be perceived). Already after 12 generations the best performing individual reached a fitness of <inline-formula id="IEq16"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\bar{f} = 99.75 \%$$\end{document}</tex-math><mml:math id="M42"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">&#x000af;</mml:mo></mml:mrow></mml:mover><mml:mo>=</mml:mo><mml:mn>99.75</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="13007_2019_386_Article_IEq16.gif"/></alternatives></inline-formula>. In the next step the best performing genome <italic>G</italic> was used to segment the validation images and resulting image masks were compared with ground truth by computing once more the fitness function <italic>f</italic>. The fitness for all 40 validation images averaged <inline-formula id="IEq17"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\bar{f} = 99.84 \pm 0.05 \%$$\end{document}</tex-math><mml:math id="M44"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">&#x000af;</mml:mo></mml:mrow></mml:mover><mml:mo>=</mml:mo><mml:mn>99.84</mml:mn><mml:mo>&#x000b1;</mml:mo><mml:mn>0.05</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="13007_2019_386_Article_IEq17.gif"/></alternatives></inline-formula>. In Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref> we show sample images that was used for training (Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>b), for testing (Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>c) and the final plant image mask (Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>d). As this optimization process requires a substantial amount of time, we recommend not to use more than 25 iterations. As illustrated above <inline-formula id="IEq18"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\bar{f}$$\end{document}</tex-math><mml:math id="M46"><mml:mover accent="true"><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">&#x000af;</mml:mo></mml:mrow></mml:mover></mml:math><inline-graphic xlink:href="13007_2019_386_Article_IEq18.gif"/></alternatives></inline-formula> will not improve notably after a few iterations. On a Samsung Galaxy S6 the processing time was approximately 20&#x000a0;min for 25 generations.<fig id="Fig3"><label>Fig.&#x000a0;3</label><caption><p>Genetic optimization of HSV thresholding parameters: <bold>a</bold> Illustration of the fitness function for the whole population (blue) and the best performing individual (red); after 3 generations more than 99% of the pixels are classified correctly (99.75% after 12 generations). <bold>b</bold> Training image, which served as the input for the optimization process; <bold>c</bold> test image and <bold>d</bold> corresponding test image mask that was computed with the optimized HSV parameter set</p></caption><graphic xlink:href="13007_2019_386_Fig3_HTML" id="MO8"/></fig>
</p></sec><sec id="Sec6"><title>Image post-processing and analysis</title><p id="Par47">Each computed segmentation is post-processed in two steps. First, morphological operations (erosion and dilation) are applied to close small gaps and to remove small fragments. Then, components with an 8-connected neighborhood are identified and labeled. In this way, multiple objects like detached leaves are counted and analyzed at the same time. The estimation of projected leaf area is the key feature of PSM and the output are pixels counts for each segment. To ensure comparability between different measurements (e.g. in setups with a varying camera-to-plant distance) PSM allows for a pixel-to-area conversion. For this purpose the user needs to place a calibration target (e.g., checkerboard pattern [<xref ref-type="bibr" rid="CR27">27</xref>]) at approximately the same distance as the plant object to be photographed. PSM automatically detects the pattern and calculates a conversion factor that is used to compute metric area values from pixel counts. Besides the estimation of projected leaf area, PSM also provides a number of additional measures, which are listed in Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>. Analyzed traits are exported to a CSV file together with information on luminance (LUX) and GPS coordinates.<table-wrap id="Tab1"><label>Table&#x000a0;1</label><caption><p>Estimated Traits (for entire image or single segments): if analysis of single segments is enabled PSM delivers the number of segments (e.g. can be used for object counting) and the statistics on each single segment</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Trait</th><th align="left">Definition</th><th align="left">Unit</th></tr></thead><tbody><tr><td align="left">Projected leaf area (PLA)</td><td align="left">Segment-wise pixel sum</td><td align="left">px/mm<sup>2</sup></td></tr><tr><td align="left">Perimeter</td><td align="left">Length of segment contour</td><td align="left">px</td></tr><tr><td align="left">Segment width</td><td align="left">Maximum horizontal segment stretch</td><td align="left">px/mm</td></tr><tr><td align="left">segment height</td><td align="left">Maximum vertical segment stretch</td><td align="left">px/mm</td></tr><tr><td align="left">Red mean</td><td align="left">Average intensity in the red channel</td><td align="left">Channel intensity</td></tr><tr><td align="left">Green mean</td><td align="left">Average intensity in the green channel</td><td align="left">Channel intensity</td></tr><tr><td align="left">Blue mean</td><td align="left">Average intensity in the blue channel</td><td align="left">Channel intensity</td></tr><tr><td align="left">Hue mean</td><td align="left">Average intensity in the hue channel</td><td align="left">Channel intensity</td></tr><tr><td align="left">Saturation mean</td><td align="left">Average intensity in the saturation channel</td><td align="left">Channel intensity</td></tr><tr><td align="left">Value mean</td><td align="left">Average intensity in the value channel</td><td align="left">Channel intensity</td></tr></tbody></table></table-wrap>
</p></sec></sec><sec id="Sec7"><title>Results</title><p id="Par48">We tested <italic>Plant Screen Mobile</italic> in two different application scenarios to evaluate both versatility and performance. In these case studies we examined plants with contrasting shoot architecture, banana and both <italic>Eragrostis tef</italic> and <italic>Eragrostis pilosa.</italic> Two genotypes of banana plantlets were obtained from University of Hohenheim&#x02013;Institute of Crop Science (Crop Physiology of Specialty Crops), Germany. Khai Thong Ruang KTR (Musa AAA) is a drought-sensitive desert banana from Thailand, Saba (Musa ABB) is a drought-tolerant African plantain. In total we used 52 replicates, 27 KTR and 25 Saba. In the <italic>Eragrostis</italic> experiment we used two species, i.e. 100 replicates in <italic>Eragrostis tef</italic> (teff) and 40 replicates in <italic>Eragrostis pilosa</italic>. Teff is a monocotyledonous species used in many parts of Africa, India, Australia and northern America. <italic>Eragrostis pilosa</italic> has no economic significance. The examples in the Additional file <xref rid="MOESM2" ref-type="media">2</xref> show typical images of banana and <italic>Eragrostis</italic> that were used in our experiments. For the destructive measurements plant leaves where weighed with a high-accuracy lab balance (XS 205, Mettler Toledo, United States) and measured with a leaf area meter (LI-3100, Licor, United States) to obtain the true leaf area destructively.</p><p id="Par49">Each plant was imaged from 4 sides adding up to 208 images in banana and 560 images in <italic>Eragrostis</italic>. Projected leaf area was estimated with PSM and compared against SVM-classified images that were acquired and analyzed with the SCREENHOUSE imaging system of IBG-2, Forschungszentrum J&#x000fc;lich GmbH [<xref ref-type="bibr" rid="CR28">28</xref>]. The SCREENHOUSE is an automated greenhouse plant phenotyping platform, equipped with an imaging station for data acquisition under controlled light conditions. It is equipped with three RGB cameras (Grasshopper 2, Point Grey Research, 5MP) that image plants from three different view angles. Support vector machine (SVM) classification [<xref ref-type="bibr" rid="CR29">29</xref>] of foreground and background pixels is a supervised approach based on training data sets, which generally yields very good solutions for linear- and nonlinear separable data regarding stability and accuracy and which is robust against outliers in the data. In both approaches the projected leaf area of each plant was averaged over 4 views, in the case of PSM outside the application using the csv output file and MS Excel.</p><sec id="Sec8"><title>Projected leaf area of <italic>Eragrostris</italic> and banana whole plants</title><p id="Par50">In these two case studies, we compared estimations of projected leaf area of <italic>Eragrostris tef</italic> and <italic>pilosa</italic> plants as well as banana plants, which were imaged with a smartphone (Galaxy S6, Samsung Electronics) and similarly with the imaging system of the SCREENHOUSE. In our test scenario, we used a side view perspective (perpendicular to the shoot axis). In order to obtain a comparable imaging setup, the smartphone was fixed on a tripod at about the same distance and orientation as the corresponding side view SCREENHOUSE camera. Camera settings were IS0 100, exposure compensation &#x02212; 2.0, white balance 5500&#x000a0;K and manual focus without flash in both experiments. To take advantage of the highest camera resolution thereby speeding up image acquisition, images were captured successively and analyzed afterwards with the batch processing option of PSM. All images were segmented with the greenness thresholding method using the ExGR Index with <inline-formula id="IEq19"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha = - \,0.03$$\end{document}</tex-math><mml:math id="M48"><mml:mrow><mml:mi>&#x003b1;</mml:mi><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mspace width="0.166667em"/><mml:mn>0.03</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="13007_2019_386_Article_IEq19.gif"/></alternatives></inline-formula> for <italic>Eragrostis</italic> and <inline-formula id="IEq20"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha = 0.03$$\end{document}</tex-math><mml:math id="M50"><mml:mrow><mml:mi>&#x003b1;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.03</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="13007_2019_386_Article_IEq20.gif"/></alternatives></inline-formula> for banana plants. Images from the SCREENHOUSE were analyzed with our in-house segmentation software, which uses a pre-trained classifier based on features from the three RGB channels and a polynomial SVM kernel, which showed best results in our test scenarios. Plant fresh weight and leaf area was measured destructively. Projected leaf area estimated by PSM shows high correlations to both reference measurements (weight and leaf area, Figs.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref>, <xref rid="Fig5" ref-type="fig">5</xref>). Taking the differences between <italic>R</italic><sup>2</sup>-values as an indicator PSM performs only slightly worse in comparison to the SCREENHOUSE imaging system. In banana and <italic>E. pilosa</italic> there were no remarkable effects. In <italic>E. pilosa</italic>
<inline-formula id="IEq21"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\Delta R^{2}$$\end{document}</tex-math><mml:math id="M52"><mml:mrow><mml:mi mathvariant="normal">&#x00394;</mml:mi><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="13007_2019_386_Article_IEq21.gif"/></alternatives></inline-formula> was 0.02 for LA and 0.03 for weight. The difference in <italic>E. tef</italic> was slightly more pronounced with values of <inline-formula id="IEq22"><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\Delta R^{2} = 0.09$$\end{document}</tex-math><mml:math id="M54"><mml:mrow><mml:mi mathvariant="normal">&#x00394;</mml:mi><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mn>0.09</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="13007_2019_386_Article_IEq22.gif"/></alternatives></inline-formula> for both LA and weight. In the <italic>Eragrostis</italic> case study (Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref>) both species <italic>E. tef</italic> and <italic>E. pilosa</italic> differ in leaf architecture and could therefore be distinguished in the diagrams. In comparison to <italic>E. tef</italic> the more dense leaf display of <italic>E. pilosa</italic> results in lower PLA estimations especially for smaller plants. Leaf area and fresh weight results are comparable, which could be taken as an indicator for minor variations in leaf thickness. Lower <italic>R</italic><sup>2</sup>-values in <italic>E. tef</italic> for PSM are mainly caused by a few data points that are most likely underestimated particularly in comparison to the SCREENHOUSE results. In the evaluation of the banana experiment we did not distinguish between both genotypes as they displayed no significant difference. Therefore both results are combined in Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5</xref>. PSM results differ only marginally from the SCREENHOUSE evaluation making this plant particularly suitable for the analysis with the mobile application at the developmental stages afforded by this study.<fig id="Fig4"><label>Fig.&#x000a0;4</label><caption><p>Case study <italic>Eragrostis</italic>: Projected leaf area (PLA) of complete plants of two <italic>Eragrostis</italic> species estimated with the Screenhouse System (<bold>a</bold>, <bold>c</bold>) and <italic>Plant Screen Mobile</italic> application (<bold>b</bold>, <bold>d</bold>) was compared to measured leaf area (<bold>a</bold>, <bold>b</bold>) and measured fresh weight (<bold>c</bold>, <bold>d</bold>)</p></caption><graphic xlink:href="13007_2019_386_Fig4_HTML" id="MO9"/></fig>
<fig id="Fig5"><label>Fig.&#x000a0;5</label><caption><p>Case study banana: Projected leaf area (PLA) of complete banana plants estimated with the SCREENHOUSE System (<bold>a</bold>, <bold>c</bold>) and <italic>Plant Screen Mobile</italic> application (<bold>b</bold>, <bold>d</bold>) was compared to measured leaf area (<bold>a</bold>, <bold>b</bold>) and measured fresh weight (<bold>c</bold>, <bold>d</bold>)</p></caption><graphic xlink:href="13007_2019_386_Fig5_HTML" id="MO10"/></fig>
</p><p id="Par51">In the Additional file <xref rid="MOESM2" ref-type="media">2</xref> we compiled various examples to display additional application scenarios; the first two show typical shoot images of <italic>Eragrostis</italic> and banana. In the following we tested the app also with root images (<italic>Cassava</italic>), blossom segmentation and seed segmentation (here: barley and rape seeds).</p></sec></sec><sec id="Sec9"><title>Discussion</title><p id="Par52">The segmentation process is the crucial step towards the quantitative estimation of leaf area or other plant traits. Therefore, we implemented a range of different approaches that use channel intensities in Gray, RGB or HSV color space. All these methods have in common that they can be processed on Android-based smartphones (of the last generations). We tested the smartphone App on African plant species with contrasting leaf architecture to showcase their application as an affordable phenotyping device supporting research where larger investments may be prohibited. In a controlled setup we could show that differences between PSM and an established shoot imaging platform like our SCREENHOUSE that uses powerful SVM segmentation are marginal. Banana and <italic>Eragrostis pilosa</italic> plants displayed barely any difference, while the difference (<inline-formula id="IEq23"><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\Delta R^{2} = 0.09$$\end{document}</tex-math><mml:math id="M56"><mml:mrow><mml:mi mathvariant="normal">&#x00394;</mml:mi><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mn>0.09</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="13007_2019_386_Article_IEq23.gif"/></alternatives></inline-formula>) in <italic>Eragrostis tef</italic> plants was the largest. Most likely these deviations are not a consequence of different hardware. Differences rather emerge from the applied processing method. Here, the SVM method benefits from its better classification capabilities. In PSM the PLA of a few <italic>Eragrostis tef</italic> plants was underestimated leading to a weaker correlation (Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref>). It must therefore be assumed that the implemented PSM methods work equally well if foreground and background features (color, intensities) are clearly separable. If this is not the case, e.g. if plants grow in the presence of other weeds or algae develop on the substrate surface, more sophisticated methods like the presented SVM method or likewise methods (e.g. Random Forest classifiers) may help. However, one has to consider the many cases, especially in outdoor applications, where training data has to be produced again and again to account for changing imaging conditions. Additional training time and computational costs would arise that can hardly be managed efficiently on a smartphone. Here the advantages of a more flexible application like PSM are evident, where the outcome can be visually controlled and changed by simple re-adjustment of parameters. We displayed the application in a robust setup, where PSM can be used in batch processing mode together with genetic parameter optimization and a pixel-to-metric system calibration. If used in less controlled application scenarios (e.g. outdoors with changing illumination) each imaging situation can be parameterized individually in order to achieve comparable results. We also highlight that PSM is not restricted to the detection of shoot and leaves. The HSV filter offers enough opportunities also to detect other plant parts like blossoms, fruits or seeds.</p></sec><sec id="Sec10"><title>Conclusion</title><p id="Par53">Estimation of plant traits by digital imaging, which requires the segmentation of imaged objects (plants and leaves as well as blossoms, fruits or seeds) is still one of the biggest challenge in non-invasive plant phenotyping approaches. There are numerous methods, which have been introduced in recent times, however for mobile solutions such as smartphones or other handheld devices there is still a lack of applications, especially ones that are generic and that make use of smartphone processing power and combine other sensors data (e.g., GPS). Constraints are not only given by the lower processing capabilities, which e.g. limit the use of machine learning based methodologies, but also the evident usage of such devices in various application scenarios that range from controlled imaging conditions (like a lab or dedicated imaging box) to not-controlled conditions (greenhouse or outdoor). With the development of <italic>Plant Screen Mobile</italic> we provide a new analysis tool that exploits various smartphone capabilities to easily quantify contrasting leaf architectures with respect to projected leaf area, which can be used as proxy for leaf area and biomass. The central processing step is the separation of plants from imaged background. Here we included different solutions that can be selected according to image acquisition conditions and desired processing speed, which also determines the speed of visual feedback for the user. The image stream is processed on-the-fly and thus the user is able to parametrize the analysis effectively and rapidly. Furthermore, we explored different application scenarios and we conclude that PSM is sufficiently versatile for a variety of plant tissues and illumination conditions.</p></sec><sec sec-type="supplementary-material"><title>Additional files</title><sec id="Sec11"><p>
<supplementary-material content-type="local-data" id="MOESM1"><media xlink:href="13007_2019_386_MOESM1_ESM.docx"><caption><p><bold>Additional file 1.</bold> Performance comparison between greenness and HSV segmentation.</p></caption></media></supplementary-material>
<supplementary-material content-type="local-data" id="MOESM2"><media xlink:href="13007_2019_386_MOESM2_ESM.docx"><caption><p><bold>Additional file 2.</bold> Application Scenarios for Plant Screen Mobile.</p></caption></media></supplementary-material>
</p></sec></sec></body><back><glossary><title>Abbreviations</title><def-list><def-item><term><italic>&#x003b1;</italic></term><def><p id="Par4">threshold that is applied on an image to separate plant from background pixels resulting in a binary mask <italic>B</italic></p></def></def-item><def-item><term><italic>B</italic></term><def><p id="Par5">binary image of ones (plant pixels) and zeros (background pixels)</p></def></def-item><def-item><term>CSV</term><def><p id="Par6">data file of comma separated values</p></def></def-item><def-item><term>ExGR</term><def><p id="Par7"><italic>Excess Green Excess Red</italic> greenness index</p></def></def-item><def-item><term><italic>f</italic></term><def><p id="Par8">fitness value in the genetic algorithm</p></def></def-item><def-item><term><italic>G</italic></term><def><p id="Par9">genome in a genetic algorithm</p></def></def-item><def-item><term>GCC</term><def><p id="Par10"><italic>Green Chromatic Coordinate</italic> greenness index</p></def></def-item><def-item><term>H, S, and V</term><def><p id="Par11">hue, saturation, and value channels of the HSV color space that result from a transformation of RGB color space</p></def></def-item><def-item><term><italic>I</italic><sub><italic>R</italic></sub><italic>I</italic><sub><italic>G</italic></sub>, and <italic>I</italic><sub><italic>B</italic></sub></term><def><p id="Par12">intensity values of each RBG channel</p></def></def-item><def-item><term><italic>I</italic><sub><italic>H</italic></sub><italic>I</italic><sub><italic>S</italic></sub>, and <italic>I</italic><sub><italic>V</italic></sub></term><def><p id="Par13">intensity values of each HSV channel</p></def></def-item><def-item><term><italic>i</italic></term><def><p id="Par14">number of generations in the genetic algorithm</p></def></def-item><def-item><term><italic>k</italic></term><def><p id="Par15">number of potential solutions (individuals) in the genetic algorithm</p></def></def-item><def-item><term><italic>M</italic></term><def><p id="Par16">mutation range</p></def></def-item><def-item><term><italic>P</italic><sub><italic>C</italic></sub></term><def><p id="Par17">crossing over rate</p></def></def-item><def-item><term><italic>P</italic><sub><italic>M</italic></sub></term><def><p id="Par18">mutation rate</p></def></def-item><def-item><term>PSM</term><def><p id="Par19">Plant Screen Mobile application for smartphones</p></def></def-item><def-item><term>R, G, and B</term><def><p id="Par20">red, green, and blue channels of the an RGB image</p></def></def-item><def-item><term>SVM</term><def><p id="Par21">support vector machine</p></def></def-item><def-item><term>VEG</term><def><p id="Par22"><italic>Vegetative</italic> greenness index</p></def></def-item><def-item><term>x, y</term><def><p id="Par23">pixel position in an image at x (column index) and y (row index)</p></def></def-item></def-list></glossary><ack><title>Authors&#x02019; contributions</title><p>MML wrote the manuscript and developed and tested the genetic algorithm. CB set up the first version of the smartphone app; JW revised the app, added a new GUI and new functionalities. TW supervised the case study with banana and <italic>Eragrostis</italic> plants. FF and US conceived the study. All authors read and approved the final manuscript.</p><sec id="FPar1"><title>Acknowledgements</title><p id="Par54">We would like to thank and acknowledge the work of Thomas Bodewein (IBG-2 Plant Sciences, Forschungszentrum J&#x000fc;lich) for operating the SCREENHOUSE system and for technical assistance. Daniel Cudjoe (CSIR-Crops Research Institute, Kumasi, Ghana) for plant cultivation and measurement of the banana plants and Dereje Beyene Degefie (Department of Microbial, Cellular and Molecular Biology, Addis Ababa University, Ethiopia) for plant cultivation and measurement of <italic>Eragrostis</italic> plants within the framework of the BMBF funded <italic>GlobE BiomassWeb</italic> project.</p></sec><sec id="FPar2"><title>Competing interests</title><p id="Par55">The authors declare that they have no competing interests.</p></sec><sec id="FPar3"><title>Availability of data and materials</title><p id="Par56">The app is accompanied by a detailed manual and checkerboard images for calibration, which can also be downloaded from the project homepage. The datasets generated and/or analyzed during the current study are available in the e!DAL research data publication system, <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.25622/FZJ/2018/1">http://dx.doi.org/10.25622/FZJ/2018/1</ext-link> [<xref ref-type="bibr" rid="CR30">30</xref>].</p></sec><sec id="FPar4"><title>Availability and requirements</title><p id="Par57">Project name: Plant Screen Mobile. Project home page: <ext-link ext-link-type="uri" xlink:href="https://fz-juelich.de/ibg/ibg-2/psm">https://fz-juelich.de/ibg/ibg-2/psm</ext-link>. Operating system(s): Android OS 4.0 (Ice Cream Sandwich) or higher. Programming language: Java. Other requirements: OpenCV manager (will be installed during Plant Screen Mobile setup). License: GNU GPL. Any restrictions to use by non-academics: app is restricted to academic use only.</p></sec><sec id="FPar5"><title>Consent for publication</title><p id="Par58">Not applicable.</p></sec><sec id="FPar6"><title>Ethics approval and consent to participate</title><p id="Par59">Not applicable.</p></sec><sec id="FPar7"><title>Funding</title><p id="Par60">This work was conducted within the framework of DPPN (German Plant Phenotyping Network), funded by the German Federal Ministry of Education and Research (BMBF: project identification number: 031A053). Cultivation and measurements in <italic>Eragrostis</italic> and banana was funded by <italic>GlobE BiomassWeb</italic> (BMBF: 031A258I). This development was partly supported by the SAPPHIRE project (BMBF: 01DP17023).</p></sec><sec id="FPar8"><title>Publisher&#x02019;s Note</title><p id="Par61">Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></sec></ack><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiorani</surname><given-names>F</given-names></name><name><surname>Rascher</surname><given-names>U</given-names></name><name><surname>Jahnke</surname><given-names>S</given-names></name><name><surname>Schurr</surname><given-names>U</given-names></name></person-group><article-title>Imaging plants dynamics in heterogenic environments</article-title><source>Curr Opin Biotechnol</source><year>2012</year><volume>23</volume><fpage>227</fpage><lpage>236</lpage><pub-id pub-id-type="doi">10.1016/j.copbio.2011.12.010</pub-id><pub-id pub-id-type="pmid">22257752</pub-id></element-citation></ref><ref id="CR2"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Breda</surname><given-names>NJJ</given-names></name></person-group><article-title>Ground-based mmeasurement of leaf area index: a review of methods, iinstrument and current controversies</article-title><source>J Exp Bot</source><year>2003</year><volume>54</volume><issue>392</issue><fpage>2403</fpage><lpage>2417</lpage><pub-id pub-id-type="doi">10.1093/jxb/erg263</pub-id><pub-id pub-id-type="pmid">14565947</pub-id></element-citation></ref><ref id="CR3"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zheng</surname><given-names>G</given-names></name><name><surname>Moskal</surname><given-names>LM</given-names></name></person-group><article-title>Retrieving Leaf Area Index (LAI) using remote sensing: theories, methods and sensors</article-title><source>Sensors</source><year>2009</year><volume>9</volume><fpage>2719</fpage><lpage>2745</lpage><pub-id pub-id-type="doi">10.3390/s90402719</pub-id><pub-id pub-id-type="pmid">22574042</pub-id></element-citation></ref><ref id="CR4"><label>4.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ross</surname><given-names>J</given-names></name></person-group><source>The radiation regime and architecture of plant stands</source><year>1981</year><publisher-loc>The Hague</publisher-loc><publisher-name>Dr Junk W</publisher-name></element-citation></ref><ref id="CR5"><label>5.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Jones</surname><given-names>HG</given-names></name></person-group><source>Plants and microclimate&#x02014;a quantitative approach to environmental plant physiology</source><year>1992</year><publisher-loc>Cambridge</publisher-loc><publisher-name>Cambridge University Press</publisher-name></element-citation></ref><ref id="CR6"><label>6.</label><mixed-citation publication-type="other">Louarn G, Carr&#x000e9; S, Boudon F, Eprinchard A, Combes D, editors. Characterization of whole plant leaf area properties using laser scanner point clouds. In: Fourth international symposium on plant growth modeling, simulation, visualization and applications, Shanghai, China; 2012 Phenotyping\Leaves\Leaf Area.</mixed-citation></ref><ref id="CR7"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sumida</surname><given-names>A</given-names></name><name><surname>Nakai</surname><given-names>T</given-names></name><name><surname>Yamada</surname><given-names>M</given-names></name><name><surname>Ono</surname><given-names>K</given-names></name><name><surname>Uemura</surname><given-names>S</given-names></name><name><surname>Hara</surname><given-names>T</given-names></name></person-group><article-title>Ground-based estimation of leaf area index and vertical distribution of leaf area density in a <italic>Betula ermanii</italic> forest</article-title><source>Silva Fenn</source><year>2009</year><volume>43</volume><fpage>799</fpage><pub-id pub-id-type="doi">10.14214/sf.174</pub-id></element-citation></ref><ref id="CR8"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rico-Garcia</surname><given-names>E</given-names></name><name><surname>Hernandez-Hernandez</surname><given-names>F</given-names></name><name><surname>Soto-Zarazua</surname><given-names>GM</given-names></name><name><surname>Herrera-Ruiz</surname><given-names>G</given-names></name></person-group><article-title>Two new methods for the estimation of leaf area using digital photography</article-title><source>Int J Agric Biol</source><year>2009</year><volume>11</volume><issue>4</issue><fpage>397</fpage><lpage>400</lpage></element-citation></ref><ref id="CR9"><label>9.</label><mixed-citation publication-type="other">Hajjdiab H, Obaid A, editors. A vision-based approach for nondestructive leaf area estimation. In: The 2nd conference on environmental science and information application technology; 2010.</mixed-citation></ref><ref id="CR10"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gong</surname><given-names>A</given-names></name><name><surname>Wu</surname><given-names>X</given-names></name><name><surname>Qiu</surname><given-names>Z</given-names></name><name><surname>He</surname><given-names>Y</given-names></name></person-group><article-title>A handheld device for leaf area measurement</article-title><source>Comput Electron Agric</source><year>2013</year><volume>98</volume><fpage>74</fpage><lpage>80</lpage><pub-id pub-id-type="doi">10.1016/j.compag.2013.07.013</pub-id></element-citation></ref><ref id="CR11"><label>11.</label><mixed-citation publication-type="other">Hofmann D, Dittrich P-G, G&#x000e4;rtner C, Klemm R, editors. Multi-hybrid instrumentations with smartphones and smartpads for innovative in-field and POC diagnostics. In: SPIE Proceedings&#x02014;Microfluidics, BioMEMS, and Medical Microsystems XI; 2013 Phenotyping\Affordable Phenotyping.</mixed-citation></ref><ref id="CR12"><label>12.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Intaravanne</surname><given-names>Y</given-names></name><name><surname>Sumriddetchkajorn</surname><given-names>S</given-names></name><name><surname>Nukeaw</surname><given-names>J</given-names></name></person-group><article-title>Cell phone-based two-dimensional spectral analysis for banana ripeness estimation</article-title><source>Sens Actuators B Chem</source><year>2012</year><volume>168</volume><fpage>390</fpage><lpage>394</lpage><pub-id pub-id-type="doi">10.1016/j.snb.2012.04.042</pub-id></element-citation></ref><ref id="CR13"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Intaravanne</surname><given-names>Y</given-names></name><name><surname>Sumriddetchkajorn</surname><given-names>S</given-names></name></person-group><article-title>Android-based rice leaf color analyzer for estimating the needed amount of nitrogen fertilizer</article-title><source>Comput Electron Agric</source><year>2015</year><volume>116</volume><fpage>228</fpage><lpage>233</lpage><pub-id pub-id-type="doi">10.1016/j.compag.2015.07.005</pub-id></element-citation></ref><ref id="CR14"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Komyshev</surname><given-names>E</given-names></name><name><surname>Genaev</surname><given-names>M</given-names></name><name><surname>Afonnikov</surname><given-names>D</given-names></name></person-group><article-title>Evaluation of the SeedCounter, a mobile application for grain phenotyping</article-title><source>Front Plant Sci</source><year>2017</year><volume>7</volume><fpage>1990</fpage><pub-id pub-id-type="doi">10.3389/fpls.2016.01990</pub-id><pub-id pub-id-type="pmid">28101093</pub-id></element-citation></ref><ref id="CR15"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhihong</surname><given-names>M</given-names></name><name><surname>Yuhan</surname><given-names>M</given-names></name><name><surname>Liang</surname><given-names>G</given-names></name><name><surname>Chengliang</surname><given-names>L</given-names></name></person-group><article-title>Smartphone-based visual measurement and portable instrumentation for crop seed phenotyping</article-title><source>IFAC-PapersOnLine</source><year>2016</year><volume>49</volume><fpage>259</fpage><lpage>264</lpage><pub-id pub-id-type="doi">10.1016/j.ifacol.2016.10.048</pub-id></element-citation></ref><ref id="CR16"><label>16.</label><mixed-citation publication-type="other">Grossetete M, Berthoumieu Y, Da Costa J-P, Germain C, Lavialle O, Grenier G. Early estimation of vineyard yield: site specific counting of berries by using a smartphone. In: International Conference on Agriculture Engineering (AgEng), Jul 2012, Spain. pp.tabla137-C1915, 2012.</mixed-citation></ref><ref id="CR17"><label>17.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pethybridge</surname><given-names>SJ</given-names></name><name><surname>Nelson</surname><given-names>SC</given-names></name></person-group><article-title>Leaf doctor: a new portable application for quantifying plant disease severity</article-title><source>Plant Dis</source><year>2015</year><volume>99</volume><issue>10</issue><fpage>1310</fpage><lpage>1316</lpage><pub-id pub-id-type="doi">10.1094/PDIS-03-15-0319-RE</pub-id></element-citation></ref><ref id="CR18"><label>18.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Confalonieri</surname><given-names>R</given-names></name><name><surname>Foi</surname><given-names>M</given-names></name><name><surname>Casa</surname><given-names>R</given-names></name><name><surname>Aquaro</surname><given-names>S</given-names></name><name><surname>Tona</surname><given-names>E</given-names></name><name><surname>Peterle</surname><given-names>M</given-names></name><etal/></person-group><article-title>Development of an app for estimating leaf area index using a smartphone. Trueness and precision determination and comparison with other indirect methods</article-title><source>Comput Electron Agric</source><year>2013</year><volume>96</volume><fpage>67</fpage><lpage>74</lpage><pub-id pub-id-type="doi">10.1016/j.compag.2013.04.019</pub-id></element-citation></ref><ref id="CR19"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Otsu</surname><given-names>N</given-names></name></person-group><article-title>Threshold selection method from gray-level histograms</article-title><source>IEEE Trans Syst Man Cybern</source><year>1979</year><volume>9</volume><issue>1</issue><fpage>62</fpage><lpage>66</lpage><pub-id pub-id-type="doi">10.1109/TSMC.1979.4310076</pub-id></element-citation></ref><ref id="CR20"><label>20.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyer</surname><given-names>GE</given-names></name><name><surname>Neto</surname><given-names>JC</given-names></name></person-group><article-title>Verification of color vegetation indices for automated crop imaging applications</article-title><source>Comput Electron Agric</source><year>2008</year><volume>63</volume><fpage>282</fpage><lpage>293</lpage><pub-id pub-id-type="doi">10.1016/j.compag.2008.03.009</pub-id></element-citation></ref><ref id="CR21"><label>21.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>W</given-names></name><name><surname>Wang</surname><given-names>S</given-names></name><name><surname>Zhao</surname><given-names>X</given-names></name><name><surname>Zhang</surname><given-names>J</given-names></name><name><surname>Feng</surname><given-names>J</given-names></name></person-group><article-title>Greenness identification based on HSV decision tree</article-title><source>Inf Process Agric</source><year>2015</year><volume>2</volume><fpage>149</fpage><lpage>160</lpage></element-citation></ref><ref id="CR22"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hague</surname><given-names>T</given-names></name><name><surname>Tillet</surname><given-names>ND</given-names></name><name><surname>Wheeler</surname><given-names>H</given-names></name></person-group><article-title>Automated crop and weed monitoring in widely spaced cereals</article-title><source>Precis Agric</source><year>2006</year><volume>7</volume><fpage>21</fpage><lpage>32</lpage><pub-id pub-id-type="doi">10.1007/s11119-005-6787-1</pub-id></element-citation></ref><ref id="CR23"><label>23.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Neto</surname><given-names>JC</given-names></name></person-group><source>A combined statistical-soft computing approach for classification and mapping weed species in minimum -tillage systems</source><year>2004</year><publisher-loc>Lincoln</publisher-loc><publisher-name>University of Nebraska</publisher-name></element-citation></ref><ref id="CR24"><label>24.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walter</surname><given-names>A</given-names></name><name><surname>Scharr</surname><given-names>H</given-names></name><name><surname>Gilmer</surname><given-names>F</given-names></name><name><surname>Zierer</surname><given-names>R</given-names></name><name><surname>Nagel</surname><given-names>KA</given-names></name><name><surname>Ernst</surname><given-names>M</given-names></name><etal/></person-group><article-title>Dynamics of seedling growth acclimation towards altered light conditions can be quantified via GROWSCREEN: a setup and procedure designed for rapid optical phenotyping of different plant species</article-title><source>New Phytol</source><year>2007</year><volume>174</volume><issue>2</issue><fpage>447</fpage><lpage>455</lpage><pub-id pub-id-type="doi">10.1111/j.1469-8137.2007.02002.x</pub-id><pub-id pub-id-type="pmid">17388907</pub-id></element-citation></ref><ref id="CR25"><label>25.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Holland</surname><given-names>JH</given-names></name></person-group><source>Adaptation in natural and artificial systems</source><year>1992</year><publisher-loc>Cambridge</publisher-loc><publisher-name>MIT Press</publisher-name></element-citation></ref><ref id="CR26"><label>26.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whitley</surname><given-names>D</given-names></name></person-group><article-title>A genetic algorithm tutorial</article-title><source>Stat Comput</source><year>1994</year><volume>4</volume><issue>2</issue><fpage>65</fpage><lpage>85</lpage><pub-id pub-id-type="doi">10.1007/BF00175354</pub-id></element-citation></ref><ref id="CR27"><label>27.</label><mixed-citation publication-type="other">Itseez. Open Source Computer Vision Library. 2015. <ext-link ext-link-type="uri" xlink:href="https://github.com/itseez/opencv">https://github.com/itseez/opencv</ext-link>.</mixed-citation></ref><ref id="CR28"><label>28.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nakhforoosh</surname><given-names>A</given-names></name><name><surname>Bodewein</surname><given-names>T</given-names></name><name><surname>Fiorani</surname><given-names>F</given-names></name><name><surname>Bodner</surname><given-names>G</given-names></name></person-group><article-title>Identification of water use strategies at early growth stages in durum wheat from shoot phenotyping and physiological measurements</article-title><source>Front Plant Sci</source><year>2016</year><volume>7</volume><fpage>1155</fpage><pub-id pub-id-type="doi">10.3389/fpls.2016.01155</pub-id><pub-id pub-id-type="pmid">27547208</pub-id></element-citation></ref><ref id="CR29"><label>29.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sch&#x000f6;lkopf</surname><given-names>B</given-names></name><name><surname>Smola</surname><given-names>AJ</given-names></name></person-group><source>Learning with kernels, support vector machines, regularization, optimization, and beyond</source><year>2002</year><publisher-loc>Cambridge</publisher-loc><publisher-name>MIT Press</publisher-name></element-citation></ref><ref id="CR30"><label>30.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>M&#x000fc;ller-Linow</surname><given-names>M</given-names></name><name><surname>Wojciechowski</surname><given-names>T</given-names></name><name><surname>Fiorani</surname><given-names>F</given-names></name></person-group><article-title>Estimating leaf area with the new smartphone app Plant Screen Mobile_ image data and corresponding ground truth measurements from a case study in Banana and Eragrostis</article-title><source>eDAL Res Data Publ Syst</source><year>2018</year><pub-id pub-id-type="doi">10.25622/fzj/2018/1</pub-id></element-citation></ref></ref-list></back></article>