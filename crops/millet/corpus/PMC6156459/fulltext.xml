<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN" "JATS-archivearticle1.dtd"> 
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="review-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName journalpublishing.dtd?><?SourceDTD.Version 2.3?><?ConverterInfo.XSLTName jp2nlmx2.xsl?><?ConverterInfo.Version 1?><front><journal-meta><journal-id journal-id-type="nlm-ta">Front Psychol</journal-id><journal-id journal-id-type="iso-abbrev">Front Psychol</journal-id><journal-id journal-id-type="publisher-id">Front. Psychol.</journal-id><journal-title-group><journal-title>Frontiers in Psychology</journal-title></journal-title-group><issn pub-type="epub">1664-1078</issn><publisher><publisher-name>Frontiers Media S.A.</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">6156459</article-id><article-id pub-id-type="doi">10.3389/fpsyg.2018.01742</article-id><article-categories><subj-group subj-group-type="heading"><subject>Psychology</subject><subj-group><subject>Review</subject></subj-group></subj-group></article-categories><title-group><article-title>Visualizing Psychological Networks: A Tutorial in R</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Jones</surname><given-names>Payton J.</given-names></name><xref ref-type="corresp" rid="c001"><sup>*</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/442513/overview"/></contrib><contrib contrib-type="author"><name><surname>Mair</surname><given-names>Patrick</given-names></name><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/314659/overview"/></contrib><contrib contrib-type="author"><name><surname>McNally</surname><given-names>Richard J.</given-names></name><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/206443/overview"/></contrib></contrib-group><aff><institution>Department of Psychology, Harvard University</institution>, <addr-line>Cambridge, MA</addr-line>, <country>United States</country></aff><author-notes><fn fn-type="edited-by"><p>Edited by: Sergio Machado, Salgado de Oliveira University, Brazil</p></fn><fn fn-type="edited-by"><p>Reviewed by: Ilya Zhbannikov, Duke University, United States; Claudio Imperatori, Universit&#x000e0; Europea di Roma, Italy</p></fn><corresp id="c001">*Correspondence: Payton J. Jones <email>payton_jones@g.harvard.edu</email></corresp><fn fn-type="other" id="fn001"><p>This article was submitted to Quantitative Psychology and Measurement, a section of the journal Frontiers in Psychology</p></fn></author-notes><pub-date pub-type="epub"><day>19</day><month>9</month><year>2018</year></pub-date><pub-date pub-type="collection"><year>2018</year></pub-date><volume>9</volume><elocation-id>1742</elocation-id><history><date date-type="received"><day>19</day><month>6</month><year>2018</year></date><date date-type="accepted"><day>28</day><month>8</month><year>2018</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2018 Jones, Mair and McNally.</copyright-statement><copyright-year>2018</copyright-year><copyright-holder>Jones, Mair and McNally</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p></license></permissions><abstract><p>Networks have emerged as a popular method for studying mental disorders. Psychopathology networks consist of aspects (e.g., symptoms) of mental disorders (nodes) and the connections between those aspects (edges). Unfortunately, the visual presentation of networks can occasionally be misleading. For instance, researchers may be tempted to conclude that nodes that appear close together are highly related, and that nodes that are far apart are less related. Yet this is not always the case. In networks plotted with force-directed algorithms, the most popular approach, the spatial arrangement of nodes is not easily interpretable. However, other plotting approaches can render node positioning interpretable. We provide a brief tutorial on several methods including multidimensional scaling, principal components plotting, and eigenmodel networks. We compare the strengths and weaknesses of each method, noting how to properly interpret each type of plotting approach.</p></abstract><kwd-group><kwd>network analysis</kwd><kwd>network psychometrics</kwd><kwd>psychopathology</kwd><kwd>multidimensional scaling</kwd><kwd>graph theory</kwd></kwd-group><counts><fig-count count="9"/><table-count count="1"/><equation-count count="0"/><ref-count count="43"/><page-count count="12"/><word-count count="7149"/></counts></article-meta></front><body><p>Psychologists have witnessed an explosion of research utilizing network analysis to measure psychological constructs (see Fried et al., <xref rid="B20" ref-type="bibr">2017</xref> for a review). Networks, which consist of nodes connected to each other by edges, are a useful tool for visualizing and interpreting relational data. Diverse statistical procedures can be applied to analyze network structures. For example, researchers can determine which nodes are most highly connected or whether the network clusters into separate communities of nodes.</p><p>Unlike social networks where one directly observes connections between individuals (e.g., friends, enemies; Burt et al., <xref rid="B7" ref-type="bibr">2013</xref>), the edges in psychological networks require statistical estimation, often partial correlations reflecting the strength of association between nodes. In visualizations, green (or blue) edges represent positive associations, and red edges represent negative associations. The thickness of an edge corresponds to the strength of association. Dubbed &#x0201c;network psychometrics,&#x0201d; (Epskamp et al., <xref rid="B18" ref-type="bibr">2016</xref>; Fried et al., <xref rid="B20" ref-type="bibr">2017</xref>), this approach has stimulated many studies estimating networks of various psychological constructs.</p><p>In contrast to traditional approaches to psychopathology that regard symptoms as reflecting the presence of a latent disease entity that causes their emergence and covariance, network researchers view mental disorders as emerging from interactions among symptoms (Cramer et al., <xref rid="B12" ref-type="bibr">2010</xref>; Borsboom and Cramer, <xref rid="B5" ref-type="bibr">2013</xref>; Borsboom, <xref rid="B4" ref-type="bibr">2017</xref>). Researchers have therefore endeavored to model disorders as causal systems. Theory motivating this type of analysis posits that mental disorders are phenomena emerging from the causal associations between biological, social, and affective components (Jones et al., <xref rid="B29" ref-type="bibr">2017</xref>).</p><p>However, network analysis has not been confined to abnormal psychology. Researchers have applied network analysis in studies on personality (Cramer et al., <xref rid="B11" ref-type="bibr">2012</xref>; Costantini et al., <xref rid="B8" ref-type="bibr">2015a</xref>,<xref rid="B9" ref-type="bibr">b</xref>, <xref rid="B10" ref-type="bibr">2017</xref>) and attitudes (Dalege et al., <xref rid="B14" ref-type="bibr">2016</xref>), arguing that traits and attitudes may be better represented as emergent properties of complex networks rather than as underlying latent variables (e.g., dimensional personality factors). Indeed, as this approach becomes more widely known, it is likely that many more psychological constructs will soon be characterized as emergent properties of complex networks (e.g., Barab&#x000e1;si, <xref rid="B1" ref-type="bibr">2011</xref>). Thus, understanding the nuances of network analysis is of growing importance in psychology.</p><p>In this article, we explore several methods for visualizing networks. Each has advantages and disadvantages. Some foster intuitive spatial interpretation of network structure, whereas others provide little spatial information, but facilitate clarity and aesthetics of network edges. Our tutorial applies exclusively to network visualization; network computation procedures such as node centrality remain identical regardless of the visualization method one uses. We provide brief, simple explanations and examples suitable for psychological researchers who plan to use or interpret network analyses. As this article is not an advanced statistical tutorial, we relegate formulas and other detailed information to an Data Sheet <xref ref-type="supplementary-material" rid="SM1">1</xref> (<xref ref-type="supplementary-material" rid="SM1">Appendix</xref>). We provide accompanying R code (R Core Team, <xref rid="B39" ref-type="bibr">2018</xref>) in the text throughout this tutorial (Data Sheet <xref ref-type="supplementary-material" rid="SM3">3</xref>).</p><sec id="s1"><title>Visual (Mis)interpretation of networks</title><p>Networks enable the visualization of complex, multidimensional data as well as provide diverse statistical indices for interpreting the resultant graphs (e.g., McNally, <xref rid="B36" ref-type="bibr">2016</xref>; Haslbeck and Waldorp, <xref rid="B23" ref-type="bibr">2017</xref>; Jones, <xref rid="B28" ref-type="bibr">2017</xref>; van Borkulo et al., <xref rid="B43" ref-type="bibr">2017</xref>). However, depending on how the network is plotted, visual interpretation of the position of nodes can easily lead one astray. Four misunderstandings about the spatial placement of nodes are common.</p><p>First, researchers may assume that the graphical spacing of two connected nodes signifies the magnitude of their association. This is not always true. Depending on the plotting method, two strongly associated nodes may appear far apart, whereas two weakly associated nodes may appear close together.</p><p>Second, researchers may mistakenly assume that a node's placement along the X and Y axes signifies a meaningful position on a coordinate plane. For example, consider a network in which OCD symptoms cluster on the right and depression symptoms cluster on the left. A researcher might erroneously conclude that the depression symptoms nearer to the right are &#x0201c;more OCD-like&#x0201d; than those toward the left. The X and Y position of nodes cannot always be interpreted in this way; position of nodes does not necessarily correspond to a meaningful coordinate plane.</p><p>Third, researchers may erroneously conclude that a node positioned in the center of the network is a <italic>central</italic> node. Node centrality metrics measure the &#x0201c;importance&#x0201d; of a node in a network, not its physical position in the graph. For example, strength centrality reflects the number and magnitude of connections a node has to other nodes in the network. A node with many strong connections may appear anywhere in the graph, not necessarily in its center. Conversely, nodes appearing near the center of a graph need not be highly central in the network.</p><p>Fourth, researchers may incorrectly assume that a network study failed to replicate because the network in the new study appears dramatically different than the original one. Not all plotting methods are stable, and some can be rotated arbitrarily. This can lead to networks that appear wildly different, even though their statistical structures are similar.</p><p>Depending on the visualization method, any or all of these assumptions may be incorrect. Researchers can minimize misinterpretations by careful choice of visualization methods and raising awareness about how to interpret each type of visualization accurately.</p></sec><sec id="s2"><title>Two practical example datasets</title><p>In order to demonstrate different types of visualizations, we will use two example datasets from the literature. Both datasets contain information on symptoms of obsessive-compulsive disorder (OCD) and depression. OCD and depression are frequently comorbid (Millet et al., <xref rid="B38" ref-type="bibr">2004</xref>). Moreover, comorbid depression is associated with aggravated OCD symptoms and higher rates of suicide (Torres et al., <xref rid="B42" ref-type="bibr">2011</xref>; Brown et al., <xref rid="B6" ref-type="bibr">2015</xref>). Understanding the complex relationships among OCD and depression symptoms may provide valuable insight for clinicians and researchers.</p><p>McNally et al. (<xref rid="B37" ref-type="bibr">2017</xref>) used network analysis to examine OCD and depression symptoms in adults. A dataset of these symptoms in 408 adults is available in the MPsychoR package (Mair, <xref rid="B34" ref-type="bibr">2018</xref>). The 26 symptoms were recorded using Likert style self-report scales (Y-BOCS, QIDS-SR; see McNally et al., <xref rid="B37" ref-type="bibr">2017</xref> for details). Let's load the data (Data Sheet <xref ref-type="supplementary-material" rid="SM2">2</xref>).</p><preformat>
library("MPsychoR")
data(Rogers)
dim(Rogers)
[1] 408 26
</preformat><p>Jones et al. (<xref rid="B30" ref-type="bibr">2018</xref>) replicated this analysis in a smaller sample of adolescents. This dataset is also included in the <italic>MPsychoR</italic> package (Mair, <xref rid="B34" ref-type="bibr">2018</xref>). This replication dataset of 87 adolescents provides an opportunity to compare and contrast visualizations with the sample from McNally et al. (<xref rid="B37" ref-type="bibr">2017</xref>).</p><preformat>
data(Rogers_Adolescent)
dim(Rogers_Adolescent)
[1] 87 26
</preformat><p>To preserve space in network visualizations, we will assign a number to each variable for the labels. Numbering and variable descriptions can be found in Table <xref rid="T1" ref-type="table">1</xref>.</p><preformat>
colnames(Rogers)
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x0003c;- colnames(Rogers_Adolescent)&#x0003c;- 1:26
</preformat><table-wrap id="T1" position="float"><label>Table 1</label><caption><p>Nodes in Adult and Adolescent OCD &#x00026; Depression Networks.</p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top" align="left" rowspan="1" colspan="1"><bold>Number</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Symptom (Depression)</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Number</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Symptom (OCD)</bold></th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1">1</td><td valign="top" align="left" rowspan="1" colspan="1">Sleep-onset insomnia</td><td valign="top" align="left" rowspan="1" colspan="1">17</td><td valign="top" align="left" rowspan="1" colspan="1">Time consumed by obsessions</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">2</td><td valign="top" align="left" rowspan="1" colspan="1">Middle insomnia</td><td valign="top" align="left" rowspan="1" colspan="1">18</td><td valign="top" align="left" rowspan="1" colspan="1">Interference due to obsessions</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">3</td><td valign="top" align="left" rowspan="1" colspan="1">Early morning awakening</td><td valign="top" align="left" rowspan="1" colspan="1">19</td><td valign="top" align="left" rowspan="1" colspan="1">Distress caused by obsessions</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">4</td><td valign="top" align="left" rowspan="1" colspan="1">Hypersomnia</td><td valign="top" align="left" rowspan="1" colspan="1">20</td><td valign="top" align="left" rowspan="1" colspan="1">Difficulty resisting obsessions</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">5</td><td valign="top" align="left" rowspan="1" colspan="1">Sadness</td><td valign="top" align="left" rowspan="1" colspan="1">21</td><td valign="top" align="left" rowspan="1" colspan="1">Difficulty controlling obsessions</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">6</td><td valign="top" align="left" rowspan="1" colspan="1">Decreased appetite</td><td valign="top" align="left" rowspan="1" colspan="1">22</td><td valign="top" align="left" rowspan="1" colspan="1">Time consumed by compulsions</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">7</td><td valign="top" align="left" rowspan="1" colspan="1">Increased appetite</td><td valign="top" align="left" rowspan="1" colspan="1">23</td><td valign="top" align="left" rowspan="1" colspan="1">Interference due to compulsions</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">8</td><td valign="top" align="left" rowspan="1" colspan="1">Weight loss</td><td valign="top" align="left" rowspan="1" colspan="1">24</td><td valign="top" align="left" rowspan="1" colspan="1">Distress caused by compulsions</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">9</td><td valign="top" align="left" rowspan="1" colspan="1">Weight gain</td><td valign="top" align="left" rowspan="1" colspan="1">25</td><td valign="top" align="left" rowspan="1" colspan="1">Difficulty resisting compulsions</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">10</td><td valign="top" align="left" rowspan="1" colspan="1">Concentration impairment</td><td valign="top" align="left" rowspan="1" colspan="1">26</td><td valign="top" align="left" rowspan="1" colspan="1">Difficulty controlling compulsions</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">11</td><td valign="top" align="left" rowspan="1" colspan="1">Guilt and self-blame</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">12</td><td valign="top" align="left" rowspan="1" colspan="1">Suicidal thoughts, plans, or attempts</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">13</td><td valign="top" align="left" rowspan="1" colspan="1">Anhedonia</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">14</td><td valign="top" align="left" rowspan="1" colspan="1">Fatigue</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">15</td><td valign="top" align="left" rowspan="1" colspan="1">Psychomotor retardation</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">16</td><td valign="top" align="left" rowspan="1" colspan="1">Agitation</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr></tbody></table></table-wrap></sec><sec id="s3"><title>Force-directed algorithms (e.g., Fruchterman-Reingold)</title><p>Most network studies in psychopathology have used the Fruchterman-Reingold (FR) algorithm to plot graphs (Fruchterman and Reingold, <xref rid="B21" ref-type="bibr">1991</xref>). The FR algorithm is a force-directed graph method (see also Kamada and Kawai, <xref rid="B31" ref-type="bibr">1989</xref>) akin to creating a physical system of balls connected by elastic strings. An elastic string connecting two nodes pulls them closer together, while other nodes draw them apart in other directions. This results in a visually appealing graph where nodes generally do not overlap and edges have approximately the same length.</p><p>The aim of force-directed algorithms is to provide aesthetically pleasing graphs by minimizing the number of crossing edges and by positioning nodes so that edges have approximately equal length. Importantly, the purpose of plotting with a force-directed algorithm is <italic>not</italic> to place the nodes in meaningful positions in space. Rather, the intent is to position nodes in a manner that allows for easy viewing of the network edges and clustering structures.</p><p>When plotting with the FR algorithm or another force-directed method, one must refrain from making any spatial interpretation. Erroneous interpretations based on spatial arrangement are a common trap as it is difficult to ignore space in a visualization.</p><p>The FR algorithm is a default plotting method in the <italic>qgraph</italic> R package (Epskamp et al., <xref rid="B17" ref-type="bibr">2012</xref>), and is thus very easy to implement. We will demonstrate by using a zero-order correlation network of adults with OCD and depression. The resultant network appears in Figure <xref ref-type="fig" rid="F1">1</xref>.</p><preformat>
library("qgraph")
adult_zeroorder &#x0003c;- cor(Rogers)
qgraph(adult_zeroorder, <bold>layout="spring"</bold>,
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;groups = list(Depression = 1:16,
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;"OCD" = 17:26),
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;color = c("lightblue",
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;"lightsalmon"))
</preformat><fig id="F1" position="float"><label>Figure 1</label><caption><p>Force-directed plotting with Fruchterman&#x02013;Reingold.</p></caption><graphic xlink:href="fpsyg-09-01742-g0001"/></fig><p>Force-directed algorithms produce visually appealing plots in which nodes rarely overlap. It is important to keep in mind that the positioning of nodes in a force-directed algorithm cannot be interpreted.</p></sec><sec id="s4"><title>Multidimensional scaling of networks</title><p>Multidimensional scaling (MDS) has a long history and has been applied in a wide variety of academic arenas (Torgerson, <xref rid="B41" ref-type="bibr">1958</xref>; Kruskal, <xref rid="B33" ref-type="bibr">1964</xref>; Borg and Groenen, <xref rid="B2" ref-type="bibr">2005</xref>; Borg et al., <xref rid="B3" ref-type="bibr">2018</xref>). MDS represents <italic>proximities</italic> among variables as distances between points in a low-dimensional space (e.g., two or three dimensions; Mair et al., <xref rid="B35" ref-type="bibr">2016</xref>). Proximity is an umbrella term for &#x0201c;similarities&#x0201d; between variables (e.g., correlation) or &#x0201c;dissimilarities&#x0201d; (e.g., Euclidean distance). Because MDS helps represent complex data in low-dimensional space, it dovetails precisely with the goal of visual presentation of complex psychological networks. That is, we can use MDS to represent proximities in a two-dimensional space (e.g., X &#x00026; Y) to produce two-dimensional network plots. MDS is particularly useful for understanding networks because the distances between plotted nodes are interpretable as Euclidean distances. That is, highly related nodes will appear close together, whereas weakly related ones will appear far apart.</p><p>In MDS, we consider a matrix of proximities between objects (in our case, nodes). The input data for MDS can be either <italic>directly observed proximities</italic> or <italic>derived proximities</italic> (for details see Mair et al., <xref rid="B35" ref-type="bibr">2016</xref>). Most psychometric networks provide us with a ready-made matrix of <italic>derived proximities</italic> (in this case, <italic>similarities</italic>): the network edges. Network edges are usually zero-order or partial correlations between pairs of nodes. Here, we will again use a zero-order correlation network as our weights matrix.</p><preformat>
adult_zeroorder &#x0003c;- cor(Rogers)
</preformat><p>Because the <italic>smacof</italic> R package (De Leeuw and Mair, <xref rid="B16" ref-type="bibr">2009</xref>) requires dissimilarities (rather than similarities) as input, we will convert the correlation matrix into a dissimilarity matrix (Gower and Legendre, <xref rid="B22" ref-type="bibr">1986</xref>; see the Data Sheet <xref ref-type="supplementary-material" rid="SM1">1</xref> (<xref ref-type="supplementary-material" rid="SM1">Appendix</xref>) for a formula). The result is a symmetric dissimilarity matrix &#x00394; with <italic>n(n-1)/2</italic> dissimilarities (in the lower diagonal portion).</p><preformat>
library("smacof")
dissimilarity_adult &#x0003c;-
&#x000a0;&#x000a0;&#x000a0;&#x000a0;sim2diss(adult_zeroorder)
</preformat><p>After determining our dissimilarity matrix, we then locate points (configuration matrix) in a two-dimensional space such that the distances between the objects (nodes) approximate a transformation of the dissimilarities as closely as possible, given the constraints of a two-dimensional solution. The configuration matrix for this specific application will be a matrix <italic>X</italic> of dimension <italic>n x 2</italic> with elements that represent Cartesian coordinate points with which to plot the nodes. The MDS configuration matrix provides the basis for visualization, not for any network calculations. Although in this tutorial we always constrain the configuration matrix to two dimensions (for two-dimensional plots), it should be noted that MDS can also be used to generate configurations in higher dimensions.</p><preformat>
adult_MDS &#x0003c;- mds(dissimilarity_adult)
head(round(adult_MDS$conf, 2)) # top of
# configuration matrix
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;D1&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;D2
1 &#x02212;0.21&#x000a0;&#x000a0;&#x000a0;&#x000a0;0.53
2 &#x02212;0.80&#x000a0;&#x000a0;&#x000a0;&#x000a0;0.03
3 &#x02212;0.70&#x000a0;&#x000a0;&#x000a0;&#x000a0;0.33
4 &#x000a0;0.25&#x000a0;&#x000a0;&#x000a0;&#x02212;0.77
5 &#x02212;0.53&#x000a0;&#x000a0;&#x000a0;&#x02212;0.07
6 &#x000a0;0.07&#x000a0;&#x000a0;&#x000a0;&#x000a0;0.78
</preformat><sec><title>Transformations</title><p>The configuration matrix is fit on a transformation of the input dissimilarity matrix. There are several different types of transformations available. It is useful to have a variety of options for transformation so that we can choose a transformation which fits our network data. Some common transformation functions include ordinal MDS, interval MDS, ratio MDS, and spline MDS. Ordinal MDS uses a monotone step function. Ratio MDS uses a linear regression with an intercept of 0. Interval MDS is also linear but allows the intercept to vary. Spline MDS uses a monotone integrated spline. These transformations are described in greater detail in Mair et al. (<xref rid="B35" ref-type="bibr">2016</xref>).</p><p>In the case of psychometric networks, where we can reasonably assume that there is some metric information in the proximities, we can choose the transformation from a data-driven perspective. As with fitting any distribution, one should choose a transformation function which is both parsimonious and provides a good fit to the data. Ordinal MDS usually provides the best goodness-of-fit, but is the least parsimonious. In contrast, ratio MDS is parsimonious, but may fit poorly to some networks. We can use Shepard diagrams (Figure <xref ref-type="fig" rid="F2">2</xref>) to visualize MDS fit and to determine the preferred transformation function (Mair et al., <xref rid="B35" ref-type="bibr">2016</xref>).</p><preformat>
adult_MDS_ordinal &#x0003c;- mds(dissimilarity_adult,
&#x000a0;&#x000a0;type="ordinal")
plot(adult_MDS_ordinal, plot.type = "Shepard",
&#x000a0;&#x000a0;main="Ordinal")
text(1.1,0.3, paste("Stress =",
&#x000a0;&#x000a0;round(adult_MDS_ordinal$stress,2)))
</preformat><preformat>
adult_MDS_ratio &#x0003c;- mds(dissimilarity_adult,
&#x000a0;&#x000a0;type="ratio")
plot(adult_MDS_ratio, plot.type = "Shepard",
&#x000a0;&#x000a0;main="Ratio")
text(1.1,0.3, paste("Stress =",
&#x000a0;&#x000a0;round(adult_MDS_ratio$stress,2)))
</preformat><preformat>
adult_MDS_interval &#x0003c;- mds(dissimilarity_adult,
&#x000a0;&#x000a0;type="interval")
plot(adult_MDS_interval, plot.type = "Shepard",
&#x000a0;&#x000a0;main="Interval")
text(1.1,0.3, paste("Stress =",
&#x000a0;&#x000a0;round(adult_MDS_interval$stress,2)))
</preformat><preformat>
adult_MDS_mspline &#x0003c;- mds(dissimilarity_adult,
&#x000a0;&#x000a0;type="mspline")
plot(adult_MDS_mspline, plot.type = "Shepard",
&#x000a0;&#x000a0;main="Spline")
text(1.1,0.3, paste("Stress =",
&#x000a0;&#x000a0;round(adult_MDS_mspline$stress,2)))
</preformat><fig id="F2" position="float"><label>Figure 2</label><caption><p>Shepard Diagrams.</p></caption><graphic xlink:href="fpsyg-09-01742-g0002"/></fig><p>Shepard diagrams allow us to visualize how well our MDS configuration fits our dissimilarity matrix. When the dissimilarities align in a linear fashion, a ratio or interval MDS is most appropriate. In other cases, a nonlinear transformation such as ordinal MDS or spline MDS may be more appropriate. In this case, we decided to use a spline MDS. The normalized stress values (plotted in each graph) can help guide us in deciding which transformation provides the best fit.</p><p>A value known as <italic>stress</italic> indicates how well one's data can be represented in two-dimensions [see Data Sheet <xref ref-type="supplementary-material" rid="SM1">1</xref> (<xref ref-type="supplementary-material" rid="SM1">Appendix</xref>)]. In this tutorial, we will use the <italic>stress-1</italic>, which is a normalized version of stress. When the stress is low, the graph is interpretable. That is, the spacing between two nodes approximately signifies the strength of their association. When the stress is higher, we must be much more cautious about these types of interpretation. A high stress indicates that the nodes cannot be accurately spaced in just two dimensions. For additional guidance on interpreting stress, see Mair et al. (<xref rid="B35" ref-type="bibr">2016</xref>).</p><preformat>
adult_MDS_mspline$stress
[1] 0.189
</preformat><p>The final product of an MDS configuration is a two-dimensional space in which distance between nodes represents the approximate dissimilarity of nodes based on their edges. For example, in our zero-order correlation network, the distance between two nodes varies inversely with their strength of association. Hence, strongly associated nodes appear close together, while weakly associated or negatively associated nodes appear far apart.</p><p>We can produce such a plot by entering the MDS configuration into the &#x0201c;layout&#x0201d; argument of <italic>qgraph</italic> or <italic>plot</italic>.<italic>igraph</italic> (Csardi and Nepusz, <xref rid="B13" ref-type="bibr">2006</xref>; Epskamp et al., <xref rid="B17" ref-type="bibr">2012</xref>). We will also put the stress-1 value as text on the plot, for easy reference. The result appears in Figure <xref ref-type="fig" rid="F3">3</xref>.</p><preformat>
qgraph(adult_zeroorder,
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;<bold>layout=adult_MDS_mspline$conf</bold>,
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;groups = list(Depression = 1:16,
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;"OCD" = 17:26), color = c("lightblue",
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;"lightsalmon"), vsize=4)
text(-1,-1, paste("Stress=",
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;round(adult_MDS_mspline$stress,2)))
</preformat><fig id="F3" position="float"><label>Figure 3</label><caption><p>MDS configuration of a zero-order correlation network.</p></caption><graphic xlink:href="fpsyg-09-01742-g0003"/></fig><p>McNally et al. (<xref rid="B37" ref-type="bibr">2017</xref>) examined a network of OCD and depression symptoms in adults. Here, a zero-order correlation network of symptoms is graphed according to a spline MDS configuration. The distance between nodes represents how close they are in terms of the zero-order correlations.</p><p>One problem with Figure <xref ref-type="fig" rid="F3">3</xref> is that some of the strongly associated nodes overlap, obscuring the edges between those two nodes. Researchers concerned about overlap obscuring important information can reduce the size of the nodes or use points instead of circles to represent variables. Let's produce a plot with points (instead of circles) for nodes. We will use the <italic>textplot</italic> function in the <italic>wordcloud</italic> R package (Fellows, <xref rid="B19" ref-type="bibr">2014</xref>) to ensure that node labels do not overlap (See Figure <xref ref-type="fig" rid="F4">4</xref>).</p><preformat>
library("wordcloud")
qgraph(adult_zeroorder,
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;layout=adult_MDS_mspline$conf,
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;groups = list(Depression = 1:16,
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;"OCD" = 17:26),
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;color = c("lightblue", "lightsalmon"),
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;<bold>vsize=0</bold>, <bold>rescale=FALSE</bold>, <bold>labels=FALSE</bold>)
<bold>points(adult_MDS_mspline$conf</bold>, <bold>pch=16)</bold>
<bold>textplot(adult_MDS_mspline$conf[,1]+.03</bold>,
<bold>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;adult_MDS_mspline$conf[,2]+.03</bold>,
<bold>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;colnames(adult_zeroorder)</bold>,
<bold>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;new=F)</bold>
</preformat><fig id="F4" position="float"><label>Figure 4</label><caption><p>MDS configuration of a zero-order correlation network, with nodes plotted as points.</p></caption><graphic xlink:href="fpsyg-09-01742-g0004"/></fig><p>This figure is identical to Figure <xref ref-type="fig" rid="F3">3</xref>, but uses points to plot nodes. This avoids overlap, although some edges may remain difficult to see if the points are very close together.</p><p>Multidimensional scaling can be applied purely on the edge values in the network. This technique can be used for both psychometric networks and directly derived (e.g., social) networks. In other words, one can generate an MDS network plot based purely on the network edges, without having access to original participant data.</p><p>If one computes an MDS configuration based on the edges, the spacing between nodes is proportional to the strength of the edges. Thus, the information provided by the node spacing is redundant &#x02013; represented once in the edge thickness, and yet again by the node spacing. This redundancy can facilitate quick and intuitive interpretation, but does not add new information to the plot.</p><p>If researchers want to provide <italic>additional</italic> information with the spacing of their nodes, they can base their MDS on a <italic>different</italic> type of similarity matrix derived from the original data. For example, a network could be plotted with edges that represent <italic>partial correlations</italic>, with spacing based on <italic>zero-order correlations</italic>. In other words, we could plot our partial correlation network, complete with edges, in a zero-order correlation <italic>space</italic>. The reverse is also possible; one could use zero-order correlations as edges, and convert a partial correlation matrix into dissimilarities as input for an MDS plotting configuration. The researcher thus maximizes the data conveyed by the graph by using the space to indicate information that is not given in the edge structure. As an example, let's compute a graphical LASSO network of the adult network, as was done by McNally et al. (<xref rid="B37" ref-type="bibr">2017</xref>), but use the zero-order MDS configuration from before to plot the positioning of the nodes (See Figure <xref ref-type="fig" rid="F5">5</xref>).</p><preformat>
adult_glasso &#x0003c;- EBICglasso(cor(Rogers), n=408)
qgraph(<bold>adult_glasso</bold>,
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;layout=adult_MDS_mspline$conf,
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;groups = list(Depression = 1:16,
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;"OCD" = 17:26),
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;color = c("lightblue", "lightsalmon"),
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;vsize=4)
text(-1,-1, paste("Stress=",
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;round(adult_MDS_mspline$stress,2)))
</preformat><fig id="F5" position="float"><label>Figure 5</label><caption><p>Graphical LASSO network, plotted with MDS configuration based on zero-order correlations.</p></caption><graphic xlink:href="fpsyg-09-01742-g0005"/></fig><p>Network of OCD and depression symptoms in adults (McNally et al., <xref rid="B37" ref-type="bibr">2017</xref>). Here, we plot edges according to a <italic>graphical LASSO</italic> network, but use the graphical space between nodes to convey how closely associated nodes are in terms of the <italic>zero-order correlations</italic> based on an MDS configuration. In other words, nodes that are close together are similar in terms of zero-order correlations; nodes that share a thick edge are similar in terms of regularized partial correlations.</p></sec><sec><title>Procrustes</title><p>As noted earlier, one particularly challenging aspect of node placement is providing an accurate visual comparison between two networks. Two or more configurations can be brought into a similar space and compared by using the Procrustes algorithm [see Data Sheet <xref ref-type="supplementary-material" rid="SM1">1</xref> (<xref ref-type="supplementary-material" rid="SM1">Appendix</xref>); see also Davison, <xref rid="B15" ref-type="bibr">1985</xref>]. This procedure, named after Poseidon's son in Greek mythology (&#x0201c;Procrustes, the stretcher&#x0201d;), removes statistically &#x0201c;meaningless&#x0201d; differences (i.e., they do not change the fit of an MDS solution) between the two configurations. We can use the Procrustes algorithm to bring together the adult network from McNally et al. (<xref rid="B37" ref-type="bibr">2017</xref>) with the adolescent network in Jones et al. (<xref rid="B30" ref-type="bibr">2018</xref>). This visual comparison is presented in Figure <xref ref-type="fig" rid="F6">6</xref>.</p><preformat>
adolescent_zeroorder &#x0003c;- cor(Rogers_Adolescent)
dissimilarity_adolescent &#x0003c;-
&#x000a0;&#x000a0;sim2diss(adolescent_zeroorder)
adolescent_MDS &#x0003c;- mds(dissimilarity_adolescent,
&#x000a0;&#x000a0;type="mspline")
fit_procrustes &#x0003c;- <bold>Procrustes(adult_MDS_</bold>
<bold>&#x000a0;&#x000a0;mspline$conf, adolescent_MDS$conf)</bold>
adolescent_glasso &#x0003c;- EBICglasso(cor
&#x000a0;&#x000a0;(Rogers_Adolescent), n=87, gamma=0)
qgraph(adult_glasso, <bold>layout=fit_procrustes$X</bold>,
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;groups = list(Depression = 1:16,
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;"OCD" = 17:26),
color = c("lightblue", "lightsalmon"), title=
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;"Adults, n=408", vsize=4)
text(-1,-1, paste("Stress=",
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;round(adult_MDS_mspline$stress,2)))
qgraph(adolescent_glasso,
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;<bold>layout=fit_procrustes$Yhat</bold>,
groups = list(Depression = 1:16,
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;"OCD" = 17:26),
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;color = c("lightblue", "lightsalmon"),
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;title="Adolescents, n=87", vsize=4)
text(-1,-1, paste("Stress=",
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;round(adolescent_MDS$stress,2)))
</preformat><fig id="F6" position="float"><label>Figure 6</label><caption><p>Two networks plotted using MDS configurations and Procrustes.</p></caption><graphic xlink:href="fpsyg-09-01742-g0006"/></fig><p>This algorithm not only creates interpretable plots; it can also be statistically evaluated in terms of how well the MDS solution replicates across different samples. The Procrustes method provides a way to compare two network plots in a highly meaningful way, where the position of nodes directly corresponds to similarities or dissimilarities between the two networks. We can even quantify the degree to which the MDS replicates between the two networks by using a congruence coefficient. A congruence coefficient is a measure of the similarity of two configurations. It is similar to a correlation coefficient, but does not extract the mean, and computes a correlation about the origin (the point [0,0]), rather than the centroid (the point around which the data are centered). This results in more favorable properties than a simple correlation for determining geometric similarity (Borg and Groenen, <xref rid="B2" ref-type="bibr">2005</xref>). The congruence coefficient is generally very high, so users should not overemphasize the magnitude.</p><preformat>
round(fit_procrustes$congcoef, 3)
[1] 0.930
</preformat><p>An original graphical LASSO empirical network configuration and a replication in a distinct sample (Jones et al., <xref rid="B29" ref-type="bibr">2017</xref>) are presented with MDS-configured networks on the zero-order correlation structures with a Procrustes transformation.</p></sec></sec><sec id="s5"><title>Principal components and eigenmodels</title><p>A potentially useful alternative approach is to plot nodes within a coordinate system based on two extracted dimensions. MDS is possibly the most useful method when one wishes to meaningfully interpret the distances between nodes. In contrast, using a coordinate system provides information on how each node scores on an X criterion and a Y criterion. In a coordinate system, nodes are interpretable in terms of their &#x0201c;X distance&#x0201d; and &#x0201c;Y distance&#x0201d; from one another, but cannot be meaningfully interpreted in terms of their Euclidean distance from one another (i.e., the distance if one drew a straight line between nodes).</p><p>In principal components plotting and eigenmodels, nodes are plotted by their loadings on extracted dimensions. To be clear, these extracted dimensions do not represent latent causes. Rather, they represent aggregations of variance in the data. In some select cases, the underlying dimensions are interpretable, making the absolute position of nodes meaningful in accordance with some theoretical dimension (e.g., a dimension from physiological to nonphysiological symptoms). Because the dimensions represent aggregated variance in the data, plotting according to extracted dimensions may be useful for visualization, even if the dimensions themselves are not interpretable. Thus, a researcher may be theoretically opposed to the idea of latent dimensions as causal mechanisms of mental disorders, but still use a principal components or eigenmodel plotting approach to present a network or compare multiple networks in an easily interpretable format.</p><p>It is unavoidable that information will be lost as we attempt to represent multidimensional data in two-dimensions. This limitation is true for <italic>all</italic> types of network plots. In our specific application of principal components analysis (PCA) and eigenmodels, information for the graph is derived from the first two components or dimensions, and information from any additional components or dimensions is ignored.</p><sec><title>Principal components analysis</title><p>Principal components analysis is an excellent method for extracting meaningful dimensions on which to plot nodes. PCA and its associated rotation methods will be accessible to most psychological researchers as common methods within psychology [see Data Sheet <xref ref-type="supplementary-material" rid="SM1">1</xref> (<xref ref-type="supplementary-material" rid="SM1">Appendix</xref>) for technical details]. Indeed, classical MDS (e.g., Torgerson, <xref rid="B41" ref-type="bibr">1958</xref>) and PCA are closely related methods. PCA can be performed in two ways: using a singular value decomposition on a dataset containing <italic>n</italic> observations on a set of variables (centered and divided by <inline-formula><mml:math id="M1"><mml:msqrt><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mstyle class="text"><mml:mtext class="textit" mathvariant="italic">n</mml:mtext></mml:mstyle><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msqrt></mml:math></inline-formula>, or using an eigenvalue decomposition of the covariance (or correlation) matrix. From a network perspective, standard PCA is thus limited to psychometric networks (i.e., networks based on derived proximities) and is not designed for relational input data as in social networks.</p><p>Unlike in an MDS configuration, the graphed Euclidean distance between nodes (i.e., the distance if one drew a straight line between nodes) is not meaningful in a network plotted with PCA. However, the X distance and the Y distance are <italic>each</italic> meaningful (e.g., how far away nodes are in horizontal space, and how far away they are in vertical space), and represent the difference between nodes on each extracted principal components. A PCA solution can be either rotated or unrotated, depending on one's preference (Joliffe, <xref rid="B27" ref-type="bibr">2002</xref>). These components might or might not be meaningfully interpreted, depending on the theories regarding the network. Regardless, using the principal components as plotting mechanisms is useful to position nodes in a way that should remain largely stable across successful replications. We demonstrate this by using a varimax-rotated PCA implemented in the <italic>psych</italic> R package (Revelle, <xref rid="B40" ref-type="bibr">2014</xref>) based on the zero-order correlation structure for the adult network (McNally et al., <xref rid="B37" ref-type="bibr">2017</xref>). This visualization is presented in Figure <xref ref-type="fig" rid="F7">7</xref>.</p><preformat>
library("psych")
PCA_adult &#x0003c;- principal(cor(Rogers),
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;nfactors = 2)
qgraph(adult_glasso, layout=<bold>PCA_adult$loadings</bold>,
groups = list(Depression = 1:16,
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;"OCD" = 17:26),
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;color = c("lightblue", "lightsalmon"),
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;title="Adults, n=408",
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;layoutOffset=c(.3,.1), vsize=4)
</preformat><fig id="F7" position="float"><label>Figure 7</label><caption><p>Principal components analysis configuration.</p></caption><graphic xlink:href="fpsyg-09-01742-g0007"/></fig><p>To facilitate interpretation, we can also add the percent variance accounted for by the first two principal components, and label the axes as &#x0201c;Component 1&#x0201d; and &#x0201c;Component 2.&#x0201d; Like the stress value in MDS, the variance accounted for by the two components can gauge how well we are capturing the complexity of the network in a two-dimensional solution. In the case of Figure <xref ref-type="fig" rid="F7">7</xref>, we accounted for a relatively low proportion of variance. Thus, even though nodes 10 and 14 are very similar in terms of the first two dimensions, we must be cautious about this interpretation, because they may differ on dimensions not captured in this plot.</p><preformat>
text(1.5,-.8, paste("% var=",
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;round(sum(PCA_adult$values[1:2]/
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;length(PCA_adult$values)),2)))
title(xlab="Component 1",
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;ylab= "Component 2")
</preformat><p>The component loadings of variables (nodes) on the first two extracted dimensions from a principal components analysis can be used as the X-Y coordinates for plotting the nodes. The second component likely captures a dimension of depression vs. OCD. The first component is less clear, but after examining specific nodes, we hypothesize that it is perhaps capturing a dimension of behavioral vs. internally experienced symptoms.</p></sec><sec><title>Eigenmodel networks</title><p>Eigenmodels are a type of latent variable model for symmetric relational data such as undirected networks (Hoff, <xref rid="B24" ref-type="bibr">2008</xref>). They are a generalization of other popular latent variable models, such as latent class and distance models. Although eigenmodels have not yet been applied to modeling psychometric constructs, they are popular in other fields, including social network analysis (Hoff et al., <xref rid="B26" ref-type="bibr">2002</xref>). Eigenmodels are extracted purely on the network structure by using a model-based eigenvalue decomposition and regression [see Data Sheet <xref ref-type="supplementary-material" rid="SM1">1</xref> (<xref ref-type="supplementary-material" rid="SM1">Appendix</xref>)]. The parameters are estimated through Markov chain Monte Carlo (MCMC). That is, for each parameter we extract a posterior distribution by means of which we can compute posterior means (or modes) and corresponding credibility intervals.</p><p>Eigenmodels allow for many interesting statistical possibilities, including attractive methods for identifying clusters (e.g., communities) of nodes. Eigenmodels also allow the researcher to study the effect of covariate variables on the structure of the weights matrix: for example, Kolaczyk and Cs&#x000e1;rdi (<xref rid="B32" ref-type="bibr">2014</xref>) used eigenmodels to study whether a shared office location (a plausible covariate) affected the network structure of collaborations among lawyers. Here, we emphasize that eigenmodels can provide a convenient method for the visual representation of networks in which nodes are plotted in a meaningful space. Because eigenmodels are based solely on the weights matrix (i.e., the edges), they can be computed for any network, and are not limited to psychometric networks. We demonstrate this, based on the graphical LASSO networks of the adult network, using the <italic>eigenmodel</italic> package (Hoff, <xref rid="B25" ref-type="bibr">2012</xref>). The resultant visualization is shown in Figure <xref ref-type="fig" rid="F8">8</xref>.</p><preformat>
library("eigenmodel")
diag(adult_glasso) &#x0003c;- NA ## the function
# needs NA diagonals
p &#x0003c;- 2 ## 2-dimensional solution
fitEM &#x0003c;- eigenmodel_mcmc(Y = adult_glasso,
&#x000a0;R = p, S = 1000, burn = 200, seed = 123)
EVD &#x0003c;- eigen(fitEM$ULU_postmean)
evecs &#x0003c;- EVD$vec[, 1:p] ## eigenvectors
# (coordinates)
qgraph(adult_glasso, layout=evecs,
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;groups = list(Depression = 1:16,
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;"OCD" = 17:26),
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;color = c("lightblue",
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;"lightsalmon"),
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;title= "Adults, n=408", vsize=4)
title(xlab="Dimension 1", ylab= "Dimension
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;2")
</preformat><fig id="F8" position="float"><label>Figure 8</label><caption><p>Eigenmodel configuration.</p></caption><graphic xlink:href="fpsyg-09-01742-g0008"/></fig><p>Eigenmodels extract latent dimensions directly from the weights matrix of a network. The first two dimensions determine the X and Y position of each node, respectively. For example, a node on the right side has a high loading on dimension 1, while a node near the top has a high loading on dimension 2.</p></sec></sec><sec id="s6"><title>Comparing visualization methods: what to use when?</title><p>In this tutorial, we presented four types of methods for visualizing network models: force-directed algorithms, multidimensional scaling, principal components analysis, and eigenmodels. Each of these methods has certain benefits and drawbacks. We present a summary of these costs and benefits in Figure <xref ref-type="fig" rid="F9">9</xref>.</p><fig id="F9" position="float"><label>Figure 9</label><caption><p>Comparison of visualization methods. *If force-directed methods are used to compare networks, the layouts should be constrained to be identical for both networks. Although this does not facilitate any spatial interpretation, it allows for easy comparison of edges. In both PCA and eigenmodels, caution should be taken in comparing networks, as the exact extracted components/dimensions will differ between datasets. **PCA relies on a correlation matrix or a set of observations. ***Although central nodes will sometimes be found near the center, we are not aware of any plotting method in which this assumption always holds.</p></caption><graphic xlink:href="fpsyg-09-01742-g0009"/></fig><sec><title>Force-directed algorithms</title><p>Perhaps the main benefit of force-directed algorithms is clean aesthetics. The nodes in a force-directed plot will rarely overlap, and relatively equal distance between nodes allows for easy viewing of the edges. The main drawback of force-directed methods is that the spacing between nodes is uninterpretable. This can lead to problems, especially when researchers or readers are unaware of this drawback, and make erroneous interpretations based on the node placement.</p></sec><sec><title>Multidimensional scaling (MDS)</title><p>The primary benefit of multidimensional scaling is that the distances between nodes are interpretable. In other words, nodes that are close together are closely related, and nodes that are far apart are less closely related. The stress-1 value provides a helpful estimate of <italic>how</italic> interpretable the distances are (e.g., how well the network is reducible to two dimensions). A low stress value means that the distances are highly interpretable, and a high stress value means that the distances are not very interpretable, due to the network's high dimensionality. MDS can be used to visually compare replications of networks via the Procrustes algorithm. One drawback of MDS (compared to force-directed algorithms) is that nodes may sometimes be placed very close together, making edges harder to see. This drawback can often be alleviated by reducing the node size or by using points rather than circles to represent nodes.</p></sec><sec><title>Principal components analysis (PCA)</title><p>The primary benefit of principal components analysis plotting is that the placement of nodes on the X and Y axes becomes interpretable. In other words, nodes that are far to the right differ in some dimension (i.e., component), compared to nodes on the left. The percent of variance accounted for by two components provides a helpful estimate of how interpretable the node positions are. PCA relies on a correlation matrix or a set of variable observations. Thus, one possible drawback of principal components analysis is that it specifically applies to psychometric networks (i.e., networks relying on a correlation matrix), but not to directly derived networks (e.g., social networks, where the data are not amenable to computing PCA). In PCA, edges may also be difficult to see if nodes score very similarly on both components.</p></sec><sec><title>Eigenmodels</title><p>In terms of plotting and interpreting networks, eigenmodels are similar to PCA. The X and Y placement of nodes is interpretable in terms of latent dimensions of the network. One main benefit of the eigenmodel plotting approach compared to PCA is that eigenmodels can be computed from any network structure, and do not rely on the correlation matrix.</p><p>A brief comparison of the benefits and costs of different visualizations.</p></sec></sec><sec id="s7"><title>Convenience functions</title><p>We hope that this tutorial provides researchers with an understanding of the methodology and rationale for using multidimensional scaling, PCA, and eigenmodels in addition to force-directed algorithms as attractive visualization methods in network analysis. In addition to using these methods as explained in the R code provided above, we have created convenience functions for these plotting methods, which facilitate ease of use at the expense of some flexibility (Jones, <xref rid="B28" ref-type="bibr">2017</xref>).</p><preformat>
library("networktools")
adult_glasso &#x0003c;- EBICglasso(cor(Rogers),
&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;n=408)
adult_qgraph &#x0003c;- qgraph(adult_glasso)
MDSnet(adult_qgraph, MDSadj = cor(Rogers))
PCAnet(adult_qgraph, cormat = cor(Rogers))
EIGENnet(adult_qgraph)
</preformat></sec><sec id="s8"><title>Summary</title><p>Although it is difficult to represent highly complex data in two dimensions, there are a variety of well-established methods that can accomplish this goal. Although two-dimensional representations can never fully convey the true complexity that underlies high-dimensional data, they can provide interpretable visualizations. In addition, many of these methods are capable of providing reasonable and interpretable visual comparisons across networks derived from different samples. We recommend that network researchers carefully consider the benefits and costs of each method and utilize methods that best accomplish their specific aims. We also recommend that researchers explicitly state their rationale for using certain visualization methods and provide clear instructions for how to interpret these visualizations. As researchers follow these recommendations, they will be able to furnish interpretable visualizations that clearly communicate their data to others. Perhaps more importantly, researchers will avoid misinterpretations of visualized data that lead to erroneous conclusions.</p></sec><sec id="s9"><title>Author contributions</title><p>PJ and PM conceived of the presented idea and developed the relevant code. PJ wrote the initial draft of the manuscript. PM wrote the initial draft of the appendix. RM supervised the project. All authors participated in critical editing and revision of the manuscript.</p><sec><title>Conflict of interest statement</title><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p></sec></sec></body><back><sec sec-type="supplementary-material" id="s10"><title>Supplementary material</title><p>The Supplementary Material for this article can be found online at: <ext-link ext-link-type="uri" xlink:href="https://www.frontiersin.org/articles/10.3389/fpsyg.2018.01742/full#supplementary-material">https://www.frontiersin.org/articles/10.3389/fpsyg.2018.01742/full#supplementary-material</ext-link></p><supplementary-material content-type="local-data" id="SM1"><media xlink:href="Data_Sheet_1.PDF"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="SM2"><media xlink:href="Data_Sheet_2.ZIP"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="SM3"><media xlink:href="Data_Sheet_3.zip"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material></sec><ref-list><title>References</title><ref id="B1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barab&#x000e1;si</surname><given-names>A.-L.</given-names></name></person-group> (<year>2011</year>). <article-title>The network takeover</article-title>. <source>Nat. Phys.</source>
<volume>8</volume>:<fpage>14</fpage>
<pub-id pub-id-type="doi">10.1038/nphys2188</pub-id></mixed-citation></ref><ref id="B2"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Borg</surname><given-names>I.</given-names></name><name><surname>Groenen</surname><given-names>P. J. F.</given-names></name></person-group> (<year>2005</year>). <source>Modern Multidimensional Scaling: Theory and Applications</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Springer Science &#x00026; Business Media</publisher-name>.</mixed-citation></ref><ref id="B3"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Borg</surname><given-names>I.</given-names></name><name><surname>Groenen</surname><given-names>P. J. F.</given-names></name><name><surname>Mair</surname><given-names>P.</given-names></name></person-group> (<year>2018</year>). <source>Applied Multidimensional Scaling and Unfolding, 2nd ed.</source>
<publisher-loc>New York, NY</publisher-loc>: <publisher-name>Springer Science &#x00026; Business Media</publisher-name>
<pub-id pub-id-type="doi">10.1007/978-3-319-73471-2</pub-id></mixed-citation></ref><ref id="B4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Borsboom</surname><given-names>D.</given-names></name></person-group> (<year>2017</year>). <article-title>A network theory of mental disorders</article-title>. <source>World Psychiatry</source>
<volume>16</volume>, <fpage>5</fpage>&#x02013;<lpage>13</lpage>. <pub-id pub-id-type="doi">10.1002/wps.20375</pub-id><?supplied-pmid 28127906?><pub-id pub-id-type="pmid">28127906</pub-id></mixed-citation></ref><ref id="B5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Borsboom</surname><given-names>D.</given-names></name><name><surname>Cramer</surname><given-names>A. O.</given-names></name></person-group> (<year>2013</year>). <article-title>Network analysis: an integrative approach to the structure of psychopathology</article-title>. <source>Annu. Rev. Clin. Psychol.</source>
<volume>9</volume>, <fpage>91</fpage>&#x02013;<lpage>121</lpage>. <pub-id pub-id-type="doi">10.1146/annurev-clinpsy-050212-185608</pub-id><?supplied-pmid 23537483?><pub-id pub-id-type="pmid">23537483</pub-id></mixed-citation></ref><ref id="B6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brown</surname><given-names>H. M.</given-names></name><name><surname>Lester</surname><given-names>K. J.</given-names></name><name><surname>Jassi</surname><given-names>A.</given-names></name><name><surname>Heyman</surname><given-names>I.</given-names></name><name><surname>Krebs</surname><given-names>G.</given-names></name></person-group> (<year>2015</year>). <article-title>Paediatric obsessive-compulsive disorder and depressive symptoms: Clinical correlates and CBT treatment outcomes</article-title>. <source>J. Abnorm. Child Psychol.</source>
<volume>43</volume>, <fpage>933</fpage>&#x02013;<lpage>942</lpage>. <pub-id pub-id-type="doi">10.1007/s10802-014-9943-0</pub-id><?supplied-pmid 25301176?><pub-id pub-id-type="pmid">25301176</pub-id></mixed-citation></ref><ref id="B7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burt</surname><given-names>R. S.</given-names></name><name><surname>Kilduff</surname><given-names>M.</given-names></name><name><surname>Tasselli</surname><given-names>S.</given-names></name></person-group> (<year>2013</year>). <article-title>Social network analysis : foundations and frontiers on advantage</article-title>. <source>Annu. Rev. Psychol.</source>
<volume>64</volume>, <fpage>527</fpage>&#x02013;<lpage>547</lpage>. <pub-id pub-id-type="doi">10.1146/annurev-psych-113011-143828</pub-id><?supplied-pmid 23282056?><pub-id pub-id-type="pmid">23282056</pub-id></mixed-citation></ref><ref id="B8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Costantini</surname><given-names>G.</given-names></name><name><surname>Epskamp</surname><given-names>S.</given-names></name><name><surname>Borsboom</surname><given-names>D.</given-names></name><name><surname>Perugini</surname><given-names>M.</given-names></name><name><surname>M&#x000f5;ttus</surname><given-names>R.</given-names></name><name><surname>Waldorp</surname><given-names>L. J.</given-names></name><etal/></person-group> (<year>2015a</year>). <article-title>State of the aRt personality research: a tutorial on network analysis of personality data in R</article-title>. <source>J. Res. Pers.</source>
<volume>54</volume>, <fpage>13</fpage>&#x02013;<lpage>29</lpage>. <pub-id pub-id-type="doi">10.1016/j.jrp.2014.07.003</pub-id></mixed-citation></ref><ref id="B9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Costantini</surname><given-names>G.</given-names></name><name><surname>Richetin</surname><given-names>J.</given-names></name><name><surname>Borsboom</surname><given-names>D.</given-names></name><name><surname>Fried</surname><given-names>E. I.</given-names></name><name><surname>Rhemtulla</surname><given-names>M.</given-names></name><name><surname>Perugini</surname><given-names>M.</given-names></name></person-group> (<year>2015b</year>). <article-title>Development of indirect measures of conscientiousness: combining a facets approach and network analysis</article-title>. <source>Eur. J. Pers.</source>
<volume>29</volume>, <fpage>548</fpage>&#x02013;<lpage>567</lpage>. <pub-id pub-id-type="doi">10.1002/per.2014</pub-id></mixed-citation></ref><ref id="B10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Costantini</surname><given-names>G.</given-names></name><name><surname>Richetin</surname><given-names>J.</given-names></name><name><surname>Preti</surname><given-names>E.</given-names></name><name><surname>Casini</surname><given-names>E.</given-names></name><name><surname>Epskamp</surname><given-names>S.</given-names></name><name><surname>Perugini</surname><given-names>M.</given-names></name></person-group> (<year>2017</year>). <article-title>Stability and variability of personality networks. A tutorial on recent developments in network psychometrics</article-title>. <source>Pers. Individ. Dif.</source>
<pub-id pub-id-type="doi">10.1016/j.paid.2017.06.011</pub-id></mixed-citation></ref><ref id="B11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cramer</surname><given-names>A. O.</given-names></name><name><surname>Sluis</surname><given-names>S.</given-names></name><name><surname>Noordhof</surname><given-names>A.</given-names></name><name><surname>Wichers</surname><given-names>M.</given-names></name><name><surname>Geschwind</surname><given-names>N.</given-names></name><name><surname>Aggen</surname><given-names>S. H.</given-names></name><etal/></person-group> (<year>2012</year>). <article-title>Measurable like temperature or mereological like flocking? On the nature of personality traits</article-title>. <source>Eur. J. Person.</source>
<volume>26</volume>, <fpage>451</fpage>&#x02013;<lpage>459</lpage>. <pub-id pub-id-type="doi">10.1002/per.1879</pub-id></mixed-citation></ref><ref id="B12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cramer</surname><given-names>A. O. J.</given-names></name><name><surname>Waldorp</surname><given-names>L. J.</given-names></name><name><surname>van der Maas</surname><given-names>H. L. J.</given-names></name><name><surname>Borsboom</surname><given-names>D.</given-names></name></person-group> (<year>2010</year>). <article-title>Comorbidity: a network perspective</article-title>. <source>Behav. Brain Sci.</source>
<volume>33</volume>, <fpage>137</fpage>&#x02013;<lpage>150</lpage>. <pub-id pub-id-type="doi">10.1017/S0140525X09991567</pub-id><?supplied-pmid 20584369?><pub-id pub-id-type="pmid">20584369</pub-id></mixed-citation></ref><ref id="B13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Csardi</surname><given-names>G.</given-names></name><name><surname>Nepusz</surname><given-names>T.</given-names></name></person-group> (<year>2006</year>). <article-title>The igraph software package for complex network research</article-title>. <source>InterJ. Comp. Syst.</source>
<volume>1695</volume>, <fpage>1</fpage>&#x02013;<lpage>9</lpage>. Available online at: <ext-link ext-link-type="uri" xlink:href="http://www.necsi.edu/events/iccs6/papers/c1602a3c126ba822d0bc4293371c.pdf">http://www.necsi.edu/events/iccs6/papers/c1602a3c126ba822d0bc4293371c.pdf</ext-link></mixed-citation></ref><ref id="B14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dalege</surname><given-names>J.</given-names></name><name><surname>Borsboom</surname><given-names>D.</given-names></name><name><surname>van Harreveld</surname><given-names>F.</given-names></name><name><surname>van den Berg</surname><given-names>H.</given-names></name><name><surname>Conner</surname><given-names>M.</given-names></name><name><surname>van der Maas</surname><given-names>H. L.</given-names></name></person-group> (<year>2016</year>). <article-title>Toward a formalized account of attitudes: the causal attitude network (CAN) model</article-title>. <source>Psychol. Rev.</source>
<volume>123</volume>, <fpage>2</fpage>&#x02013;<lpage>22</lpage>. <pub-id pub-id-type="doi">10.1037/a0039802</pub-id><?supplied-pmid 26479706?><pub-id pub-id-type="pmid">26479706</pub-id></mixed-citation></ref><ref id="B15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davison</surname><given-names>M. L.</given-names></name></person-group> (<year>1985</year>). <article-title>Multidimensional scaling versus components analysis of test intercorrelations</article-title>. <source>Psychol. Bull.</source>
<volume>97</volume>, <fpage>94</fpage>&#x02013;<lpage>105</lpage>. <pub-id pub-id-type="doi">10.1037/0033-2909.97.1.94</pub-id></mixed-citation></ref><ref id="B16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Leeuw</surname><given-names>J.</given-names></name><name><surname>Mair</surname><given-names>P.</given-names></name></person-group> (<year>2009</year>). <article-title>Multidimensional scaling using majorization: SMACOF in R</article-title>. <source>J. Stat. Softw.</source>
<volume>31</volume>, <fpage>1</fpage>&#x02013;<lpage>30</lpage>. <pub-id pub-id-type="doi">10.18637/jss.v031.i03</pub-id></mixed-citation></ref><ref id="B17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Epskamp</surname><given-names>S.</given-names></name><name><surname>Cramer</surname><given-names>A. O. J.</given-names></name><name><surname>Waldorp</surname><given-names>L. J.</given-names></name><name><surname>Schmittmann</surname><given-names>V. D.</given-names></name><name><surname>Borsboom</surname><given-names>D.</given-names></name></person-group> (<year>2012</year>). <article-title>qgraph: network visualizations of relationships in psychometric data</article-title>. <source>J. Stat. Softw.</source>
<volume>48</volume>, <fpage>1</fpage>&#x02013;<lpage>18</lpage>. <pub-id pub-id-type="doi">10.18637/jss.v048.i04</pub-id></mixed-citation></ref><ref id="B18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Epskamp</surname><given-names>S.</given-names></name><name><surname>Rhemtulla</surname><given-names>M.</given-names></name><name><surname>Borsboom</surname><given-names>D.</given-names></name></person-group> (<year>2016</year>). <article-title>Generalized network psychometrics: Combining network and latent variable models</article-title>. <source>Psychometrika</source>, <volume>82</volume>, <fpage>904</fpage>&#x02013;<lpage>927</lpage>. <pub-id pub-id-type="doi">10.1007/s11336-017-9557-x</pub-id><?supplied-pmid 28290111?><pub-id pub-id-type="pmid">28290111</pub-id></mixed-citation></ref><ref id="B19"><mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Fellows</surname><given-names>I.</given-names></name></person-group> (<year>2014</year>). <source>wordcloud: Word Clouds</source>. R package version 2.5. Available online at: <ext-link ext-link-type="uri" xlink:href="https://CRAN.R-project.org/package=wordcloud">https://CRAN.R-project.org/package=wordcloud</ext-link></mixed-citation></ref><ref id="B20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fried</surname><given-names>E. I.</given-names></name><name><surname>van Borkulo</surname><given-names>C. D.</given-names></name><name><surname>Cramer</surname><given-names>A. O.</given-names></name><name><surname>Boschloo</surname><given-names>L.</given-names></name><name><surname>Schoevers</surname><given-names>R. A.</given-names></name><name><surname>Borsboom</surname><given-names>D.</given-names></name></person-group> (<year>2017</year>). <article-title>Mental disorders as networks of problems: a review of recent insights</article-title>. <source>Soc. Psychiatry Psychiatr. Epidemiol.</source>
<volume>52</volume>, <fpage>1</fpage>&#x02013;<lpage>10</lpage>. <pub-id pub-id-type="doi">10.1007/s00127-016-1319-z</pub-id><?supplied-pmid 27921134?><pub-id pub-id-type="pmid">27921134</pub-id></mixed-citation></ref><ref id="B21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fruchterman</surname><given-names>T. M. J.</given-names></name><name><surname>Reingold</surname><given-names>E. M.</given-names></name></person-group> (<year>1991</year>). <article-title>Graph drawing by force-directed placement</article-title>. <source>Software Pract. Exp.</source>
<volume>21</volume>, <fpage>1129</fpage>&#x02013;<lpage>1164</lpage>. <pub-id pub-id-type="doi">10.1002/spe.4380211102</pub-id></mixed-citation></ref><ref id="B22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gower</surname><given-names>J. C.</given-names></name><name><surname>Legendre</surname><given-names>P.</given-names></name></person-group> (<year>1986</year>). <article-title>Metric and Euclidean properties of dissimilarity coefficients</article-title>. <source>J. Classificat.</source>
<volume>3</volume>, <fpage>5</fpage>&#x02013;<lpage>48</lpage>. <pub-id pub-id-type="doi">10.1007/BF01896809</pub-id></mixed-citation></ref><ref id="B23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haslbeck</surname><given-names>J. M. B.</given-names></name><name><surname>Waldorp</surname><given-names>L. J.</given-names></name></person-group> (<year>2017</year>). <article-title>How well do network models predict observations? On the importance of predictability in network models</article-title>. <source>Behav. Res. Methods</source>. <volume>50</volume>, <fpage>853</fpage>&#x02013;<lpage>861</lpage>. <pub-id pub-id-type="doi">10.3758/s13428-017-0910-x</pub-id><?supplied-pmid 28718088?><pub-id pub-id-type="pmid">28718088</pub-id></mixed-citation></ref><ref id="B24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoff</surname><given-names>P.</given-names></name></person-group> (<year>2008</year>). <article-title>Modeling homophily and stochastic equivalence in symmetric relational data</article-title>, in <source>Advances in Neural Information Processing Systems</source>, <fpage>657</fpage>&#x02013;<lpage>664</lpage>. Available online at: <ext-link ext-link-type="uri" xlink:href="https://papers.nips.cc/book/advances-in-neural-information-processing-systems-20-2007">https://papers.nips.cc/book/advances-in-neural-information-processing-systems-20-2007</ext-link></mixed-citation></ref><ref id="B25"><mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Hoff</surname><given-names>P.</given-names></name></person-group> (<year>2012</year>). <source>Eigenmodel: Semiparametric Factor And Regression Models For Symmetric Relational Data</source>. R Package Version, 1. Available online at: <ext-link ext-link-type="uri" xlink:href="https://cran.r-project.org/package=eigenmodel">https://cran.r-project.org/package=eigenmodel</ext-link></mixed-citation></ref><ref id="B26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoff</surname><given-names>P.</given-names></name><name><surname>Raftery</surname><given-names>A. E.</given-names></name><name><surname>Handcock</surname><given-names>M. S.</given-names></name></person-group> (<year>2002</year>). <article-title>Latent space approaches to social network analysis</article-title>. <source>J. Am. Stat. Assoc.</source>
<volume>97</volume>, <fpage>1090</fpage>&#x02013;<lpage>1098</lpage>. <pub-id pub-id-type="doi">10.1198/016214502388618906</pub-id></mixed-citation></ref><ref id="B27"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Joliffe</surname><given-names>I. T.</given-names></name></person-group> (<year>2002</year>). <source>Principal Component Analysis, 2nd Edn</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Springer</publisher-name>.</mixed-citation></ref><ref id="B28"><mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Jones</surname><given-names>P. J.</given-names></name></person-group> (<year>2017</year>). <source>Networktools: Assorted Tools for Identifying Important Nodes in Networks</source>. R Package Version 1.1.2. Available online at: <ext-link ext-link-type="uri" xlink:href="https://cran.r-project.org/package=networktools">https://cran.r-project.org/package=networktools</ext-link></mixed-citation></ref><ref id="B29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jones</surname><given-names>P. J.</given-names></name><name><surname>Heeren</surname><given-names>A.</given-names></name><name><surname>McNally</surname><given-names>R. J.</given-names></name></person-group> (<year>2017</year>). <article-title>Commentary: a network theory of mental disorders</article-title>. <source>Front. Psychol.</source>, <volume>8</volume>:<fpage>1305</fpage>. <pub-id pub-id-type="doi">10.3389/fpsyg.2017.01305</pub-id><?supplied-pmid 28824490?><pub-id pub-id-type="pmid">28824490</pub-id></mixed-citation></ref><ref id="B30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jones</surname><given-names>P. J.</given-names></name><name><surname>Mair</surname><given-names>P.</given-names></name><name><surname>Riemann</surname><given-names>B. C.</given-names></name><name><surname>Mugno</surname><given-names>B. L.</given-names></name><name><surname>McNally</surname><given-names>R. J.</given-names></name></person-group> (<year>2018</year>). <article-title>A network perspective on comorbid depression in adolescents with obsessive-compulsive disorder</article-title>. <source>J. Anxiety Disord.</source>
<volume>53</volume>, <fpage>1</fpage>&#x02013;<lpage>8</lpage>. <pub-id pub-id-type="doi">10.1016/j.janxdis.2017.09.008</pub-id><?supplied-pmid 29125957?><pub-id pub-id-type="pmid">29125957</pub-id></mixed-citation></ref><ref id="B31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kamada</surname><given-names>T.</given-names></name><name><surname>Kawai</surname><given-names>S.</given-names></name></person-group> (<year>1989</year>). <article-title>An algorithm for drawing general undirected graphs</article-title>. <source>Inf. Process. Lett.</source>
<volume>31</volume>, <fpage>7</fpage>&#x02013;<lpage>15</lpage>. <pub-id pub-id-type="doi">10.1016/0020-0190(89)90102-6</pub-id></mixed-citation></ref><ref id="B32"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kolaczyk</surname><given-names>E.</given-names></name><name><surname>Cs&#x000e1;rdi</surname><given-names>G&#x000e1;bor.</given-names></name></person-group> (<year>2014</year>). <source>Statistical Analysis of Network Data With R (Use R!).</source>
<publisher-loc>New York, NY</publisher-loc>: <publisher-name>Springer</publisher-name>.</mixed-citation></ref><ref id="B33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kruskal</surname><given-names>J. B.</given-names></name></person-group> (<year>1964</year>). <article-title>Nonmetric multidimensional scaling: a numerical method</article-title>. <source>Psychometrika</source>
<volume>29</volume>, <fpage>115</fpage>&#x02013;<lpage>129</lpage>. <pub-id pub-id-type="doi">10.1007/BF02289694</pub-id></mixed-citation></ref><ref id="B34"><mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Mair</surname><given-names>P.</given-names></name></person-group> (<year>2018</year>). <source>MPsychoR: Modern Psychometrics With R</source>. R Package Version 0.10-6. Available online at: <ext-link ext-link-type="uri" xlink:href="https://CRAN.R-project.org/package=MPsychoR">https://CRAN.R-project.org/package=MPsychoR</ext-link></mixed-citation></ref><ref id="B35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mair</surname><given-names>P.</given-names></name><name><surname>Borg</surname><given-names>I.</given-names></name><name><surname>Rusch</surname><given-names>T.</given-names></name></person-group> (<year>2016</year>). <article-title>Goodness-of-fit assessment in multidimensional scaling and unfolding</article-title>. <source>Multivariate Behav. Res.</source>
<volume>51</volume>, <fpage>772</fpage>&#x02013;<lpage>789</lpage>. <pub-id pub-id-type="doi">10.1080/00273171.2016.1235966</pub-id><?supplied-pmid 27802073?><pub-id pub-id-type="pmid">27802073</pub-id></mixed-citation></ref><ref id="B36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McNally</surname><given-names>R. J.</given-names></name></person-group> (<year>2016</year>). <article-title>Can network analysis transform psychopathology?</article-title>
<source>Behav. Res. Ther.</source>
<volume>86</volume>, <fpage>95</fpage>&#x02013;<lpage>104</lpage>. <pub-id pub-id-type="doi">10.1016/j.brat.2016.06.006</pub-id><?supplied-pmid 27424882?><pub-id pub-id-type="pmid">27424882</pub-id></mixed-citation></ref><ref id="B37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McNally</surname><given-names>R. J.</given-names></name><name><surname>Mair</surname><given-names>P.</given-names></name><name><surname>Mugno</surname><given-names>B. L.</given-names></name><name><surname>Riemann</surname><given-names>B. C.</given-names></name></person-group> (<year>2017</year>). <article-title>Co-morbid obsessive&#x02013;compulsive disorder and depression: a Bayesian network approach</article-title>. <source>Psychol. Med.</source>
<volume>47</volume>, <fpage>1204</fpage>&#x02013;<lpage>1214</lpage>. <pub-id pub-id-type="doi">10.1017/S0033291716003287</pub-id><?supplied-pmid 28052778?><pub-id pub-id-type="pmid">28052778</pub-id></mixed-citation></ref><ref id="B38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Millet</surname><given-names>B.</given-names></name><name><surname>Kochman</surname><given-names>F.</given-names></name><name><surname>Gallarda</surname><given-names>T.</given-names></name><name><surname>Krebs</surname><given-names>M. O.</given-names></name><name><surname>Demonfaucon</surname><given-names>F.</given-names></name><name><surname>Barrot</surname><given-names>I.</given-names></name><etal/></person-group>. (<year>2004</year>). <article-title>Phenomenological and comorbid features associated in obsessive&#x02013;compulsive disorder: influence of age of onset</article-title>. <source>J. Affect. Disord.</source>
<volume>79</volume>, <fpage>241</fpage>&#x02013;<lpage>246</lpage>. <pub-id pub-id-type="doi">10.1016/S.0165-0327(02)00351-8</pub-id><?supplied-pmid 15023501?><pub-id pub-id-type="pmid">15023501</pub-id></mixed-citation></ref><ref id="B39"><mixed-citation publication-type="book"><person-group person-group-type="author"><collab>R Core Team</collab></person-group> (<year>2018</year>). <source>R: A Language and Environment for Statistical Computing</source>. <publisher-name>R Foundation for Statistical Computing</publisher-name>, <publisher-loc>Vienna</publisher-loc>.</mixed-citation></ref><ref id="B40"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Revelle</surname><given-names>W.</given-names></name></person-group> (<year>2014</year>). <source>Psych: Procedures For Personality And Psychological Research</source>. <publisher-name>Northwestern University</publisher-name>, <publisher-loc>Evanston</publisher-loc>. R Package Version, 1.</mixed-citation></ref><ref id="B41"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Torgerson</surname><given-names>W.</given-names></name></person-group> (<year>1958</year>). <source>Theory and Methods of Scaling</source>. (<italic>Human Relations Collection</italic>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Wiley</publisher-name>.</mixed-citation></ref><ref id="B42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Torres</surname><given-names>A. R.</given-names></name><name><surname>Ramos-Cerqueira</surname><given-names>A. T.</given-names></name><name><surname>Ferr&#x000e3;o</surname><given-names>Y. A.</given-names></name><name><surname>Fontenelle</surname><given-names>L. F.</given-names></name><name><surname>do Ros&#x000e1;rio</surname><given-names>M. C.</given-names></name><name><surname>Miguel</surname><given-names>E. C.</given-names></name></person-group> (<year>2011</year>). <article-title>Suicidality in obsessive- compulsive disorder: prevalence and relation to symptom dimensions and comorbid conditions</article-title>. <source>J. Clin. Psychiatry</source>
<volume>72</volume>:<fpage>17</fpage>. <pub-id pub-id-type="doi">10.4088/JCP.09m05651blu</pub-id><?supplied-pmid 21272513?><pub-id pub-id-type="pmid">21272513</pub-id></mixed-citation></ref><ref id="B43"><mixed-citation publication-type="other"><person-group person-group-type="author"><name><surname>van Borkulo</surname><given-names>C. D.</given-names></name><name><surname>Boschloo</surname><given-names>L.</given-names></name><name><surname>Kossakowski</surname><given-names>J. J.</given-names></name><name><surname>Tio</surname><given-names>P.</given-names></name><name><surname>Schoevers</surname><given-names>R. A.</given-names></name><name><surname>Borsboom</surname><given-names>D.</given-names></name><etal/></person-group> (<year>2017</year>). <source>Comparing Network Structures on Three Aspects</source>. <pub-id pub-id-type="doi">10.13140/RG.2.2.29455.38569</pub-id></mixed-citation></ref></ref-list></back></article>